{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxgx2wHjrQL9AahRW8ZV4B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pathbit/pathbit-academy-ai/blob/master/0001_llm_x_lrm%20/notebooks/comparacao_llm_lrm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚ú® **Pathbit Academy AI**\n",
        "---"
      ],
      "metadata": {
        "id": "1CWaJaNkr5JB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üö® **IMPORTANTE:**\n",
        "\n",
        "*üí• QUALQUER PESSOA QUE CONSIGA RESOLVER A EQUA√á√ÉO `2 + 2 = ?` PODE CONTINUAR OS PASSOS ABAIXO*"
      ],
      "metadata": {
        "id": "Xv670htP1LDr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Artigo de refer√™ncia:** [https://github.com/pathbit/pathbit-academy-ai/blob/master/0001_llm_x_lrm/article/ARTICLE.md](https://github.com/pathbit/pathbit-academy-ai/blob/master/0001_llm_x_lrm/article/ARTICLE.md)"
      ],
      "metadata": {
        "id": "IjPFjjMwyR7a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ÷é **Compara√ß√£o LLM vs LRM**\n",
        "---"
      ],
      "metadata": {
        "id": "xVCGcybMsiqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ‚ÅâÔ∏è O que √© LLM de forma pr√°tica?\n",
        "\n",
        "**Foco:** gera√ß√£o de linguagem natural.\n",
        "Treinamento: enormes volumes de texto para aprender padr√µes lingu√≠sticos.\n",
        "\n",
        "**Ponto forte:** velocidade e flexibilidade para responder qualquer tipo de pergunta textual.\n",
        "\n",
        "**Ponto fraco:** racioc√≠nio profundo e consist√™ncia em decis√µes complexas.\n",
        "\n",
        "\n",
        "#### ‚ÅâÔ∏è O que √© LRM de forma pr√°tica?\n",
        "\n",
        "**Foco:** racioc√≠nio estruturado e resolu√ß√£o de problemas.\n",
        "Treinamento: combina dados textuais com t√©cnicas que for√ßam o modelo a explicar e validar seu racioc√≠nio (cadeia de pensamento, decomposi√ß√£o de problemas, verifica√ß√£o de hip√≥teses).\n",
        "\n",
        "**Ponto forte:** consist√™ncia em tomadas de decis√£o complexas.\n",
        "\n",
        "**Ponto fraco:** pode ser mais lento e caro que um LLM para tarefas simples."
      ],
      "metadata": {
        "id": "vtuur6nhxuec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ‚õ≥ Cria√ß√£o de conta no Groq\n",
        "---"
      ],
      "metadata": {
        "id": "UR5UUSs1vSa9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ‚ñ∂ Acessar o site abaixo para criar sua conta\n",
        "\n",
        "**[Groq.com](https://console.groq.com/)**"
      ],
      "metadata": {
        "id": "AZ0vnkOtvX_K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ‚ñ∂ Criar uma `API KEY` para a sua conta\n",
        "\n",
        "![Cria√ß√£o API KEY](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0001_llm_x_lrm/assets/01.png)"
      ],
      "metadata": {
        "id": "qwSYsld9wklD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ‚ñ∂ Copiar e salvar a Api Key em um lugar seguro\n",
        "\n",
        "> **Observa√ß√µes**: *Voc√™ pode acessar Api Keys criados atrav√©s deste link: [https://console.groq.com/keys](https://console.groq.com/keys)*\n",
        "\n",
        "![Copiar API KEY](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0001_llm_x_lrm/assets/02.png)"
      ],
      "metadata": {
        "id": "hW3KkWLhwmAF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ‚ñ∂ Adicionar a Api Key criada nas `secrets` do seu Notebook\n",
        "\n",
        "![Adicionar API KEY no Secrets](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0001_llm_x_lrm/assets/03.png)\n",
        "\n",
        "\n",
        "![Adicionar API KEY no Secrets](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0001_llm_x_lrm/assets/04.png)"
      ],
      "metadata": {
        "id": "lBz8FBEFzVrg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ‚öôÔ∏è Configura√ß√£o do ambiente\n",
        "---"
      ],
      "metadata": {
        "id": "RqiwoNKc1GOU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ‚ñ∂ Instalar os pacotes que iremos utilizar neste projeto"
      ],
      "metadata": {
        "id": "MBglR7um29yg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zC78TBpW-9J_"
      },
      "outputs": [],
      "source": [
        "# Instalar a biblioteca do groq\n",
        "!pip -q install groq"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ‚ñ∂ Criar e recuperar a vari√°vel de ambiente para utilizar no Groq"
      ],
      "metadata": {
        "id": "WMx9g-Xf3pae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar e recuperar a vari√°vel de ambiente do Groq\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# Importar os m√≥dulos\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Constante com o nome da secrete adicionada no Notebook\n",
        "GROQ_API_KEY_NAME = \"GROQ_API_KEY\"\n",
        "\n",
        "try:\n",
        "  # Apagar vari√°vel de ambiente criada anteriormente\n",
        "  os.environ.pop(GROQ_API_KEY_NAME, None)\n",
        "\n",
        "  # Recupera a secrete adicionada no Notebook\n",
        "  groq_api_key = userdata.get(GROQ_API_KEY_NAME)\n",
        "\n",
        "  # Cria a vari√°vel de ambiente para o Groq\n",
        "  os.environ[GROQ_API_KEY_NAME] = groq_api_key\n",
        "\n",
        "  # Verifica se a vari√°vel de ambiente n√£o existe\n",
        "  if GROQ_API_KEY_NAME not in os.environ:\n",
        "    raise ValueError(f\"Vari√°vel de ambiente {GROQ_API_KEY_NAME} n√£o definida\")\n",
        "\n",
        "  # Imprime o valor da vari√°vel de ambiente criada para o Groq\n",
        "  print(f\"‚úÖ {GROQ_API_KEY_NAME}: {os.environ['GROQ_API_KEY'][:6]}******\")\n",
        "except Exception as e:\n",
        "  # Imprime o erro ao tentar recuperar e atualizar a vari√°vel de ambiente\n",
        "  print(f\"‚ùå Erro ao atualizar a vari√°vel de ambiente {GROQ_API_KEY_NAME}: {e}\")"
      ],
      "metadata": {
        "id": "KRkCX4pC3p3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ‚ñ∂ Validar se o Groq est√° funcionando corretamente\n",
        "\n",
        "‚ö†Ô∏è Este modelo `compound-beta` √© da pr√≥pria `Groq`, tem um resultado excelente at√© estes momentos dos meus testes."
      ],
      "metadata": {
        "id": "lvBbPHNVvd9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validar se o Groq est√° funcionando corretamente\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# Importar os m√≥dulos\n",
        "import os\n",
        "from groq import Groq\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Configurar a API Key da Groq\n",
        "# (recomendo guardar em segredos do Colab)\n",
        "groq_api_key = os.environ[GROQ_API_KEY_NAME]\n",
        "client = Groq(api_key=groq_api_key)\n",
        "\n",
        "# Definir o modelo de LLM que iremos utilizar\n",
        "# Modelos: https://console.groq.com/docs/models\n",
        "LLM_MODEL = \"compound-beta\"\n",
        "\n",
        "# Criar a prompt do sistema\n",
        "prompt_sistema = \"\"\"\n",
        "REGRAS:\n",
        "\n",
        "++++\n",
        "\n",
        "Voc√™ √© um especialista da √°rea de intelig√™ncia artificial e est√° instruindo\n",
        "crian√ßas e adolescentes no per√≠odo escolar fundamental.\n",
        "\n",
        "  1. Utilize respostas f√°ceis para o seu p√∫blico.\n",
        "\n",
        "  2. Utilize exemplos pr√°ticos do dia-a-dia desse p√∫blico.\n",
        "\n",
        "  3. A resposta deve ser formatada no padr√£o Markdown, seus t√≠tulos devem come√ßar\n",
        "  com 3 \"#\", utilizar emojis e ter as quebras adequadas para separar bem cada\n",
        "  parte do texto, facilitando a leitura.\n",
        "\n",
        "  4. Voc√™ pode utiliar um pouco de linguagem t√©cnica at√© para que a pessoa tenha\n",
        "  interesse em continuar pesquisando sobre o tema e seus subtemas.\n",
        "\n",
        "++++\n",
        "\n",
        "\"\"\".strip()\n",
        "\n",
        "# Pergunta do usu√°rio\n",
        "pergunta_usuario = \"Qual a diferen√ßa entre LLMs e LRMs?\"\n",
        "\n",
        "# Criar o prompt final concatenado (para exibir ou logar)\n",
        "prompt_final = f\"{prompt_sistema}\\n\\nUSU√ÅRIO:\\n\\n{pergunta_usuario}\"\n",
        "\n",
        "# Montar mensagens no formato da Groq e chamar o modelo\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": prompt_sistema},\n",
        "    {\"role\": \"user\", \"content\": pergunta_usuario},\n",
        "]\n",
        "\n",
        "resp = client.chat.completions.create(\n",
        "    model=LLM_MODEL,\n",
        "    messages=messages,\n",
        "    temperature=0.3,\n",
        "    max_completion_tokens=1024,\n",
        ")\n",
        "\n",
        "resposta_modelo = resp.choices[0].message.content\n",
        "\n",
        "# Visualizando o resultado formatado em Markdown\n",
        "display(Markdown(f\"\"\"\n",
        "## > Prompt do sistema\n",
        "{prompt_sistema}\n",
        "\n",
        "## > Pergunta do usu√°rio\n",
        "{pergunta_usuario}\n",
        "\n",
        "## > Prompt final enviado ao LLM\n",
        "{prompt_final}\n",
        "\n",
        "## > Resposta do LLM\n",
        "{resposta_modelo}\n",
        "\"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IKUwA6xYvThe",
        "outputId": "11bc4202-b1e9-496c-b93a-e2a675ca1946"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n## > Prompt do sistema\nREGRAS:\n\n++++\n\nVoc√™ √© um especialista da √°rea de intelig√™ncia artificial e est√° instruindo\ncrian√ßas e adolescentes no per√≠odo escolar fundamental.\n\n  1. Utilize respostas f√°ceis para o seu p√∫blico.\n\n  2. Utilize exemplos pr√°ticos do dia-a-dia desse p√∫blico.\n\n  3. A resposta deve ser formatada no padr√£o Markdown, seus t√≠tulos devem come√ßar\n  com 3 \"#\", utilizar emojis e ter as quebras adequadas para separar bem cada\n  parte do texto, facilitando a leitura.\n\n  4. Voc√™ pode utiliar um pouco de linguagem t√©cnica at√© para que a pessoa tenha\n  interesse em continuar pesquisando sobre o tema e seus subtemas.\n\n++++\n\n## > Pergunta do usu√°rio\nQual a diferen√ßa entre LLMs e LRMs?\n\n## > Prompt final enviado ao LLM\nREGRAS:\n\n++++\n\nVoc√™ √© um especialista da √°rea de intelig√™ncia artificial e est√° instruindo\ncrian√ßas e adolescentes no per√≠odo escolar fundamental.\n\n  1. Utilize respostas f√°ceis para o seu p√∫blico.\n\n  2. Utilize exemplos pr√°ticos do dia-a-dia desse p√∫blico.\n\n  3. A resposta deve ser formatada no padr√£o Markdown, seus t√≠tulos devem come√ßar\n  com 3 \"#\", utilizar emojis e ter as quebras adequadas para separar bem cada\n  parte do texto, facilitando a leitura.\n\n  4. Voc√™ pode utiliar um pouco de linguagem t√©cnica at√© para que a pessoa tenha\n  interesse em continuar pesquisando sobre o tema e seus subtemas.\n\n++++\n\nUSU√ÅRIO:\n\nQual a diferen√ßa entre LLMs e LRMs?\n\n## > Resposta do LLM\n# Diferen√ßa entre LLMs e LRMs ü§î\nA diferen√ßa entre LLMs (Large Language Models) e LRMs (Large Reasoning Models) √© fundamental para entender como a intelig√™ncia artificial processa e entende informa√ß√µes.\n\n## O que s√£o LLMs e LRMs? ü§î\nLLMs s√£o **Modelos de Linguagem Grandes**, projetados para processar e entender linguagem natural. J√° os LRMs s√£o **Modelos de Racioc√≠nio Grandes**, projetados para processar e realizar racioc√≠nios complexos.\n\n## Caracter√≠sticas de LLMs ü§ñ\n* **Exemplo:** Assistente virtual como Siri, Google Assistant ou Alexa.\n* **Fun√ß√£o:** Entender e responder perguntas, realizar tarefas simples, etc.\n* **Treinamento:** Grande quantidade de dados de texto.\n\n## Caracter√≠sticas de LRMs ü§ñ\n* **Exemplo:** Sistemas de recomenda√ß√£o, diagn√≥stico m√©dico ou planejamento de rotas.\n* **Fun√ß√£o:** Realizar racioc√≠nios complexos, tomar decis√µes, etc.\n* **Treinamento:** Grande quantidade de dados e regras l√≥gicas.\n\n## Principais diferen√ßas ü§ù\nA principal diferen√ßa entre LLMs e LRMs √© o **objetivo** e o **treinamento**. LLMs se concentram em processar e entender linguagem natural, enquanto LRMs se concentram em realizar racioc√≠nios complexos e tomar decis√µes. Al√©m disso, o treinamento de LLMs √© baseado em grandes quantidades de dados de texto, enquanto o treinamento de LRMs √© baseado em grandes quantidades de dados e regras l√≥gicas.\n\n## Exemplos pr√°ticos üìö\nPara ilustrar a diferen√ßa, considere os seguintes exemplos:\n* Um LLM pode ser usado para criar um chatbot que responde perguntas frequentes de clientes.\n* Um LRM pode ser usado para criar um sistema de recomenda√ß√£o de produtos que sugere itens baseados nas prefer√™ncias do cliente.\n\n## Conclus√£o üéâ\nEm resumo, a diferen√ßa entre LLMs e LRMs √© que LLMs se concentram em processar e entender linguagem natural, enquanto LRMs se concentram em realizar racioc√≠nios complexos e tomar decis√µes. Ambos s√£o importantes para o desenvolvimento de sistemas inteligentes e podem ser usados em conjunto para criar solu√ß√µes mais avan√ßadas. üöÄ\n\nA resposta para a pergunta \"Qual a diferen√ßa entre LLMs e LRMs?\" √©:\n**A diferen√ßa entre LLMs e LRMs √© o objetivo e o treinamento, onde LLMs se concentram em processar e entender linguagem natural e LRMs se concentram em realizar racioc√≠nios complexos e tomar decis√µes.** ü§î\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### </> Criando as fun√ß√µes para utilizar modelos de LLM e LRM\n",
        "---\n",
        "\n",
        "**‚ÑπÔ∏èÔ∏è Observa√ß√µes:**\n",
        "\n",
        "*Tentei fazer a melhor documenta√ß√£o poss√≠vel para explicar o c√≥digo.*\n",
        "\n",
        "**‚ö†Ô∏è Importante:**\n",
        "\n",
        "*Para garantir os melhores resultados, o c√≥digo utiliza dois modelos de linguagem diferentes, cada um com uma finalidade espec√≠fica:*\n",
        "\n",
        "- **`Llama3-70B-8192:`** Um modelo mais gen√©rico, com um foco em compreens√£o de linguagem natural e tarefas de conversa√ß√£o. Ele √© ideal para interpretar o contexto do texto e gerar respostas fluentes e coerentes, garantindo que a comunica√ß√£o seja clara e natural. O `llama3-70b-8192` est√° focado gerar texto de forma flu√≠da e natural, como uma conversa, mas n√£o em resolver problemas l√≥gicos ou matem√°ticos complexos passo a passo como o outro modelo.\n",
        "\n",
        "- **`DeepSeek R1 Distill Llama 70B:`** Este modelo √© especializado em tarefas que exigem um racioc√≠nio complexo, como l√≥gica, matem√°tica e programa√ß√£o. Sua arquitetura √© otimizada para resolver problemas estruturados de forma eficiente. O `deepseek-r1-distill-llama-70b` √© um exemplo, focado em \"pensar\" passo a passo antes de chegar a uma resposta."
      ],
      "metadata": {
        "id": "OAOrEU7q7F1J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **FUN√á√ïES B√ÅSICAS**"
      ],
      "metadata": {
        "id": "d95kpV6QA3oc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**1. Fun√ß√£o para recuperar o cliente do Groq**\n"
      ],
      "metadata": {
        "id": "qd0IVDMn-MaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defini√ß√µes das fun√ß√µes auxiliares\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# Importar os m√≥dulos\n",
        "import os\n",
        "import time\n",
        "from groq import Groq\n",
        "from typing import Tuple, Optional\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "\n",
        "def criar_cliente_groq() -> Groq:\n",
        "    \"\"\"\n",
        "    Cria o cliente da Groq usando a vari√°vel de ambiente GROQ_API_KEY.\n",
        "\n",
        "    Por que usar env var?\n",
        "    - Seguran√ßa: evita hardcode de chaves no notebook.\n",
        "    - Reprodutibilidade: o mesmo c√≥digo funciona em diferentes ambientes.\n",
        "    \"\"\"\n",
        "    groq_api_key = os.environ[GROQ_API_KEY_NAME]\n",
        "    if not groq_api_key:\n",
        "        raise RuntimeError(\n",
        "            \"GROQ_API_KEY n√£o definida. No Colab, use: os.environ['GROQ_API_KEY']='sua_chave'\"\n",
        "        )\n",
        "    return Groq(api_key=groq_api_key)\n",
        "\n",
        "\n",
        "def exibir_resposta(\n",
        "    modelo: str,\n",
        "    pergunta: str,\n",
        "    resposta: str,\n",
        "    raciocinio: str = None,\n",
        "    tempo: float = 0.0\n",
        "  ):\n",
        "    \"\"\"\n",
        "    Exibe sa√≠da formatada em Markdown no Jupyter/Colab.\n",
        "    - modelo     : nome do modelo utilizado (LLM ou LRM)\n",
        "    - pergunta   : texto enviado\n",
        "    - resposta   : resposta final ao usu√°rio\n",
        "    - raciocinio : cadeia de racioc√≠nio (opcional)\n",
        "    - tempo      : tempo total da execu√ß√£o\n",
        "    \"\"\"\n",
        "    texto_raciocinio = \"\"\n",
        "\n",
        "    if raciocinio:\n",
        "        texto_raciocinio += f\"\\n\\n\"\n",
        "        texto_raciocinio += f\"## üßê Racioc√≠nio                                \\n\"\n",
        "        texto_raciocinio += f\"================================================\\n\\n\"\n",
        "        texto_raciocinio += f\"{raciocinio.strip()}\"\n",
        "\n",
        "    texto_md = f\"\"\"\n",
        "## üß† Modelo: `{modelo}`\n",
        "**‚è± Tempo de execu√ß√£o:** {tempo:.2f}s\n",
        "\n",
        "{texto_raciocinio}\n",
        "\n",
        "### üì• Pergunta\n",
        "\n",
        "{pergunta.strip()}\n",
        "\n",
        "### üì§ Resposta\n",
        "\n",
        "{resposta.strip()}\n",
        "    \"\"\"\n",
        "\n",
        "    display(Markdown(texto_md))"
      ],
      "metadata": {
        "id": "2syPSkoZ8Tgg"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **LLM: FUN√á√ïES E TESTES**\n",
        "\n"
      ],
      "metadata": {
        "id": "HcQRCQ4yAljB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. LLM: Fun√ß√£o para responder usando modelo llama3 do Groq**"
      ],
      "metadata": {
        "id": "UMaq_7lW-r2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defini√ß√£o da fun√ß√£o para responder a pergunta usando LLM\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# Importar os m√≥dulos\n",
        "import os\n",
        "import time\n",
        "from typing import Tuple, Optional\n",
        "from groq import Groq\n",
        "\n",
        "# ==============================\n",
        "# Fun√ß√£o: perguntar_llm\n",
        "# Objetivo: enviar pergunta a um modelo de LINGUAGEM (LLM)\n",
        "# Retorna: (texto_resposta, tempo_em_segundos)\n",
        "# ==============================\n",
        "def perguntar_llm(\n",
        "    pergunta: str,\n",
        "    modelo: str = \"llama3-70b-8192\",       # Modelo padr√£o para linguagem natural\n",
        "    temperatura: float = 0.2,              # Controla a aleatoriedade da resposta\n",
        "    max_tokens_resposta: int = 1024,       # Limita tamanho da resposta (custo/lat√™ncia)\n",
        "    sistema: Optional[str] = None          # Regras ou persona opcionais\n",
        ") -> Tuple[str, float]:\n",
        "    \"\"\"\n",
        "    Envia uma pergunta para um modelo LLM.\n",
        "\n",
        "    Par√¢metros:\n",
        "    - pergunta           : texto enviado ao modelo.\n",
        "    - modelo             : modelo LLM para tarefas gerais (resumo, reescrita, Q&A).\n",
        "    - temperatura        : controla a \"criatividade\" (0.1‚Äì0.3 = mais determin√≠stico).\n",
        "    - max_tokens_resposta: limita tamanho da sa√≠da, evitando custo ou lentid√£o.\n",
        "    - sistema            : mensagem opcional para regras ou persona.\n",
        "\n",
        "    Retorna:\n",
        "    - texto: resposta final do modelo.\n",
        "    - tempo: tempo total da chamada em segundos.\n",
        "    \"\"\"\n",
        "    # cria o cliente autenticado\n",
        "    cliente = criar_cliente_groq()\n",
        "\n",
        "    # monta mensagens no formato da API (sistema opcional + usu√°rio obrigat√≥rio)\n",
        "    mensagens = []\n",
        "    if sistema:\n",
        "        mensagens.append({\"role\": \"system\", \"content\": sistema})\n",
        "\n",
        "    mensagens.append({\"role\": \"user\", \"content\": pergunta})\n",
        "\n",
        "    # marca in√≠cio para medir tempo de execu√ß√£o\n",
        "    inicio = time.perf_counter()\n",
        "\n",
        "    # chamada √† API da Groq\n",
        "    resposta = cliente.chat.completions.create(\n",
        "        model=modelo,\n",
        "        messages=mensagens,\n",
        "        temperature=temperatura,\n",
        "        max_completion_tokens=max_tokens_resposta,\n",
        "    )\n",
        "\n",
        "    # calcula tempo total\n",
        "    tempo_execucao = time.perf_counter() - inicio\n",
        "\n",
        "    # extrai conte√∫do textual da resposta\n",
        "    texto_resposta = resposta.choices[0].message.content.strip()\n",
        "\n",
        "    return modelo, texto_resposta, tempo_execucao"
      ],
      "metadata": {
        "id": "VPoE6SHo-qCJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. LLM: Testando a fun√ß√£o para responder com LLM**"
      ],
      "metadata": {
        "id": "ijpWGrbX_bX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste da fun√ß√£o para responder a pergunta usando LLM\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# Importar os m√≥dulos\n",
        "import os\n",
        "import time\n",
        "from typing import Tuple, Optional\n",
        "from groq import Groq\n",
        "\n",
        "# LLM: resumo e reescrita de tom (usando perguntar_llm)\n",
        "texto = \"\"\"\n",
        "O Banco Central manteve a taxa Selic inalterada. Analistas projetam estabilidade\n",
        "nos pr√≥ximos meses, com aten√ß√£o √† infla√ß√£o de servi√ßos e ao mercado de trabalho.\n",
        "\"\"\"\n",
        "\n",
        "# Pedimos um RESUMO curto (linguagem neutra) ‚Äî tarefa t√≠pica de LLM\n",
        "prompt_resumo = f\"Resuma em 2 frases, com linguagem neutra e direta: {texto}\"\n",
        "modelo_resumo, resposta_resumo, tempo_resumo = perguntar_llm(\n",
        "    pergunta=prompt_resumo,\n",
        "    sistema=\"Responda em Markdown de forma clara e concisa.\"\n",
        ")\n",
        "\n",
        "exibir_resposta(\n",
        "    modelo=modelo_resumo,\n",
        "    pergunta=prompt_resumo,\n",
        "    resposta=resposta_resumo,\n",
        "    tempo=tempo_resumo\n",
        ")\n",
        "\n",
        "# Agora pedimos para REESCREVER o pr√≥prio resumo com outro tom.\n",
        "#   - IMPORTANTE: inclu√≠mos explicitamente o 'resumo' no prompt (o modelo n√£o ‚Äúlembra‚Äù sozinho).\n",
        "prompt_tom = (\n",
        "    \"Reescreva o resumo abaixo com tom mais informal e amig√°vel, mantendo precis√£o.\\n\\n\"\n",
        "    f\"RESUMO ORIGINAL:\\n{resposta_resumo}\"\n",
        ")\n",
        "modelo_tom, resposta_tom, tempo_tom = perguntar_llm(\n",
        "    pergunta=prompt_tom,\n",
        "    sistema=\"Responda em Markdown e use linguagem acess√≠vel; evite jarg√µes.\"\n",
        ")\n",
        "\n",
        "exibir_resposta(\n",
        "    modelo=modelo_tom,\n",
        "    pergunta=prompt_tom,\n",
        "    resposta=resposta_tom,\n",
        "    tempo=tempo_tom\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "XxprzeEJ_bJL",
        "outputId": "be120c51-8c26-424b-916d-e74150d1123a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n## üß† Modelo: `llama3-70b-8192`\n**‚è± Tempo de execu√ß√£o:** 0.34s\n\n\n\n### üì• Pergunta\n\nResuma em 2 frases, com linguagem neutra e direta: \nO Banco Central manteve a taxa Selic inalterada. Analistas projetam estabilidade\nnos pr√≥ximos meses, com aten√ß√£o √† infla√ß√£o de servi√ßos e ao mercado de trabalho.\n\n### üì§ Resposta\n\nO Banco Central manteve a taxa Selic inalterada, indicando estabilidade nos pr√≥ximos meses. Analistas seguem atentos √† infla√ß√£o de servi√ßos e ao mercado de trabalho para avaliar poss√≠veis mudan√ßas futuras.\n    "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n## üß† Modelo: `llama3-70b-8192`\n**‚è± Tempo de execu√ß√£o:** 0.41s\n\n\n\n### üì• Pergunta\n\nReescreva o resumo abaixo com tom mais informal e amig√°vel, mantendo precis√£o.\n\nRESUMO ORIGINAL:\nO Banco Central manteve a taxa Selic inalterada, indicando estabilidade nos pr√≥ximos meses. Analistas seguem atentos √† infla√ß√£o de servi√ßos e ao mercado de trabalho para avaliar poss√≠veis mudan√ßas futuras.\n\n### üì§ Resposta\n\n**Boas Not√≠cias!**\nO Banco Central decidiu manter a taxa Selic igual, o que significa que as coisas devem ficar est√°veis nos pr√≥ximos meses. Agora, os especialistas est√£o de olho na infla√ß√£o de servi√ßos e no mercado de trabalho para ver se h√° alguma mudan√ßa no horizonte.\n    "
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **LRM: FUN√á√ïES E TESTES**"
      ],
      "metadata": {
        "id": "cJs63UUhAwja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. LRM: Fun√ß√£o para responder usando modelo deepseek do Groq**"
      ],
      "metadata": {
        "id": "gYh2luuPAzrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defini√ß√£o da fun√ß√£o para responder a pergunta usando LRM\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# Importar os m√≥dulos\n",
        "import os\n",
        "import time\n",
        "from typing import Tuple, Optional\n",
        "from groq import Groq\n",
        "\n",
        "# ==============================\n",
        "# Fun√ß√£o: perguntar_lrm\n",
        "# Objetivo: enviar pergunta a um modelo de RACIOC√çNIO (LRM)\n",
        "# Retorna: (texto_ao_usuario, cadeia_de_raciocinio, tempo_em_segundos)\n",
        "# ==============================\n",
        "def perguntar_lrm(\n",
        "    pergunta: str,\n",
        "    modelo: str = \"deepseek-r1-distill-llama-70b\",   # Modelo otimizado para racioc√≠nio\n",
        "    temperatura: float = 0.2,                        # Baixa varia√ß√£o para consist√™ncia\n",
        "    formato_raciocinio: Optional[str] = \"parsed\",    # 'parsed', 'raw', 'hidden' ou None\n",
        "    incluir_raciocinio: bool = True,                 # S√≥ usado se formato_raciocinio=None\n",
        "    max_tokens_resposta: int = 2000,                 # Limite da resposta final\n",
        "    max_tokens_raciocinio: Optional[int] = None,     # Limite da cadeia de racioc√≠nio\n",
        "    sistema: Optional[str] = None                    # Mensagem de sistema opcional\n",
        ") -> Tuple[str, Optional[str], float]:\n",
        "    \"\"\"\n",
        "    Envia uma pergunta a um modelo de racioc√≠nio (LRM) da Groq.\n",
        "\n",
        "    Comportamento:\n",
        "    - Se `formato_raciocinio` ‚àà {'parsed','raw','hidden'} ‚Üí usa `reasoning_format` e\n",
        "      **N√ÉO** envia `include_reasoning` (evita erro 400).\n",
        "      ‚Ä¢ 'parsed'  ‚Üí cadeia vem separada em `message.reasoning`\n",
        "      ‚Ä¢ 'raw'     ‚Üí cadeia vem crua, com marca√ß√µes\n",
        "      ‚Ä¢ 'hidden'  ‚Üí o modelo raciocina, mas n√£o retorna a cadeia\n",
        "    - Se `formato_raciocinio` for None ‚Üí n√£o envia `reasoning_format` e usa `include_reasoning`.\n",
        "\n",
        "    Retorno:\n",
        "      (conteudo_final, cadeia_de_raciocinio|None, tempo_execucao_s)\n",
        "    \"\"\"\n",
        "    # Cliente autenticado\n",
        "    chave = os.getenv(\"GROQ_API_KEY\")\n",
        "    if not chave:\n",
        "        raise RuntimeError(\"Defina GROQ_API_KEY no ambiente.\")\n",
        "    cliente = Groq(api_key=chave)\n",
        "\n",
        "    # Mensagens no formato Chat\n",
        "    mensagens = []\n",
        "    if sistema:\n",
        "        mensagens.append({\"role\": \"system\", \"content\": sistema})\n",
        "    mensagens.append({\"role\": \"user\", \"content\": pergunta})\n",
        "\n",
        "    # Monta kwargs din√¢micos conforme as regras da API\n",
        "    kwargs = {\n",
        "        \"model\": modelo,\n",
        "        \"messages\": mensagens,\n",
        "        \"temperature\": temperatura,\n",
        "        \"max_completion_tokens\": max_tokens_resposta,\n",
        "    }\n",
        "\n",
        "    # Se limite de tokens do racioc√≠nio foi definido, adiciona\n",
        "    if max_tokens_raciocinio is not None:\n",
        "        kwargs[\"max_reasoning_tokens\"] = max_tokens_raciocinio\n",
        "\n",
        "    # Regra de exclus√£o m√∫tua:\n",
        "    # - Se formato_raciocinio estiver definido, usa reasoning_format e IGNORA include_reasoning\n",
        "    # - Se formato_raciocinio for None, usa include_reasoning (sem reasoning_format)\n",
        "    if formato_raciocinio is not None:\n",
        "        kwargs[\"reasoning_format\"] = formato_raciocinio\n",
        "        # N√ÉO adicionar include_reasoning para evitar o erro 400\n",
        "    else:\n",
        "        kwargs[\"include_reasoning\"] = bool(incluir_raciocinio)\n",
        "\n",
        "    # Chamada e cron√¥metro\n",
        "    inicio = time.perf_counter()\n",
        "    resp = cliente.chat.completions.create(**kwargs)\n",
        "    tempo = time.perf_counter() - inicio\n",
        "\n",
        "    # Extra√ß√£o da resposta e (se houver) do racioc√≠nio\n",
        "    msg = resp.choices[0].message\n",
        "    conteudo = (msg.content or \"\").strip()\n",
        "\n",
        "    # A cadeia s√≥ vem quando:\n",
        "    # - usamos reasoning_format ('parsed'/'raw'), E\n",
        "    # - n√£o √© 'hidden'\n",
        "    if formato_raciocinio in (\"parsed\", \"raw\"):\n",
        "        raciocinio = getattr(msg, \"reasoning\", None)\n",
        "    else:\n",
        "        # Quando formato=None e include_reasoning=True, algumas combina√ß√µes\n",
        "        # podem retornar o racioc√≠nio embutido; a API nem sempre exp√µe em `reasoning`.\n",
        "        raciocinio = getattr(msg, \"reasoning\", None)\n",
        "\n",
        "    return modelo, conteudo, raciocinio, tempo"
      ],
      "metadata": {
        "id": "pqYmYrwP-RoL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. LRM: Testando a fun√ß√£o para responder com LRM**\n",
        "\n",
        "-\n",
        "\n",
        "**‚ÑπÔ∏èÔ∏è IMPORTANTE:**\n",
        "\n",
        "> *Para ver como o modelo chegou √† resposta final, procure a se√ß√£o **üßê Racioc√≠nio.** Essa √© uma demonstra√ß√£o do poder dos modelos especializados em l√≥gica e racioc√≠nio.*\n"
      ],
      "metadata": {
        "id": "9eS76H1EDeJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testando a fun√ß√£o para responder a pergunta usando LRM\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# Importar os m√≥dulos\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "from typing import Tuple, Optional\n",
        "from groq import Groq\n",
        "\n",
        "cenario = {\n",
        "    \"perfil\": \"conservador\",\n",
        "    \"inflacao_projetada_aa\": 4.0,\n",
        "    \"cdi_aa\": 13.25,\n",
        "    \"vencimentos_anos\": [2026, 2027],\n",
        "    \"objetivo\": \"renda previs√≠vel com baixa volatilidade\",\n",
        "}\n",
        "cenario_fmt = json.dumps(cenario, ensure_ascii=False)\n",
        "\n",
        "prompt_lrm = f\"\"\"\n",
        "Voc√™ √© um analista de investimentos.\n",
        "\n",
        "Dado o cen√°rio:\n",
        "- {cenario_fmt}\n",
        "\n",
        "Decida entre:\n",
        "- t√≠tulo atrelado ao CDI;\n",
        "- prefixado curto;\n",
        "- IPCA+ longo.\n",
        "\n",
        "Importante:\n",
        "\n",
        "1. Resposta e racioc√≠nio sempre em portug√™s do brasil.\n",
        "2. Estruture o racioc√≠nio em etapas (riscos, liquidez, duration, sensibilidade √† infla√ß√£o).\n",
        "3. Apresente a recomenda√ß√£o final e uma pol√≠tica de rebalanceamento simples.\n",
        "4. Use n√∫meros aproximados e justificativas claras.\n",
        "\"\"\"\n",
        "\n",
        "modelo, resposta, cadeia, tempo = perguntar_lrm(\n",
        "    pergunta=prompt_lrm,\n",
        "    sistema=\"Responda em Markdown, com listas numeradas nas etapas.\"\n",
        ")\n",
        "\n",
        "exibir_resposta(\n",
        "    modelo=modelo,\n",
        "    pergunta=prompt_lrm,\n",
        "    resposta=resposta,\n",
        "    raciocinio=cadeia,\n",
        "    tempo=tempo\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3ejlx82kDZ2P",
        "outputId": "3cc94834-8e71-4ceb-ccd0-a2c2d0279ecc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n## üß† Modelo: `deepseek-r1-distill-llama-70b`\n**‚è± Tempo de execu√ß√£o:** 4.86s\n\n\n\n## üßê Racioc√≠nio                                \n================================================\n\nOk, vou come√ßar analisando o perfil do investidor. Ele √© conservador, ent√£o prioriza seguran√ßa e baixa volatilidade. Seu objetivo √© ter renda previs√≠vel, o que sugere que ele busca retornos regulares e confi√°veis.\n\nAgora, vou considerar os riscos de cada op√ß√£o. O t√≠tulo atrelado ao CDI oferece retorno fixo mais uma parcela atrelada ao CDI, o que pode ser atraente em um cen√°rio de taxas mais altas. No entanto, ele est√° sujeito a riscos de cr√©dito e mercado, embora esses sejam menores em t√≠tulos de maior rating.\n\nO prefixado curto paga um valor fixo no vencimento, o que √© bom para quem quer certeza. O risco aqui √© mais relacionado √† infla√ß√£o, pois se os √≠ndices de infla√ß√£o subirem al√©m do projetado, o poder de compra pode ser afetado. Al√©m disso, taxas de juros flutuantes podem impactar o valor de mercado do t√≠tulo.\n\nJ√° o IPCA+ longo oferece prote√ß√£o contra infla√ß√£o, o que √© bom, mas o risco de cr√©dito √© maior, especialmente se a infla√ß√£o ultrapassar as expectativas. Al√©m disso, a liquidez pode ser menor para t√≠tulos mais longos.\n\nEm termos de liquidez, o t√≠tulo atrelado ao CDI geralmente tem boa liquidez, pois √© amplamente negociado. O prefixado curto tamb√©m √© l√≠quido, mas pode ter spreads mais amplos. O IPCA+ longo pode ser menos l√≠quido, especialmente em momentos de estresse no mercado.\n\nQuanto √† duration, o IPCA+ longo tem uma maior exposi√ß√£o a mudan√ßas nas taxas de juros, o que pode afetar seu valor. O prefixado curto tem menor duration, tornando-o menos sens√≠vel a varia√ß√µes nas taxas. O t√≠tulo atrelado ao CDI, por sua vez, tem uma duration intermedi√°ria, dependendo do per√≠odo de recompra.\n\nSobre a sensibilidade √† infla√ß√£o, o IPCA+ longo √© o mais protegido, j√° que acompanha a infla√ß√£o. O t√≠tulo atrelado ao CDI tamb√©m tem uma prote√ß√£o parcial, pois o CDI muitas vezes incorpora expectativas de infla√ß√£o. O prefixado curto √© o mais exposto, j√° que o pagamento √© fixo e n√£o acompanharia uma alta da infla√ß√£o.\n\nConsiderando o vencimento em 2026 e 2027, o IPCA+ longo pode ser mais adequado, pois protege contra infla√ß√£o e oferece retorno real. O t√≠tulo atrelado ao CDI √© uma boa op√ß√£o para diversifica√ß√£o, oferecendo exposi√ß√£o a taxas de juros mais altas. O prefixado curto √© mais adequado para investidores que buscam liquidez e menor exposi√ß√£o a riscos de mercado.\n\nPara o rebalanceamento, recomendo revisar a carteira anualmente, ajustando os pesos das diferentes classes de ativos conforme as condi√ß√µes de mercado e as necessidades do investidor. Isso ajuda a manter o perfil de risco desejado e a maximizar os retornos.\n\nFinalmente, a recomenda√ß√£o √© alocar 50% no IPCA+ longo para prote√ß√£o contra infla√ß√£o, 30% no t√≠tulo atrelado ao CDI para exposi√ß√£o a taxas de juros e 20% no prefixado curto para liquidez e seguran√ßa. Isso oferece um equil√≠brio entre seguran√ßa, renda previs√≠vel e prote√ß√£o contra infla√ß√£o, alinhando-se com o perfil conservador do investidor.\n\n### üì• Pergunta\n\nVoc√™ √© um analista de investimentos.\n\nDado o cen√°rio:\n- {\"perfil\": \"conservador\", \"inflacao_projetada_aa\": 4.0, \"cdi_aa\": 13.25, \"vencimentos_anos\": [2026, 2027], \"objetivo\": \"renda previs√≠vel com baixa volatilidade\"}\n\nDecida entre:\n- t√≠tulo atrelado ao CDI;\n- prefixado curto;\n- IPCA+ longo.\n\nImportante:\n\n1. Resposta e racioc√≠nio sempre em portug√™s do brasil.\n2. Estruture o racioc√≠nio em etapas (riscos, liquidez, duration, sensibilidade √† infla√ß√£o).\n3. Apresente a recomenda√ß√£o final e uma pol√≠tica de rebalanceamento simples.\n4. Use n√∫meros aproximados e justificativas claras.\n\n### üì§ Resposta\n\n### An√°lise e Recomenda√ß√£o para Investimento\n\n#### 1. **Perfil do Investidor**\n   - **Perfil:** Conservador\n   - **Objetivo:** Renda previs√≠vel com baixa volatilidade\n   - **Infla√ß√£o Projetada (a.a.):** 4,0%\n   - **CDI (a.a.):** 13,25%\n   - **Vencimentos Anos:** 2026 e 2027\n\n#### 2. **Etapas de An√°lise**\n\n##### **2.1. Riscos**\n   - **T√≠tulo atrelado ao CDI:** \n     - Risco de cr√©dito moderado.\n     - Sens√≠vel a mudan√ßas nas taxas de juros.\n   - **Prefixado Curto:**\n     - Risco de infla√ß√£o.\n     - Risco de reinvestimento.\n   - **IPCA+ Longo:**\n     - Risco de cr√©dito mais elevado.\n     - Risco de liquidez.\n\n##### **2.2. Liquidez**\n   - **T√≠tulo atrelado ao CDI:** Alta liquidez.\n   - **Prefixado Curto:** Liquidez moderada.\n   - **IPCA+ Longo:** Liquidez baixa.\n\n##### **2.3. Duration**\n   - **T√≠tulo atrelado ao CDI:** Duration intermedi√°ria.\n   - **Prefixado Curto:** Duration baixa.\n   - **IPCA+ Longo:** Duration alta.\n\n##### **2.4. Sensibilidade √† Infla√ß√£o**\n   - **T√≠tulo atrelado ao CDI:** Prote√ß√£o parcial contra infla√ß√£o.\n   - **Prefixado Curto:** Sem prote√ß√£o contra infla√ß√£o.\n   - **IPCA+ Longo:** Prote√ß√£o total contra infla√ß√£o.\n\n#### 3. **Recomenda√ß√£o Final**\n   - **T√≠tulo atrelado ao CDI:** 50%\n     - Oferece retorno fixo com exposi√ß√£o ao CDI.\n     - Prote√ß√£o parcial contra infla√ß√£o.\n   - **Prefixado Curto:** 30%\n     - Oferece retorno fixo e liquidez.\n     - Ideal para vencimentos em 2026 e 2027.\n   - **IPCA+ Longo:** 20%\n     - Prote√ß√£o total contra infla√ß√£o.\n     - Ideal para investidores que buscam prote√ß√£o contra infla√ß√£o.\n\n#### 4. **Pol√≠tica de Rebalanceamento**\n   - Rebalancear a carteira anualmente.\n   - Ajustar os pesos dos ativos de acordo com as condi√ß√µes de mercado e necessidades do investidor.\n\n### Conclus√£o\nA recomenda√ß√£o √© alocar 50% no t√≠tulo atrelado ao CDI, 30% no prefixado curto e 20% no IPCA+ longo. Essa aloca√ß√£o oferece um equil√≠brio entre seguran√ßa, renda previs√≠vel e prote√ß√£o contra infla√ß√£o, alinhando-se com o perfil conservador do investidor.\n    "
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparando ÷é LLM vs LRM üß†\n",
        "---"
      ],
      "metadata": {
        "id": "bIbj9yHPDx5l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> *Agora, utilizando o problema anterior, vamsos comparar a diferen√ßa entre os modelos com base em um mesmo contexto e/ou problema.*"
      ],
      "metadata": {
        "id": "8hig7SEawnuX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CEN√ÅRIO 1"
      ],
      "metadata": {
        "id": "ARtpn5Fc2VgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compara√ß√£o do MESMO PROMPT para LLM e LRM\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# Importar os m√≥dulos\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "from typing import Tuple, Optional\n",
        "from groq import Groq\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Defindo o prompt\n",
        "cenario = {\n",
        "    \"perfil\": \"conservador\",\n",
        "    \"inflacao_projetada_aa\": 5.0,\n",
        "    \"cdi_aa\": 14.5,\n",
        "    \"vencimentos_anos\": [2026, 2027],\n",
        "    \"objetivo\": \"renda previs√≠vel com baixa volatilidade\",\n",
        "}\n",
        "\n",
        "cenario_fmt = json.dumps(cenario, ensure_ascii=False)\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Voc√™ √© um analista de investimentos.\n",
        "\n",
        "Dado o cen√°rio:\n",
        "- {cenario_fmt}\n",
        "\n",
        "Decida entre:\n",
        "- t√≠tulo atrelado ao CDI;\n",
        "- prefixado curto;\n",
        "- IPCA+ longo.\n",
        "\n",
        "Importante:\n",
        "\n",
        "1. Resposta e racioc√≠nio sempre em portug√™s do brasil.\n",
        "2. Estruture o racioc√≠nio em etapas (riscos, liquidez, duration, sensibilidade √† infla√ß√£o).\n",
        "3. Apresente a recomenda√ß√£o final e uma pol√≠tica de rebalanceamento simples.\n",
        "4. Use n√∫meros aproximados e justificativas claras.\n",
        "\"\"\"\n",
        "\n",
        "# T√≠tulo das compara√ß√µes\n",
        "display(Markdown(\"## üî¨ Compara√ß√£o Lado a Lado ‚Äî LLM vs LRM (MESMO prompt)\"))\n",
        "display(Markdown(f\"### üìù Prompt usado nos dois modelos\\n> {prompt.replace('\\\\n', '\\\\n> ')}\"))\n",
        "\n",
        "# M√°ximo de tokens\n",
        "total_tokens_resposta=2000\n",
        "\n",
        "# LLM\n",
        "modelo_llm, saida_llm, tempo_llm = perguntar_llm(\n",
        "    pergunta=prompt,\n",
        "    sistema=\"Responda em Markdown; explicite depend√™ncias, riscos e mitiga√ß√£o.\",\n",
        "    max_tokens_resposta=total_tokens_resposta\n",
        ")\n",
        "\n",
        "exibir_resposta(\n",
        "    modelo=modelo_llm,\n",
        "    pergunta=prompt,\n",
        "    resposta=saida_llm,\n",
        "    tempo=tempo_llm\n",
        ")\n",
        "\n",
        "# LRM\n",
        "modelo_lrm, saida_lrm, cadeia_lrm, tempo_lrm = perguntar_lrm(\n",
        "    pergunta=prompt,\n",
        "    sistema=\"Responda em Markdown; explicite depend√™ncias, riscos e mitiga√ß√£o.\",\n",
        "    max_tokens_resposta=total_tokens_resposta\n",
        ")\n",
        "\n",
        "exibir_resposta(\n",
        "    modelo=modelo_lrm,\n",
        "    pergunta=prompt,\n",
        "    resposta=saida_lrm,\n",
        "    raciocinio=cadeia_lrm,\n",
        "    tempo=tempo_lrm\n",
        ")"
      ],
      "metadata": {
        "id": "EFQKdnzCELm6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c882f408-d837-45e1-e5cd-86f0d6c5620a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## üî¨ Compara√ß√£o Lado a Lado ‚Äî LLM vs LRM (MESMO prompt)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### üìù Prompt usado nos dois modelos\n> \nVoc√™ √© um analista de investimentos.\n\nDado o cen√°rio:\n- {\"perfil\": \"conservador\", \"inflacao_projetada_aa\": 5.0, \"cdi_aa\": 14.5, \"vencimentos_anos\": [2026, 2027], \"objetivo\": \"renda previs√≠vel com baixa volatilidade\"}\n\nDecida entre:\n- t√≠tulo atrelado ao CDI;\n- prefixado curto;\n- IPCA+ longo.\n\nImportante:\n\n1. Resposta e racioc√≠nio sempre em portug√™s do brasil.\n2. Estruture o racioc√≠nio em etapas (riscos, liquidez, duration, sensibilidade √† infla√ß√£o).\n3. Apresente a recomenda√ß√£o final e uma pol√≠tica de rebalanceamento simples.\n4. Use n√∫meros aproximados e justificativas claras.\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n## üß† Modelo: `llama3-70b-8192`\n**‚è± Tempo de execu√ß√£o:** 2.65s\n\n\n\n### üì• Pergunta\n\nVoc√™ √© um analista de investimentos.\n\nDado o cen√°rio:\n- {\"perfil\": \"conservador\", \"inflacao_projetada_aa\": 5.0, \"cdi_aa\": 14.5, \"vencimentos_anos\": [2026, 2027], \"objetivo\": \"renda previs√≠vel com baixa volatilidade\"}\n\nDecida entre:\n- t√≠tulo atrelado ao CDI;\n- prefixado curto;\n- IPCA+ longo.\n\nImportante:\n\n1. Resposta e racioc√≠nio sempre em portug√™s do brasil.\n2. Estruture o racioc√≠nio em etapas (riscos, liquidez, duration, sensibilidade √† infla√ß√£o).\n3. Apresente a recomenda√ß√£o final e uma pol√≠tica de rebalanceamento simples.\n4. Use n√∫meros aproximados e justificativas claras.\n\n### üì§ Resposta\n\n**An√°lise de Investimento**\n\n**Perfil do Investidor:** Conservador\n**Objetivo:** Renda previs√≠vel com baixa volatilidade\n\n**Etapa 1: Riscos**\n\nO perfil conservador do investidor indica que ele busca minimizar o risco de perda de capital. Portanto, √© fundamental evitar investimentos com alto risco de perda de valor.\n\n**Etapa 2: Liquidez**\n\nO investidor n√£o especificou uma necessidade de liquidez imediata, mas √© importante considerar a possibilidade de resgate em caso de necessidade. Investimentos com vencimentos mais curtos ou liquidez di√°ria s√£o mais apropriados.\n\n**Etapa 3: Duration**\n\nA duration √© um fator importante para investimentos com vencimentos mais longos. No entanto, como o objetivo √© renda previs√≠vel com baixa volatilidade, √© mais importante considerar a taxa de juros e a infla√ß√£o projetada.\n\n**Etapa 4: Sensibilidade √† Infla√ß√£o**\n\nA infla√ß√£o projetada para os pr√≥ximos anos √© de 5,0% ao ano. √â fundamental considerar investimentos que mantenham o poder de compra do capital investido.\n\n**An√°lise das Op√ß√µes**\n\n* **T√≠tulo atrelado ao CDI:** Oferece uma taxa de juros de 14,5% ao ano, o que √© atraente em um cen√°rio de alta taxa de juros. No entanto, como o t√≠tulo √© atrelado ao CDI, a taxa de juros pode variar ao longo do tempo, o que pode afetar a renda previs√≠vel.\n* **Prefixado curto:** Oferece uma taxa de juros fixa por um per√≠odo curto de tempo. Embora seja uma op√ß√£o mais segura, a taxa de juros pode ser menor que a do t√≠tulo atrelado ao CDI.\n* **IPCA+ longo:** Oferece uma taxa de juros indexada √† infla√ß√£o, o que mant√©m o poder de compra do capital investido. No entanto, a taxa de juros pode ser menor que a do t√≠tulo atrelado ao CDI.\n\n**Recomenda√ß√£o Final**\n\nConsiderando o perfil conservador do investidor e o objetivo de renda previs√≠vel com baixa volatilidade, **recomendo o t√≠tulo atrelado ao CDI**. Embora haja um risco de varia√ß√£o da taxa de juros, a taxa de 14,5% ao ano √© atraente em um cen√°rio de alta taxa de juros. Al√©m disso, o t√≠tulo atrelado ao CDI oferece uma renda previs√≠vel com baixa volatilidade.\n\n**Pol√≠tica de Rebalanceamento**\n\nPara manter a estrat√©gia de investimento, √© recomend√°vel rever a carteira a cada 6 meses e rebalancear se a taxa de juros do t√≠tulo atrelado ao CDI variar em mais de 1% em rela√ß√£o √† taxa de juros projetada. Al√©m disso, √© importante monitorar a infla√ß√£o projetada e ajustar a estrat√©gia de investimento se necess√°rio.\n    "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n## üß† Modelo: `deepseek-r1-distill-llama-70b`\n**‚è± Tempo de execu√ß√£o:** 5.78s\n\n\n\n## üßê Racioc√≠nio                                \n================================================\n\nOk, vamos l√°. Primeiro, preciso entender o perfil do investidor. Ele √© conservador, ent√£o busca renda previs√≠vel com baixa volatilidade. Isso significa que ele provavelmente n√£o quer correr riscos altos e prefere estabilidade.\n\nAgora, os dados do cen√°rio: infla√ß√£o projetada de 5% ao ano e CDI de 14,5% ao ano. Os vencimentos s√£o em 2026 e 2027. O objetivo √© renda previs√≠vel com baixa volatilidade.\n\nPrimeiro, vou analisar cada uma das op√ß√µes: t√≠tulo atrelado ao CDI, prefixado curto e IPCA+ longo.\n\nCome√ßo com o t√≠tulo atrelado ao CDI. Como o CDI est√° em 14,5%, isso oferece uma rentabilidade maior, mas com risco de cr√©dito. Se o investidor optar por um t√≠tulo de liquidez di√°ria, pode resgatar o dinheiro quando precisar, o que √© bom. No entanto, se a taxa de juros subir, o valor do t√≠tulo pode cair, o que √© um risco. Al√©m disso, a infla√ß√£o projetada de 5% √© menor que o CDI, ent√£o a rentabilidade real seria de 9,5%, o que √© bom. Mas o risco de cr√©dito pode ser um problema se a institui√ß√£o financeira tiver problemas.\n\nEm seguida, o prefixado curto. Com vencimento em 2026 e 2027, a rentabilidade l√≠quida √© de 8% a 9%. Isso √© menor que o CDI, mas o risco de taxa de juros √© menor porque o prazo √© curto. A liquidez tamb√©m √© boa, pois s√£o t√≠tulos de alta liquidez. A exposi√ß√£o √† infla√ß√£o √© menor aqui, j√° que o prazo √© curto e a infla√ß√£o projetada √© de 5%, ent√£o a rentabilidade real seria de 3% a 4%, o que √© razo√°vel, mas menor que o CDI.\n\nPor fim, o IPCA+ longo. Oferece uma rentabilidade de 4% mais a infla√ß√£o. Com a infla√ß√£o projetada de 5%, a rentabilidade total seria de 9%. Isso protege contra a infla√ß√£o, o que √© bom. No entanto, o prazo mais longo significa que o risco de taxa de juros √© maior. Se as taxas de juros subirem, o valor do t√≠tulo pode cair bastante. Al√©m disso, a liquidez pode ser menor, o que pode ser um problema se o investidor precisar do dinheiro rapidamente.\n\nAgora, pensando no perfil conservador, a liquidez √© importante, ent√£o op√ß√µes com boa liquidez s√£o prefer√≠veis. O risco de cr√©dito no CDI pode ser mitigado escolhendo institui√ß√µes financeiras s√≥lidas. O risco de taxa de juros no IPCA+ longo √© preocupante, ent√£o talvez n√£o seja a melhor op√ß√£o para um investidor conservador.\n\nConsiderando tudo isso, o t√≠tulo atrelado ao CDI parece mais adequado. Oferece uma boa rentabilidade, prote√ß√£o contra a infla√ß√£o e liquidez di√°ria. Al√©m disso, o risco de cr√©dito pode ser minimizado escolhendo institui√ß√µes confi√°veis. Para mitigar o risco de taxa de juros, o investidor pode manter uma carteira diversificada e monitorar as taxas de juros para decidir se precisa rebalancear.\n\nPortanto, a recomenda√ß√£o seria investir em t√≠tulos atrelados ao CDI, com vencimentos em 2026 e 2027, para garantir renda previs√≠vel e baixa volatilidade. Al√©m disso, √© importante monitorar regularmente as taxas de juros e a infla√ß√£o para decidir se √© necess√°rio rebalancear a carteira, mantendo-a alinhada com o perfil de risco do investidor.\n\n### üì• Pergunta\n\nVoc√™ √© um analista de investimentos.\n\nDado o cen√°rio:\n- {\"perfil\": \"conservador\", \"inflacao_projetada_aa\": 5.0, \"cdi_aa\": 14.5, \"vencimentos_anos\": [2026, 2027], \"objetivo\": \"renda previs√≠vel com baixa volatilidade\"}\n\nDecida entre:\n- t√≠tulo atrelado ao CDI;\n- prefixado curto;\n- IPCA+ longo.\n\nImportante:\n\n1. Resposta e racioc√≠nio sempre em portug√™s do brasil.\n2. Estruture o racioc√≠nio em etapas (riscos, liquidez, duration, sensibilidade √† infla√ß√£o).\n3. Apresente a recomenda√ß√£o final e uma pol√≠tica de rebalanceamento simples.\n4. Use n√∫meros aproximados e justificativas claras.\n\n### üì§ Resposta\n\n# An√°lise de Investimentos para Perfil Conservador\n\n## Resumo da Situa√ß√£o\n- **Perfil do Investidor:** Conservador, busca renda previs√≠vel com baixa volatilidade.\n- **Cen√°rio Econ√¥mico:**\n  - Infla√ß√£o projetada: 5,0% a.a.\n  - CDI: 14,5% a.a.\n  - Vencimentos desejados: 2026 e 2027.\n\n## Op√ß√µes de Investimento\n\n### 1. T√≠tulo Atrelado ao CDI\n- **Caracter√≠sticas:**\n  - Rentabilidade de 14,5% a.a.\n  - Liquidez di√°ria.\n  - Sens√≠vel a mudan√ßas nas taxas de juros.\n  - Risco de cr√©dito depende da institui√ß√£o emissora.\n\n- **Vantagens:**\n  - Alta rentabilidade.\n  - Liquidez imediata.\n  - Prote√ß√£o contra infla√ß√£o superior √† projetada.\n\n- **Desvantagens:**\n  - Risco de perda de valor se as taxas de juros subirem.\n  - Risco de cr√©dito.\n\n### 2. Prefixado Curto\n- **Caracter√≠sticas:**\n  - Rentabilidade l√≠quida de 8% a 9% a.a.\n  - Vencimento em 2026 e 2027.\n  - Menor exposi√ß√£o ao risco de taxa de juros.\n\n- **Vantagens:**\n  - Menor risco de taxa de juros.\n  - Liquidez relativamente boa.\n  - Rentabilidade razo√°vel.\n\n- **Desvantagens:**\n  - Rentabilidade inferior ao CDI.\n  - Exposi√ß√£o √† infla√ß√£o, embora menor.\n\n### 3. IPCA+ Longo\n- **Caracter√≠sticas:**\n  - Rentabilidade de IPCA + 4% a.a. (9% total).\n  - Prote√ß√£o contra infla√ß√£o.\n  - Maior exposi√ß√£o ao risco de taxa de juros.\n\n- **Vantagens:**\n  - Prote√ß√£o contra infla√ß√£o.\n  - Rentabilidade competitiva.\n\n- **Desvantagens:**\n  - Maior risco de perda de valor com aumento das taxas de juros.\n  - Menor liquidez.\n\n## An√°lise por Etapas\n\n### 1. Riscos\n- **T√≠tulo CDI:** Risco de cr√©dito e risco de taxa de juros.\n- **Prefixado Curto:** Menor risco de taxa de juros, exposi√ß√£o √† infla√ß√£o.\n- **IPCA+ Longo:** Maior risco de taxa de juros.\n\n### 2. Liquidez\n- **T√≠tulo CDI:** Alta liquidez.\n- **Prefixado Curto:** Liquidez boa.\n- **IPCA+ Longo:** Liquidez menor.\n\n### 3. Duration\n- **T√≠tulo CDI:** Duration mais curto, menos exposi√ß√£o ao risco de taxa de juros.\n- **Prefixado Curto:** Duration curto, menor risco.\n- **IPCA+ Longo:** Duration mais longo, maior exposi√ß√£o ao risco.\n\n### 4. Sensibilidade √† Infla√ß√£o\n- **T√≠tulo CDI:** Prote√ß√£o contra infla√ß√£o.\n- **Prefixado Curto:** Menor prote√ß√£o.\n- **IPCA+ Longo:** Prote√ß√£o total contra infla√ß√£o.\n\n## Recomenda√ß√£o Final\n**Recomenda√ß√£o:** Investir em **t√≠tulos atrelados ao CDI** com vencimentos em 2026 e 2027.\n\n**Justificativa:**\n- Oferecem alta rentabilidade (14,5% a.a.).\n- Prote√ß√£o contra infla√ß√£o.\n- Liquidez di√°ria.\n- Risco de cr√©dito pode ser mitigado escolhendo institui√ß√µes financeiras s√≥lidas.\n\n## Pol√≠tica de Rebalanceamento\n- Monitorar taxas de juros e infla√ß√£o semestralmente.\n- Rebalancear para manter a exposi√ß√£o ao risco de taxa de juros em n√≠veis confort√°veis para o perfil conservador.\n\n## Conclus√£o\nOs t√≠tulos atrelados ao CDI s√£o a melhor op√ß√£o para o perfil conservador, oferecendo renda previs√≠vel, baixa volatilidade e prote√ß√£o contra infla√ß√£o. A liquidez di√°ria e a rentabilidade superior compensam os riscos associados, que podem ser mitigados com uma gest√£o cuidadosa.\n    "
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CEN√ÅRIO 2"
      ],
      "metadata": {
        "id": "yG9bx5kR2ZmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compara√ß√£o do MESMO PROMPT para LLM e LRM\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# Importar os m√≥dulos\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "from typing import Tuple, Optional\n",
        "from groq import Groq\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "def _blockquote(txt: str) -> str:\n",
        "    txt = (txt or \"\").strip()\n",
        "    return \"\" if not txt else \"\\n\".join(\"> \" + ln for ln in txt.splitlines())\n",
        "\n",
        "# Mesmo CEN√ÅRIO (user prompt id√™ntico para ambos) ===\n",
        "prompt_comum = \"\"\"\n",
        "Crie um plano de 6 semanas para lan√ßar um MVP de assistente de atendimento:\n",
        "\n",
        "  - Backend: APIs j√° existentes.\n",
        "  - Frontend: web app simples.\n",
        "  - Equipe: 2 devs full-stack, 1 QA, 1 PM; sprint semanal.\n",
        "  - Restri√ß√µes: integra√ß√£o com WhatsApp Business na semana 3+; testes de carga na semana 5.\n",
        "  - Entreg√°veis por semana; riscos e mitiga√ß√£o; crit√©rios de aceite.\n",
        "\"\"\".strip()\n",
        "\n",
        "display(Markdown(\"## üî¨ Compara√ß√£o LLM vs LRM ‚Äî **mesmo cen√°rio**, pap√©is diferentes\"))\n",
        "display(Markdown(\"### üìù Prompt (usu√°rio) enviado *igual* aos dois modelos\"))\n",
        "display(Markdown(_blockquote(prompt_comum)))\n",
        "\n",
        "# M√°ximo de tokens\n",
        "total_tokens_resposta=2000\n",
        "\n",
        "# Regras de SISTEMA para separar os perfis\n",
        "prompt_sistema_comum =f\"\"\"\n",
        "Voc√™ √© um analista de projetos e deve EXPLICAR O RACIOC√çNIO.\n",
        "-\n",
        "Responda em Markdown, com:\n",
        "\n",
        "  1) Decomposi√ß√£o em etapas (depend√™ncias, riscos, trade-offs).\n",
        "  2) Estimativas simples (horas por papel, capacidade por sprint, margens).\n",
        "  3) Tabela de riscos (probabilidade x impacto x mitiga√ß√£o) e caminho cr√≠tico.\n",
        "  4) Crit√©rios de aceite objetivos por semana.\n",
        "  5) Formate como lista de semanas com checklist objetivo.\n",
        "\n",
        "  Inclua uma se√ß√£o final de 'Decis√µes e justificativas' com o porqu√™ de cada escolha.\n",
        "\n",
        "Importante:\n",
        "\n",
        "  1. Texto do racioc√≠nio sempre em portugu√™s do brasil.\n",
        "  2. Estruture o racioc√≠nio em etapas (riscos, liquidez, duration, sensibilidade √† infla√ß√£o).\n",
        "  3. Apresente a recomenda√ß√£o final e uma pol√≠tica de rebalanceamento simples.\n",
        "  4. Use n√∫meros aproximados e justificativas claras.\n",
        "  5. M√°ximo de {total_tokens_resposta} tokens no retorno.\n",
        "\"\"\"\n",
        "\n",
        "# LLM: s√≠ntese direta, sem cadeia expl√≠cita ===\n",
        "modelo_llm, saida_llm, tempo_llm = perguntar_llm(\n",
        "    pergunta=prompt_comum,\n",
        "    sistema=prompt_sistema_comum,\n",
        "    max_tokens_resposta=8192\n",
        ")\n",
        "\n",
        "# Exibe resposta LLM\n",
        "exibir_resposta(\n",
        "    modelo=modelo_llm,\n",
        "    pergunta=prompt_comum,\n",
        "    resposta=saida_llm,\n",
        "    tempo=tempo_llm\n",
        ")\n",
        "\n",
        "# -----\n",
        "\n",
        "# LRM: estrutura com cadeia de racioc√≠nio separada ===\n",
        "modelo_lrm, saida_lrm, cadeia_lrm, tempo_lrm = perguntar_lrm(\n",
        "    pergunta=prompt_comum,\n",
        "    sistema=prompt_sistema_comum,\n",
        "    max_tokens_resposta=2000\n",
        ")\n",
        "\n",
        "# Exibe LRM com racioc√≠nio destacado\n",
        "exibir_resposta(\n",
        "    modelo=modelo_lrm,\n",
        "    pergunta=prompt_comum,\n",
        "    resposta=saida_lrm,\n",
        "    raciocinio=cadeia_lrm,\n",
        "    tempo=tempo_lrm\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HUj2yrlf2BJY",
        "outputId": "627313a2-903d-4fe8-81fc-648851b686f8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## üî¨ Compara√ß√£o LLM vs LRM ‚Äî **mesmo cen√°rio**, pap√©is diferentes"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### üìù Prompt (usu√°rio) enviado *igual* aos dois modelos"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Crie um plano de 6 semanas para lan√ßar um MVP de assistente de atendimento:\n>   \n>   - Backend: APIs j√° existentes.\n>   - Frontend: web app simples.\n>   - Equipe: 2 devs full-stack, 1 QA, 1 PM; sprint semanal.\n>   - Restri√ß√µes: integra√ß√£o com WhatsApp Business na semana 3+; testes de carga na semana 5.\n>   - Entreg√°veis por semana; riscos e mitiga√ß√£o; crit√©rios de aceite."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n## üß† Modelo: `llama3-70b-8192`\n**‚è± Tempo de execu√ß√£o:** 3.06s\n\n\n\n### üì• Pergunta\n\nCrie um plano de 6 semanas para lan√ßar um MVP de assistente de atendimento:\n  \n  - Backend: APIs j√° existentes.\n  - Frontend: web app simples.\n  - Equipe: 2 devs full-stack, 1 QA, 1 PM; sprint semanal.\n  - Restri√ß√µes: integra√ß√£o com WhatsApp Business na semana 3+; testes de carga na semana 5.\n  - Entreg√°veis por semana; riscos e mitiga√ß√£o; crit√©rios de aceite.\n\n### üì§ Resposta\n\n**Plano de 6 semanas para lan√ßar um MVP de assistente de atendimento**\n\n### Decomposi√ß√£o em etapas\n\n1. **Semana 1: Defini√ß√£o de requisitos e planejamento**\n\t* Definir requisitos funcionais e n√£o funcionais do MVP\n\t* Planejar a estrutura do frontend e backend\n\t* Identificar riscos e criar plano de mitiga√ß√£o\n\t* Estabelecer crit√©rios de aceite para cada semana\n\t* Risco: Mudan√ßas nos requisitos funcionais; Mitiga√ß√£o: Reuni√µes di√°rias com a equipe e stakeholders\n2. **Semana 2: Desenvolvimento do frontend**\n\t* Desenvolver a estrutura b√°sica do frontend (HTML, CSS, JS)\n\t* Implementar a l√≥gica de neg√≥cios do assistente de atendimento\n\t* Risco: Complexidade na implementa√ß√£o da l√≥gica de neg√≥cios; Mitiga√ß√£o: Dividir a tarefa em subtarefas menores e revisar o c√≥digo regularmente\n3. **Semana 3: Integra√ß√£o com WhatsApp Business**\n\t* Integrar o frontend com as APIs do WhatsApp Business\n\t* Implementar a l√≥gica de envio e recebimento de mensagens\n\t* Risco: Dificuldades na integra√ß√£o com WhatsApp Business; Mitiga√ß√£o: Contato pr√©vio com a equipe de suporte do WhatsApp Business e testes rigorosos\n4. **Semana 4: Desenvolvimento do backend**\n\t* Desenvolver a l√≥gica de neg√≥cios do backend (APIs)\n\t* Implementar a integra√ß√£o com as APIs existentes\n\t* Risco: Complexidade na implementa√ß√£o da l√≥gica de neg√≥cios; Mitiga√ß√£o: Dividir a tarefa em subtarefas menores e revisar o c√≥digo regularmente\n5. **Semana 5: Testes de carga e ajustes**\n\t* Realizar testes de carga no sistema\n\t* Ajustar a performance do sistema\n\t* Risco: Falha nos testes de carga; Mitiga√ß√£o: Realizar testes de carga incremental e ajustar a performance gradualmente\n6. **Semana 6: Testes finais e deploy**\n\t* Realizar testes finais do sistema\n\t* Deploy do sistema em produ√ß√£o\n\t* Risco: Erros cr√≠ticos no sistema; Mitiga√ß√£o: Realizar testes rigorosos e ter um plano de rollback pronto\n\n### Estimativas simples\n\n* 2 devs full-stack: 80 horas por semana\n* 1 QA: 40 horas por semana\n* 1 PM: 20 horas por semana\n* Capacidade por sprint: 120 horas\n\n### Tabela de riscos\n\n| Risco | Probabilidade | Impacto | Mitiga√ß√£o |\n| --- | --- | --- | --- |\n| Mudan√ßas nos requisitos funcionais | 30% | Alto | Reuni√µes di√°rias com a equipe e stakeholders |\n| Complexidade na implementa√ß√£o da l√≥gica de neg√≥cios | 40% | M√©dio | Dividir a tarefa em subtarefas menores e revisar o c√≥digo regularmente |\n| Dificuldades na integra√ß√£o com WhatsApp Business | 20% | Alto | Contato pr√©vio com a equipe de suporte do WhatsApp Business e testes rigorosos |\n| Falha nos testes de carga | 10% | Alto | Realizar testes de carga incremental e ajustar a performance gradualmente |\n| Erros cr√≠ticos no sistema | 10% | Alto | Realizar testes rigorosos e ter um plano de rollback pronto |\n\n### Crit√©rios de aceite por semana\n\n* Semana 1: Defini√ß√£o de requisitos funcionais e n√£o funcionais do MVP\n* Semana 2: Implementa√ß√£o da l√≥gica de neg√≥cios do frontend\n* Semana 3: Integra√ß√£o com WhatsApp Business\n* Semana 4: Implementa√ß√£o da l√≥gica de neg√≥cios do backend\n* Semana 5: Testes de carga e ajustes\n* Semana 6: Testes finais e deploy\n\n### Formato de checklist por semana\n\n**Semana 1**\n\n* Defini√ß√£o de requisitos funcionais e n√£o funcionais do MVP\n* Planejamento da estrutura do frontend e backend\n* Identifica√ß√£o de riscos e cria√ß√£o de plano de mitiga√ß√£o\n\n**Semana 2**\n\n* Implementa√ß√£o da l√≥gica de neg√≥cios do frontend\n* Revis√£o do c√≥digo e ajustes\n\n**Semana 3**\n\n* Integra√ß√£o com WhatsApp Business\n* Implementa√ß√£o da l√≥gica de envio e recebimento de mensagens\n\n**Semana 4**\n\n* Implementa√ß√£o da l√≥gica de neg√≥cios do backend\n* Integra√ß√£o com as APIs existentes\n\n**Semana 5**\n\n* Testes de carga e ajustes\n* Ajustes na performance do sistema\n\n**Semana 6**\n\n* Testes finais do sistema\n* Deploy do sistema em produ√ß√£o\n\n### Decis√µes e justificativas\n\n* A equipe de desenvolvimento foi dividida em duas para trabalhar em paralelo no frontend e backend, para reduzir o tempo de desenvolvimento.\n* A integra√ß√£o com WhatsApp Business foi priorizada para a semana 3, pois √© um requisito cr√≠tico para o MVP.\n* Os testes de carga foram agendados para a semana 5, para garantir que o sistema esteja pronto para o deploy.\n* A equipe de QA foi designada para realizar testes rigorosos em todas as semanas, para garantir a qualidade do sistema.\n* O PM foi designado para gerenciar o projeto e garantir que os crit√©rios de aceite sejam atendidos em cada semana.\n    "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n## üß† Modelo: `deepseek-r1-distill-llama-70b`\n**‚è± Tempo de execu√ß√£o:** 7.35s\n\n\n\n## üßê Racioc√≠nio                                \n================================================\n\nOkay, I need to create a 6-week plan to launch an MVP for a customer service assistant. The user has provided specific details about the team, technologies, and constraints, so I should structure the plan accordingly.\n\nFirst, I'll break down the project into weekly sprints. Each sprint should have clear objectives, deliverables, and considerations for risks and dependencies. Since the backend uses existing APIs, that should save some time, but the frontend is a new web app, so I'll need to allocate time for that.\n\nThe team consists of 2 full-stack devs, 1 QA, and 1 PM. That means development can be parallelized, but I need to ensure tasks are distributed efficiently. The PM will handle coordination, so that's a plus for keeping things on track.\n\nLooking at the constraints, integration with WhatsApp Business starts from week 3 onwards, and load testing is in week 5. These are critical points because delays here could affect the entire timeline. I should plan for contingencies around these areas.\n\nI'll start by outlining each week with specific goals. Week 1 should focus on project setup and initial planning. The PM sets up the environment, defines the backlog, and the team finalizes the MVP scope. Risks here might include scope creep, so keeping the scope small is key.\n\nIn Week 2, the frontend development begins. The devs will work on the basic UI/UX, and the QA starts drafting test cases. The risk here is design issues, so regular feedback sessions can mitigate that.\n\nWeek 3 is when the WhatsApp integration starts. The backend team will handle the API integration while the frontend continues with advanced features. The risk is API compatibility issues, so having a backup plan is essential.\n\nWeek 4 focuses on connecting the frontend and backend. The QA does system testing, and the PM ensures everything is on track. The risk here is integration bugs, so thorough testing is crucial.\n\nWeek 5 is for performance testing. The team conducts load tests and optimizes the system. The risk is discovering scalability issues late, so starting early and iterating quickly is important.\n\nFinally, Week 6 is the preparation for launch. The team deploys the MVP, sets up monitoring, and gets ready for user feedback. The risk is deployment issues, so a rollback plan is necessary.\n\nI'll also outline the estimated hours per role to ensure the workload is manageable. The PM has consistent hours each week, while devs and QA have varying loads depending on the sprint.\n\nFor risks, I'll create a table assessing probability, impact, and mitigation strategies. The critical path includes WhatsApp integration and frontend development, as delays here would directly impact the launch.\n\nThe acceptance criteria should be clear each week, ensuring that each sprint delivers functional and tested features. This helps in maintaining quality and meeting deadlines.\n\nIn the end, I'll summarize the decisions made, like starting with the MVP scope to avoid delays, integrating early with WhatsApp to handle issues sooner, and prioritizing performance testing to ensure scalability.\n\nOverall, the plan balances development, testing, and integration with clear risk management strategies to ensure the MVP launches successfully within six weeks.\n\n### üì• Pergunta\n\nCrie um plano de 6 semanas para lan√ßar um MVP de assistente de atendimento:\n  \n  - Backend: APIs j√° existentes.\n  - Frontend: web app simples.\n  - Equipe: 2 devs full-stack, 1 QA, 1 PM; sprint semanal.\n  - Restri√ß√µes: integra√ß√£o com WhatsApp Business na semana 3+; testes de carga na semana 5.\n  - Entreg√°veis por semana; riscos e mitiga√ß√£o; crit√©rios de aceite.\n\n### üì§ Resposta\n\n### Plano de 6 Semanas para Lan√ßar MVP de Assistente de Atendimento\n\n#### 1) Decomposi√ß√£o em Etapas (Depend√™ncias, Riscos, Trade-offs)\n\n| Semana | Etapa                          | Depend√™ncias                     | Riscos                                      | Trade-offs                                   |\n|--------|--------------------------------|----------------------------------|---------------------------------------------|----------------------------------------------|\n| 1      | Setup do Projeto e Planejamento | Defini√ß√£o do escopo MVP         | Atraso na defini√ß√£o do escopo                | Priorizar funcionalidades essenciais         |\n| 2      | Desenvolvimento Frontend B√°sico | Conclus√£o da semana 1            | Dificuldade na implementa√ß√£o da UI/UX       | Simplificar a interface para agilizar o desenvolvimento |\n| 3      | Integra√ß√£o com WhatsApp Business | Conclus√£o da semana 2           | Problemas de compatibilidade com a API do WhatsApp | Testar em ambiente de homologa√ß√£o antes de deploy |\n| 4      | Conex√£o Frontend-Backend        | Conclus√£o da semana 3            | Erros de integra√ß√£o                         | Focar em testes unit√°rios e de integra√ß√£o     |\n| 5      | Testes de Carga e Otimiza√ß√£o   | Conclus√£o da semana 4            | Descoberta tardia de problemas de performance | Realizar testes incrementais desde cedo       |\n| 6      | Prepara√ß√£o para Lan√ßamento      | Conclus√£o da semana 5            | Problemas de deploy                          | Realizar deploy gradual e ter plano de rollback |\n\n#### 2) Estimativas Simples\n\n| Papel           | Hrs Semana 1 | Hrs Semana 2 | Hrs Semana 3 | Hrs Semana 4 | Hrs Semana 5 | Hrs Semana 6 |\n|-----------------|--------------|--------------|--------------|--------------|--------------|--------------|\n| Dev Full-Stack  | 40           | 40           | 40           | 40           | 40           | 20           |\n| QA              | 20           | 20           | 20           | 20           | 40           | 20           |\n| PM              | 20           | 20           | 20           | 20           | 20           | 20           |\n\n**Capacidade por Sprint:**  \n- **Desenvolvedores:** 80 hrs/semana  \n- **QA:** 20 hrs/semana (aumenta para 40 na semana 5)  \n- **PM:** 20 hrs/semana  \n\n**Margens de Seguran√ßa:**  \n- Desenvolvedores: 10% de folga  \n- QA: 20% de folga  \n\n#### 3) Tabela de Riscos\n\n| Risco                              | Probabilidade | Impacto | Mitiga√ß√£o                                      |\n|-------------------------------------|---------------|---------|------------------------------------------------|\n| Atraso na defini√ß√£o do escopo MVP   | Alta          | Alto    | Workshop de defini√ß√£o de escopo na semana 1     |\n| Dificuldade na implementa√ß√£o da UI/UX | M√©dia        | M√©dio   | Feedback constante com o time de UX            |\n| Problemas de compatibilidade com WhatsApp | Alta | Alto | Testar em ambiente de homologa√ß√£o antes do deploy |\n| Erros de integra√ß√£o                 | M√©dia         | M√©dio   | Realizar testes de integra√ß√£o cont√≠nuos         |\n| Descoberta tardia de problemas de performance | Baixa | Alto | Realizar testes de carga incrementais desde cedo |\n| Problemas de deploy                  | Baixa        | M√©dio   | Realizar deploy gradual e ter plano de rollback |\n\n**Caminho Cr√≠tico:**  \n1. Integra√ß√£o com WhatsApp Business (Semana 3)  \n2. Desenvolvimento Frontend B√°sico (Semana 2)  \n3. Testes de Carga (Semana 5)  \n\n#### 4) Crit√©rios de Aceite Objetivos por Semana\n\n| Semana | Crit√©rios de Aceite                                                                 |\n|--------|-------------------------------------------------------------------------------------|\n| 1      | Escopo MVP definido e aprovado; Ambiente de desenvolvimento configurado               |\n| 2      | Funcionalidades b√°sicas do frontend implementadas e testadas                           |\n| 3      | Integra√ß√£o com WhatsApp Business funcional em ambiente de homologa√ß√£o                |\n| 4      | Frontend conectado ao backend com testes de integra√ß√£o bem-sucedidos                  |\n| 5      | Testes de carga aprovados; Sistema otimizado para 1000 usu√°rios simult√¢neos            |\n| 6      | MVP deployado em produ√ß√£o; Documenta√ß√£o finalizada; Monitoramento configurado         |\n\n#### 5) Formato de Semanas com Checklist Objetivo\n\n| Semana | Checklist                                                                 |\n|--------|-----------------------------------------------------------------------------|\n| 1      | - Escopo MVP definido e aprovado<br>- Ambiente de desenvolvimento configurado |\n| 2      | - Funcionalidades b√°sicas do frontend implementadas e testadas                |\n| 3      | - Integra√ß√£o com WhatsApp Business funcional em homologa√ß√£o                  |\n| 4      | - Frontend conectado ao backend com testes de integra√ß√£o                      |\n| 5      | - Testes de carga aprovados; Sistema otimizado                                |\n| 6      | - MVP deployado em produ√ß√£o; Documenta√ß√£o finalizada; Monitoramento configurado |\n\n### Decis√µes e Justificativas\n\n1. **Prioriza√ß√£o do Escopo MVP na Semana 1:**  \n   - Justificativa: √â crucial definir claramente o que ser√° entregue no MVP para evitar escopo creep e garantir que todos estejam alinhados.\n\n2. **In√≠cio da Integra√ß√£o com WhatsApp Business na Semana 3:**  \n   - Justificativa: A integra√ß√£o com o WhatsApp Business √© um ponto cr√≠tico e pode ter problemas n√£o previstos, ent√£o √© importante come√ßar cedo para ter tempo de resolver problemas.\n\n3. **Realiza√ß√£o de Testes de Carga na Semana 5:**  \n   - Justificativa: Testes de carga s√£o essenciais para garantir que o sistema suporte o tr√°fego esperado. Realiz√°-los tarde dem\n    "
          },
          "metadata": {}
        }
      ]
    }
  ]
}