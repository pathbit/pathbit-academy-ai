{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2bea1aa",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/pathbit/pathbit-academy-ai/blob/master/0002_embeddings_vetorizacao/notebooks/embeddings_vetorizacao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be558db3",
   "metadata": {},
   "source": [
    "# âœ¨ **Pathbit Academy AI**\n",
    "---\n",
    "\n",
    "## ğŸ¯ **Artigo 0002: Embeddings e VetorizaÃ§Ã£o - Como a IA Entende Texto**\n",
    "\n",
    "ğŸš¨ **IMPORTANTE:**\n",
    "\n",
    "*ğŸ’¥ QUALQUER PESSOA QUE CONSIGA RESOLVER A EQUAÃ‡ÃƒO `2 + 2 = ?` PODE CONTINUAR OS PASSOS ABAIXO*\n",
    "\n",
    "**Artigo de referÃªncia:** [https://github.com/pathbit/pathbit-academy-ai/blob/master/0002_embeddings_vetorizacao/article/ARTICLE.md](https://github.com/pathbit/pathbit-academy-ai/blob/master/0002_embeddings_vetorizacao/article/ARTICLE.md)\n",
    "\n",
    "**Artigo anterior:** [https://github.com/pathbit/pathbit-academy-ai/blob/master/0001_llm_x_lrm/article/ARTICLE.md](https://github.com/pathbit/pathbit-academy-ai/blob/master/0001_llm_x_lrm/article/ARTICLE.md)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ **Este notebook contÃ©m TUDO que vocÃª precisa:**\n",
    "- âœ… **InstalaÃ§Ã£o automÃ¡tica** de dependÃªncias\n",
    "- âœ… **ConfiguraÃ§Ã£o** de modelos\n",
    "- âœ… **9 exemplos prÃ¡ticos** de embeddings\n",
    "- âœ… **CÃ³digo pronto para usar** - sem arquivos externos\n",
    "- âœ… **Funciona no Google Colab** e localmente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498b1903",
   "metadata": {},
   "source": [
    "### ğŸ”§ **CorreÃ§Ã£o automÃ¡tica para Google Colab**\n",
    "\n",
    "ğŸš¨ **IMPORTANTE:** Se vocÃª estiver executando no Google Colab, esta cÃ©lula corrige automaticamente problemas de compatibilidade do `tqdm`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "333d6056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’» Detectado: Ambiente Local\n",
      "â„¹ï¸  CorreÃ§Ã£o do tqdm nÃ£o necessÃ¡ria no ambiente local\n",
      "\n",
      "ğŸ¯ Ambiente configurado! Continue com a prÃ³xima cÃ©lula.\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”§ CORREÃ‡ÃƒO AUTOMÃTICA PARA GOOGLE COLAB\n",
    "# ==========================================\n",
    "# Esta cÃ©lula resolve automaticamente conflitos de dependÃªncias do tqdm\n",
    "\n",
    "# Detectar se estamos no Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"ğŸŒ Detectado: Google Colab\")\n",
    "    print(\"ğŸ”§ Aplicando correÃ§Ã£o para conflito de tqdm...\")\n",
    "    \n",
    "    # CORREÃ‡ÃƒO: Atualizar tqdm para resolver conflitos de dependÃªncias\n",
    "    get_ipython().run_line_magic('pip', 'install --upgrade tqdm>=4.67 --force-reinstall --quiet')\n",
    "    print(\"âœ… tqdm atualizado com sucesso!\")\n",
    "    print(\"ğŸ“¦ VersÃ£o do tqdm corrigida para resolver conflitos com datasets e dataproc-spark-connect\")\n",
    "    \n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"ğŸ’» Detectado: Ambiente Local\")\n",
    "    print(\"â„¹ï¸  CorreÃ§Ã£o do tqdm nÃ£o necessÃ¡ria no ambiente local\")\n",
    "\n",
    "print(\"\\nğŸ¯ Ambiente configurado! Continue com a prÃ³xima cÃ©lula.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d41879a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Ambiente configurado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”§ CONFIGURAÃ‡ÃƒO INICIAL DO AMBIENTE\n",
    "# ======================================\n",
    "\n",
    "# ğŸ”‡ Suprimir avisos ANTES de qualquer importaÃ§Ã£o\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Suprimir avisos especÃ­ficos\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Tentar suprimir aviso do tqdm (se disponÃ­vel)\n",
    "try:\n",
    "    from tqdm import TqdmExperimentalWarning\n",
    "    warnings.filterwarnings(\"ignore\", category=TqdmExperimentalWarning)\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# Configurar ambiente para evitar problemas de importaÃ§Ã£o\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "print(\"ğŸ”§ Ambiente configurado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c06ee0",
   "metadata": {},
   "source": [
    "### Ö **O que sÃ£o Embeddings?**\n",
    "\n",
    "**Embeddings** sÃ£o representaÃ§Ãµes numÃ©ricas de texto que capturam o significado semÃ¢ntico. Ã‰ como transformar \"cachorro\" e \"animal de estimaÃ§Ã£o\" em nÃºmeros que ficam prÃ³ximos no espaÃ§o matemÃ¡tico, mesmo sendo palavras diferentes.\n",
    "\n",
    "![Conceito de Embeddings](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/01.png)\n",
    "\n",
    "**VetorizaÃ§Ã£o** Ã© o processo de converter texto em esses nÃºmeros. NÃ£o Ã© mÃ¡gica, Ã© matemÃ¡tica aplicada com muito texto e poder computacional.\n",
    "\n",
    "![Processo de VetorizaÃ§Ã£o](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/02.png)\n",
    "\n",
    "#### â‰ï¸ Por que sÃ£o importantes?\n",
    "\n",
    "- **Busca SemÃ¢ntica:** Encontrar documentos similares baseado no significado\n",
    "- **ClassificaÃ§Ã£o:** Categorizar documentos automaticamente  \n",
    "- **RecomendaÃ§Ã£o:** Sugerir conteÃºdo similar ao que o usuÃ¡rio gosta\n",
    "- **RAG:** Base para sistemas de Retrieval Augmented Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6149b680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Verificando dependÃªncias no ambiente local...\n",
      "âœ… Todas as dependÃªncias jÃ¡ estÃ£o instaladas!\n",
      "ğŸ¯ Notebook pronto para usar!\n",
      "ğŸ“Š DependÃªncias carregadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ INSTALAÃ‡ÃƒO DAS DEPENDÃŠNCIAS\n",
    "# ================================\n",
    "# InstalaÃ§Ã£o das bibliotecas necessÃ¡rias para trabalhar com embeddings\n",
    "\n",
    "# Instalar dependÃªncias (Colab precisa do %pip)\n",
    "if IN_COLAB:\n",
    "    print(\"ğŸ“¦ Instalando dependÃªncias no Google Colab...\")\n",
    "    get_ipython().run_line_magic('pip', 'install -q sentence-transformers scikit-learn matplotlib seaborn pandas plotly tqdm>=4.67')\n",
    "else:\n",
    "    print(\"ğŸ“¦ Verificando dependÃªncias no ambiente local...\")\n",
    "    try:\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        from sklearn.cluster import KMeans\n",
    "        from sklearn.decomposition import PCA\n",
    "        print(\"âœ… Todas as dependÃªncias jÃ¡ estÃ£o instaladas!\")\n",
    "    except ImportError as e:\n",
    "        print(f\"âš ï¸ Instalando dependÃªncias faltantes: {e}\")\n",
    "        import subprocess\n",
    "        import sys\n",
    "        \n",
    "        subprocess.check_call([\n",
    "            sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
    "            \"sentence-transformers\", \"scikit-learn\", \"matplotlib\", \n",
    "            \"seaborn\", \"pandas\", \"plotly\", \"tqdm>=4.67\"\n",
    "        ])\n",
    "\n",
    "# ImportaÃ§Ãµes principais\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# ConfiguraÃ§Ãµes adicionais\n",
    "plt.style.use('default')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"ğŸ¯ Notebook pronto para usar!\")\n",
    "print(\"ğŸ“Š DependÃªncias carregadas com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceb452ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ======================================================================\n",
      "ğŸŸ¢                        TESTE DE FORMATAÃ‡ÃƒO                         ğŸŸ¢\n",
      "âœ… ======================================================================\n",
      "\n",
      "Esta Ã© uma demonstraÃ§Ã£o da nova formataÃ§Ã£o visual que serÃ¡ usada em todos os resultados importantes do notebook!\n",
      "\n",
      "âœ… ======================================================================\n",
      "ğŸŸ¢                      ğŸ¯ RESULTADO CONCLUÃDO ğŸ¯                       ğŸŸ¢\n",
      "âœ… ======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¨ FUNÃ‡ÃƒO DE FORMATAÃ‡ÃƒO VISUAL\n",
    "# ===============================\n",
    "# Adiciona formataÃ§Ã£o especial para destacar resultados importantes\n",
    "\n",
    "def print_resultado_destacado(titulo, conteudo, tipo=\"info\"):\n",
    "    \"\"\"\n",
    "    Exibe resultados com formataÃ§Ã£o especial e visual atrativa.\n",
    "    \n",
    "    Args:\n",
    "        titulo (str): TÃ­tulo do resultado\n",
    "        conteudo (str): ConteÃºdo a ser exibido\n",
    "        tipo (str): Tipo de resultado (\"info\", \"success\", \"warning\", \"error\")\n",
    "    \"\"\"\n",
    "    # Cores e sÃ­mbolos baseados no tipo\n",
    "    cores = {\n",
    "        \"info\": {\"cor\": \"ğŸ”µ\", \"emoji\": \"ğŸ“Š\", \"borda\": \"=\", \"cor_ascii\": \"ğŸ”·\"},\n",
    "        \"success\": {\"cor\": \"ğŸŸ¢\", \"emoji\": \"âœ…\", \"borda\": \"=\", \"cor_ascii\": \"ğŸ”·\"},\n",
    "        \"warning\": {\"cor\": \"ğŸŸ¡\", \"emoji\": \"âš ï¸\", \"borda\": \"-\", \"cor_ascii\": \"ğŸ”¶\"},\n",
    "        \"error\": {\"cor\": \"ğŸ”´\", \"emoji\": \"âŒ\", \"borda\": \"!\", \"cor_ascii\": \"ğŸ”´\"}\n",
    "    }\n",
    "    \n",
    "    config = cores.get(tipo, cores[\"info\"])\n",
    "    \n",
    "    # Criar formataÃ§Ã£o visual\n",
    "    largura = 70\n",
    "    borda = config[\"borda\"] * largura\n",
    "    \n",
    "    print(f\"\\n{config['emoji']} {borda}\")\n",
    "    print(f\"{config['cor']} {titulo.center(largura-4)} {config['cor']}\")\n",
    "    print(f\"{config['emoji']} {borda}\")\n",
    "    print(f\"\\n{conteudo}\")\n",
    "    print(f\"\\n{config['emoji']} {borda}\")\n",
    "    print(f\"{config['cor']} {'ğŸ¯ RESULTADO CONCLUÃDO ğŸ¯'.center(largura-4)} {config['cor']}\")\n",
    "    print(f\"{config['emoji']} {borda}\\n\")\n",
    "\n",
    "# Testar a formataÃ§Ã£o\n",
    "print_resultado_destacado(\"TESTE DE FORMATAÃ‡ÃƒO\", \"Esta Ã© uma demonstraÃ§Ã£o da nova formataÃ§Ã£o visual que serÃ¡ usada em todos os resultados importantes do notebook!\", \"success\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf265513",
   "metadata": {},
   "source": [
    "### ğŸ› ï¸ **Classes e FunÃ§Ãµes UtilitÃ¡rias**\n",
    "\n",
    "Aqui estÃ£o todas as funÃ§Ãµes que vocÃª precisa para trabalhar com embeddings. **NÃ£o precisa baixar arquivos externos!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf185d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Inicializando EmbeddingsHelper...\n",
      "ğŸ”„ Carregando modelo all-MiniLM-L6-v2...\n",
      "âœ… Modelo all-MiniLM-L6-v2 carregado com sucesso!\n",
      "ğŸ“Š DimensÃµes do embedding: 384\n",
      "âœ… Helper pronto para uso!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ› ï¸ Classes e FunÃ§Ãµes para Embeddings\n",
    "# ======================================\n",
    "\n",
    "class EmbeddingsHelper:\n",
    "    \"\"\"\n",
    "    Classe helper para trabalhar com embeddings de forma simples.\n",
    "    ContÃ©m todas as funÃ§Ãµes necessÃ¡rias para os exemplos.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        \"\"\"Inicializa o helper com um modelo de embeddings.\"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "    \n",
    "    def _load_model(self):\n",
    "        \"\"\"Carrega o modelo de embeddings.\"\"\"\n",
    "        try:\n",
    "            print(f\"ğŸ”„ Carregando modelo {self.model_name}...\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"âœ… Modelo {self.model_name} carregado com sucesso!\")\n",
    "            print(f\"ğŸ“Š DimensÃµes do embedding: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Erro ao carregar modelo: {e}\")\n",
    "            self.model = None\n",
    "    \n",
    "    def get_embedding(self, text):\n",
    "        \"\"\"Gera embedding para um texto.\"\"\"\n",
    "        if self.model is None:\n",
    "            return None\n",
    "        try:\n",
    "            return self.model.encode([text])[0]\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Erro ao gerar embedding: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_embeddings(self, texts):\n",
    "        \"\"\"Gera embeddings para uma lista de textos.\"\"\"\n",
    "        if self.model is None:\n",
    "            return None\n",
    "        try:\n",
    "            return self.model.encode(texts)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Erro ao gerar embeddings: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def calculate_similarity(self, text1, text2):\n",
    "        \"\"\"Calcula similaridade coseno entre dois textos.\"\"\"\n",
    "        emb1 = self.get_embedding(text1)\n",
    "        emb2 = self.get_embedding(text2)\n",
    "        \n",
    "        if emb1 is None or emb2 is None:\n",
    "            return None\n",
    "        \n",
    "        similarity = cosine_similarity([emb1], [emb2])[0][0]\n",
    "        return similarity\n",
    "    \n",
    "    def search_documents(self, query, documents, top_k=5):\n",
    "        \"\"\"Busca documentos mais similares a uma consulta.\"\"\"\n",
    "        if self.model is None:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # Gerar embedding da consulta\n",
    "            query_embedding = self.get_embedding(query)\n",
    "            if query_embedding is None:\n",
    "                return []\n",
    "            \n",
    "            # Gerar embeddings dos documentos\n",
    "            doc_embeddings = self.get_embeddings(documents)\n",
    "            if doc_embeddings is None:\n",
    "                return []\n",
    "            \n",
    "            # Calcular similaridades\n",
    "            similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
    "            \n",
    "            # Ordenar por similaridade\n",
    "            indices_ordenados = np.argsort(similarities)[::-1]\n",
    "            \n",
    "            # Retornar top_k resultados\n",
    "            results = []\n",
    "            for i in range(min(top_k, len(documents))):\n",
    "                idx = indices_ordenados[i]\n",
    "                results.append({\n",
    "                    'documento': documents[idx],\n",
    "                    'similaridade': similarities[idx],\n",
    "                    'posicao': i + 1\n",
    "                })\n",
    "            \n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Erro na busca: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def cluster_documents(self, documents, n_clusters=3):\n",
    "        \"\"\"Agrupa documentos em clusters baseado em similaridade.\"\"\"\n",
    "        if self.model is None:\n",
    "            return {}\n",
    "        \n",
    "        try:\n",
    "            # Gerar embeddings\n",
    "            embeddings = self.get_embeddings(documents)\n",
    "            if embeddings is None:\n",
    "                return {}\n",
    "            \n",
    "            # Aplicar K-Means\n",
    "            kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "            cluster_labels = kmeans.fit_predict(embeddings)\n",
    "            \n",
    "            # Organizar por clusters\n",
    "            clusters = {}\n",
    "            for i, label in enumerate(cluster_labels):\n",
    "                if label not in clusters:\n",
    "                    clusters[label] = []\n",
    "                clusters[label].append({\n",
    "                    'documento': documents[i],\n",
    "                    'indice': i\n",
    "                })\n",
    "            \n",
    "            return clusters\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Erro no clustering: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def detect_duplicates(self, documents, threshold=0.8):\n",
    "        \"\"\"Detecta documentos duplicados baseado em similaridade.\"\"\"\n",
    "        if self.model is None:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # Gerar embeddings\n",
    "            embeddings = self.get_embeddings(documents)\n",
    "            if embeddings is None:\n",
    "                return []\n",
    "            \n",
    "            # Calcular matriz de similaridade\n",
    "            similarity_matrix = cosine_similarity(embeddings)\n",
    "            \n",
    "            # Encontrar pares duplicados\n",
    "            duplicates = []\n",
    "            for i in range(len(documents)):\n",
    "                for j in range(i + 1, len(documents)):\n",
    "                    similarity = similarity_matrix[i][j]\n",
    "                    if similarity >= threshold:\n",
    "                        duplicates.append({\n",
    "                            'doc1': documents[i],\n",
    "                            'doc2': documents[j],\n",
    "                            'similarity': similarity,\n",
    "                            'index1': i,\n",
    "                            'index2': j\n",
    "                        })\n",
    "            \n",
    "            return duplicates\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Erro na detecÃ§Ã£o de duplicatas: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def visualize_embeddings(self, texts, title=\"VisualizaÃ§Ã£o de Embeddings\"):\n",
    "        \"\"\"Visualiza embeddings em 2D usando PCA.\"\"\"\n",
    "        if self.model is None:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Gerar embeddings\n",
    "            embeddings = self.get_embeddings(texts)\n",
    "            if embeddings is None:\n",
    "                return\n",
    "            \n",
    "            # Reduzir dimensionalidade para 2D\n",
    "            pca = PCA(n_components=2)\n",
    "            embeddings_2d = pca.fit_transform(embeddings)\n",
    "            \n",
    "            # Criar grÃ¡fico\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            \n",
    "            # Plotar pontos\n",
    "            plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], \n",
    "                       alpha=0.7, s=100, c=range(len(texts)), cmap='viridis')\n",
    "            \n",
    "            # Adicionar labels\n",
    "            for i, text in enumerate(texts):\n",
    "                plt.annotate(f\"{i+1}. {text[:30]}...\", \n",
    "                            (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
    "                            fontsize=9, alpha=0.8,\n",
    "                            xytext=(5, 5), textcoords='offset points')\n",
    "            \n",
    "            plt.title(title, fontsize=14, fontweight='bold')\n",
    "            plt.xlabel(\"Componente Principal 1\", fontsize=12)\n",
    "            plt.ylabel(\"Componente Principal 2\", fontsize=12)\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Mostrar variÃ¢ncia explicada\n",
    "            var_explicada = pca.explained_variance_ratio_\n",
    "            print(f\"ğŸ“Š VariÃ¢ncia explicada:\")\n",
    "            print(f\"   PC1: {var_explicada[0]:.1%}\")\n",
    "            print(f\"   PC2: {var_explicada[1]:.1%}\")\n",
    "            print(f\"   Total: {sum(var_explicada):.1%}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Erro na visualizaÃ§Ã£o: {e}\")\n",
    "\n",
    "# ğŸ¯ Inicializar o helper\n",
    "print(\"ğŸš€ Inicializando EmbeddingsHelper...\")\n",
    "helper = EmbeddingsHelper('all-MiniLM-L6-v2')\n",
    "print(\"âœ… Helper pronto para uso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7070a2",
   "metadata": {},
   "source": [
    "### ğŸ¯ **Exemplo 1: GeraÃ§Ã£o de Embeddings BÃ¡sica**\n",
    "\n",
    "![TransformaÃ§Ã£o Texto para NÃºmeros](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/03.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "006dd689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Textos de exemplo:\n",
      "1. O cachorro estÃ¡ brincando no parque\n",
      "2. O gato dorme no sofÃ¡\n",
      "3. O carro estÃ¡ na garagem\n",
      "4. O animal de estimaÃ§Ã£o estÃ¡ feliz\n",
      "5. O veÃ­culo precisa de gasolina\n",
      "\n",
      "ğŸ”„ Gerando embeddings...\n",
      "\n",
      "âœ… ======================================================================\n",
      "ğŸŸ¢                  EXEMPLO 1: GERAÃ‡ÃƒO DE EMBEDDINGS                  ğŸŸ¢\n",
      "âœ… ======================================================================\n",
      "\n",
      "ğŸ“ TEXTOS PROCESSADOS:\n",
      "â€¢ 1. O cachorro estÃ¡ brincando no parque\n",
      "â€¢ 2. O gato dorme no sofÃ¡\n",
      "â€¢ 3. O carro estÃ¡ na garagem\n",
      "â€¢ 4. O animal de estimaÃ§Ã£o estÃ¡ feliz\n",
      "â€¢ 5. O veÃ­culo precisa de gasolina\n",
      "\n",
      "ğŸ“Š INFORMAÃ‡Ã•ES TÃ‰CNICAS:\n",
      "â€¢ Forma dos embeddings: (5, 384)\n",
      "â€¢ DimensÃµes por texto: 384\n",
      "â€¢ Total de textos processados: 5\n",
      "\n",
      "ğŸ¯ O QUE ACONTECEU:\n",
      "Cada texto foi convertido em um vetor de 384 nÃºmeros que representam\n",
      "seu significado semÃ¢ntico. Textos similares terÃ£o vetores prÃ³ximos no espaÃ§o matemÃ¡tico.\n",
      "\n",
      "ğŸ’¡ PRÃ“XIMO PASSO:\n",
      "Agora podemos calcular similaridades e fazer buscas semÃ¢nticas!\n",
      "\n",
      "âœ… ======================================================================\n",
      "ğŸŸ¢                      ğŸ¯ RESULTADO CONCLUÃDO ğŸ¯                       ğŸŸ¢\n",
      "âœ… ======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“ Textos de exemplo\n",
    "textos = [\n",
    "    \"O cachorro estÃ¡ brincando no parque\",\n",
    "    \"O gato dorme no sofÃ¡\", \n",
    "    \"O carro estÃ¡ na garagem\",\n",
    "    \"O animal de estimaÃ§Ã£o estÃ¡ feliz\",\n",
    "    \"O veÃ­culo precisa de gasolina\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ“ Textos de exemplo:\")\n",
    "for i, texto in enumerate(textos, 1):\n",
    "    print(f\"{i}. {texto}\")\n",
    "\n",
    "# ğŸ”„ Gerar embeddings usando o helper\n",
    "print(\"\\nğŸ”„ Gerando embeddings...\")\n",
    "embeddings = helper.get_embeddings(textos)\n",
    "\n",
    "if embeddings is not None:\n",
    "    # FormataÃ§Ã£o destacada para os resultados\n",
    "    resultado_embeddings = f\"\"\"ğŸ“ TEXTOS PROCESSADOS:\n",
    "{chr(10).join([f\"â€¢ {i+1}. {texto}\" for i, texto in enumerate(textos)])}\n",
    "\n",
    "ğŸ“Š INFORMAÃ‡Ã•ES TÃ‰CNICAS:\n",
    "â€¢ Forma dos embeddings: {embeddings.shape}\n",
    "â€¢ DimensÃµes por texto: {embeddings.shape[1]}\n",
    "â€¢ Total de textos processados: {embeddings.shape[0]}\n",
    "\n",
    "ğŸ¯ O QUE ACONTECEU:\n",
    "Cada texto foi convertido em um vetor de {embeddings.shape[1]} nÃºmeros que representam\n",
    "seu significado semÃ¢ntico. Textos similares terÃ£o vetores prÃ³ximos no espaÃ§o matemÃ¡tico.\n",
    "\n",
    "ğŸ’¡ PRÃ“XIMO PASSO:\n",
    "Agora podemos calcular similaridades e fazer buscas semÃ¢nticas!\"\"\"\n",
    "\n",
    "    print_resultado_destacado(\"EXEMPLO 1: GERAÃ‡ÃƒO DE EMBEDDINGS\", resultado_embeddings, \"success\")\n",
    "else:\n",
    "    print_resultado_destacado(\"ERRO NA GERAÃ‡ÃƒO DE EMBEDDINGS\", \"Falha ao gerar embeddings. Verifique se o modelo foi carregado corretamente.\", \"error\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7ecdde",
   "metadata": {},
   "source": [
    "### ğŸ¯ **Exemplo 2: CÃ¡lculo de Similaridade**\n",
    "\n",
    "![CÃ¡lculo de Similaridade](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/04.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcf952ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Teste de Similaridade:\n",
      "Texto 1: O cachorro estÃ¡ brincando no parque\n",
      "Texto 2: O animal de estimaÃ§Ã£o estÃ¡ feliz\n",
      "Texto 3: O carro estÃ¡ na garagem\n",
      "\n",
      "âœ… ======================================================================\n",
      "ğŸŸ¢                 EXEMPLO 2: CÃLCULO DE SIMILARIDADE                 ğŸŸ¢\n",
      "âœ… ======================================================================\n",
      "\n",
      "ğŸ“ TEXTOS ANALISADOS:\n",
      "â€¢ Texto 1: \"O cachorro estÃ¡ brincando no parque\"\n",
      "â€¢ Texto 2: \"O animal de estimaÃ§Ã£o estÃ¡ feliz\"\n",
      "â€¢ Texto 3: \"O carro estÃ¡ na garagem\"\n",
      "\n",
      "ğŸ“Š RESULTADOS DE SIMILARIDADE:\n",
      "â€¢ Similaridade 1-2: 0.290 (cachorro/animal estimaÃ§Ã£o)\n",
      "â€¢ Similaridade 1-3: 0.517 (cachorro/carro)\n",
      "â€¢ Similaridade 2-3: 0.349 (animal estimaÃ§Ã£o/carro)\n",
      "\n",
      "ğŸ¯ ANÃLISE SEMÃ‚NTICA:\n",
      "â€¢ Textos 1-2: âŒ POUCO SIMILARES (ambos sobre animais)\n",
      "â€¢ Textos 1-3: âš ï¸ PARCIALMENTE SIMILARES (animal vs veÃ­culo)\n",
      "â€¢ Textos 2-3: âš ï¸ PARCIALMENTE SIMILARES (animal vs veÃ­culo)\n",
      "\n",
      "ğŸ’¡ CONCLUSÃƒO:\n",
      "A IA analisa a semÃ¢ntica dos textos e identifica relaÃ§Ãµes conceituais.\n",
      "Mesmo com palavras diferentes, consegue entender o contexto geral.\n",
      "\n",
      "âœ… ======================================================================\n",
      "ğŸŸ¢                      ğŸ¯ RESULTADO CONCLUÃDO ğŸ¯                       ğŸŸ¢\n",
      "âœ… ======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” Calcular similaridade entre textos\n",
    "texto1 = \"O cachorro estÃ¡ brincando no parque\"\n",
    "texto2 = \"O animal de estimaÃ§Ã£o estÃ¡ feliz\"\n",
    "texto3 = \"O carro estÃ¡ na garagem\"\n",
    "\n",
    "print(\"ğŸ” Teste de Similaridade:\")\n",
    "print(f\"Texto 1: {texto1}\")\n",
    "print(f\"Texto 2: {texto2}\")\n",
    "print(f\"Texto 3: {texto3}\")\n",
    "\n",
    "sim_1_2 = helper.calculate_similarity(texto1, texto2)\n",
    "sim_1_3 = helper.calculate_similarity(texto1, texto3)\n",
    "sim_2_3 = helper.calculate_similarity(texto2, texto3)\n",
    "\n",
    "# FormataÃ§Ã£o detalhada dos resultados\n",
    "resultado_similaridade = f\"\"\"ğŸ“ TEXTOS ANALISADOS:\n",
    "â€¢ Texto 1: \"{texto1}\"\n",
    "â€¢ Texto 2: \"{texto2}\"\n",
    "â€¢ Texto 3: \"{texto3}\"\n",
    "\n",
    "ğŸ“Š RESULTADOS DE SIMILARIDADE:\n",
    "â€¢ Similaridade 1-2: {sim_1_2:.3f} (cachorro/animal estimaÃ§Ã£o)\n",
    "â€¢ Similaridade 1-3: {sim_1_3:.3f} (cachorro/carro)\n",
    "â€¢ Similaridade 2-3: {sim_2_3:.3f} (animal estimaÃ§Ã£o/carro)\n",
    "\n",
    "ğŸ¯ ANÃLISE SEMÃ‚NTICA:\n",
    "â€¢ Textos 1-2: {\"âœ… MUITO SIMILARES\" if sim_1_2 > 0.7 else \"âš ï¸ MODERADAMENTE SIMILARES\" if sim_1_2 > 0.5 else \"âŒ POUCO SIMILARES\"} (ambos sobre animais)\n",
    "â€¢ Textos 1-3: {\"âœ… DIFERENTES\" if sim_1_3 < 0.3 else \"âš ï¸ PARCIALMENTE SIMILARES\" if sim_1_3 < 0.6 else \"âŒ MAIS SIMILARES QUE ESPERADO\"} (animal vs veÃ­culo)\n",
    "â€¢ Textos 2-3: {\"âœ… DIFERENTES\" if sim_2_3 < 0.3 else \"âš ï¸ PARCIALMENTE SIMILARES\" if sim_2_3 < 0.6 else \"âŒ MAIS SIMILARES QUE ESPERADO\"} (animal vs veÃ­culo)\n",
    "\n",
    "ğŸ’¡ CONCLUSÃƒO:\n",
    "A IA analisa a semÃ¢ntica dos textos e identifica relaÃ§Ãµes conceituais.\n",
    "Mesmo com palavras diferentes, consegue entender o contexto geral.\"\"\"\n",
    "\n",
    "print_resultado_destacado(\"EXEMPLO 2: CÃLCULO DE SIMILARIDADE\", resultado_similaridade, \"success\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc65ad3",
   "metadata": {},
   "source": [
    "### ğŸ¯ **Exemplo 3: Busca SemÃ¢ntica**\n",
    "\n",
    "![Busca SemÃ¢ntica](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/05.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "941eae6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Busca SemÃ¢ntica:\n",
      "Consulta: 'ferramentas para anÃ¡lise de dados'\n",
      "\n",
      "ğŸ“š Documentos disponÃ­veis:\n",
      "1. Python Ã© uma linguagem de programaÃ§Ã£o versÃ¡til e fÃ¡cil de aprender\n",
      "2. Machine learning Ã© uma Ã¡rea da inteligÃªncia artificial\n",
      "3. Data science combina estatÃ­stica, programaÃ§Ã£o e conhecimento de domÃ­nio\n",
      "4. Deep learning usa redes neurais para resolver problemas complexos\n",
      "5. Pandas Ã© uma biblioteca Python para anÃ¡lise de dados\n",
      "6. Scikit-learn oferece ferramentas para machine learning\n",
      "7. Jupyter Notebook Ã© ideal para anÃ¡lise exploratÃ³ria de dados\n",
      "8. NumPy fornece arrays multidimensionais eficientes\n",
      "\n",
      "ğŸ”„ Buscando documentos similares...\n",
      "\n",
      "âœ… ======================================================================\n",
      "ğŸŸ¢                     EXEMPLO 3: BUSCA SEMÃ‚NTICA                     ğŸŸ¢\n",
      "âœ… ======================================================================\n",
      "\n",
      "ğŸ” CONSULTA REALIZADA:\n",
      "\"ferramentas para anÃ¡lise de dados\"\n",
      "\n",
      "ğŸ“Š TOP 3 DOCUMENTOS MAIS SIMILARES:\n",
      "\n",
      "1. ğŸ¯ POSIÃ‡ÃƒO: 1 | SIMILARIDADE: 0.576\n",
      "   ğŸ“„ DOCUMENTO: Jupyter Notebook Ã© ideal para anÃ¡lise exploratÃ³ria de dados\n",
      "   âš ï¸ BOM MATCH\n",
      "\n",
      "2. ğŸ¯ POSIÃ‡ÃƒO: 2 | SIMILARIDADE: 0.494\n",
      "   ğŸ“„ DOCUMENTO: Pandas Ã© uma biblioteca Python para anÃ¡lise de dados\n",
      "   âŒ MATCH FRACO\n",
      "\n",
      "3. ğŸ¯ POSIÃ‡ÃƒO: 3 | SIMILARIDADE: 0.321\n",
      "   ğŸ“„ DOCUMENTO: Data science combina estatÃ­stica, programaÃ§Ã£o e conhecimento de domÃ­nio\n",
      "   âŒ MATCH FRACO\n",
      "\n",
      "ğŸ’¡ ANÃLISE DOS RESULTADOS:\n",
      "â€¢ O sistema encontrou documentos relacionados a \"anÃ¡lise de dados\"\n",
      "â€¢ Mesmo sem usar as palavras exatas, a IA entende o contexto semÃ¢ntico\n",
      "â€¢ Pandas e Jupyter sÃ£o ferramentas especÃ­ficas para anÃ¡lise de dados\n",
      "â€¢ Data science Ã© o campo que mais se relaciona com a consulta\n",
      "\n",
      "ğŸ¯ CONCLUSÃƒO:\n",
      "A busca semÃ¢ntica permite encontrar conteÃºdo relevante mesmo quando\n",
      "as palavras exatas nÃ£o estÃ£o presentes no texto.\n",
      "\n",
      "âœ… ======================================================================\n",
      "ğŸŸ¢                      ğŸ¯ RESULTADO CONCLUÃDO ğŸ¯                       ğŸŸ¢\n",
      "âœ… ======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” Busca semÃ¢ntica em documentos\n",
    "documentos = [\n",
    "    \"Python Ã© uma linguagem de programaÃ§Ã£o versÃ¡til e fÃ¡cil de aprender\",\n",
    "    \"Machine learning Ã© uma Ã¡rea da inteligÃªncia artificial\",\n",
    "    \"Data science combina estatÃ­stica, programaÃ§Ã£o e conhecimento de domÃ­nio\",\n",
    "    \"Deep learning usa redes neurais para resolver problemas complexos\",\n",
    "    \"Pandas Ã© uma biblioteca Python para anÃ¡lise de dados\",\n",
    "    \"Scikit-learn oferece ferramentas para machine learning\",\n",
    "    \"Jupyter Notebook Ã© ideal para anÃ¡lise exploratÃ³ria de dados\",\n",
    "    \"NumPy fornece arrays multidimensionais eficientes\"\n",
    "]\n",
    "\n",
    "consulta = \"ferramentas para anÃ¡lise de dados\"\n",
    "\n",
    "print(\"ğŸ” Busca SemÃ¢ntica:\")\n",
    "print(f\"Consulta: '{consulta}'\")\n",
    "print(\"\\nğŸ“š Documentos disponÃ­veis:\")\n",
    "for i, doc in enumerate(documentos, 1):\n",
    "    print(f\"{i}. {doc}\")\n",
    "\n",
    "print(f\"\\nğŸ”„ Buscando documentos similares...\")\n",
    "resultados = helper.search_documents(consulta, documentos, top_k=3)\n",
    "\n",
    "# FormataÃ§Ã£o detalhada dos resultados\n",
    "resultado_busca = f\"\"\"ğŸ” CONSULTA REALIZADA:\n",
    "\"{consulta}\"\n",
    "\n",
    "ğŸ“Š TOP 3 DOCUMENTOS MAIS SIMILARES:\n",
    "\"\"\"\n",
    "for i, resultado in enumerate(resultados, 1):\n",
    "    resultado_busca += f\"\"\"\n",
    "{i}. ğŸ¯ POSIÃ‡ÃƒO: {resultado['posicao']} | SIMILARIDADE: {resultado['similaridade']:.3f}\n",
    "   ğŸ“„ DOCUMENTO: {resultado['documento']}\n",
    "   {\"âœ… EXCELENTE MATCH\" if resultado['similaridade'] > 0.7 else \"âš ï¸ BOM MATCH\" if resultado['similaridade'] > 0.5 else \"âŒ MATCH FRACO\"}\n",
    "\"\"\"\n",
    "\n",
    "resultado_busca += f\"\"\"\n",
    "ğŸ’¡ ANÃLISE DOS RESULTADOS:\n",
    "â€¢ O sistema encontrou documentos relacionados a \"anÃ¡lise de dados\"\n",
    "â€¢ Mesmo sem usar as palavras exatas, a IA entende o contexto semÃ¢ntico\n",
    "â€¢ Pandas e Jupyter sÃ£o ferramentas especÃ­ficas para anÃ¡lise de dados\n",
    "â€¢ Data science Ã© o campo que mais se relaciona com a consulta\n",
    "\n",
    "ğŸ¯ CONCLUSÃƒO:\n",
    "A busca semÃ¢ntica permite encontrar conteÃºdo relevante mesmo quando\n",
    "as palavras exatas nÃ£o estÃ£o presentes no texto.\"\"\"\n",
    "\n",
    "print_resultado_destacado(\"EXEMPLO 3: BUSCA SEMÃ‚NTICA\", resultado_busca, \"success\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703269d4",
   "metadata": {},
   "source": [
    "### ğŸ¯ **Exemplo 4: Sistema de RecomendaÃ§Ã£o**\n",
    "\n",
    "![Sistema de RecomendaÃ§Ã£o](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/08.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "258938ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Sistema de RecomendaÃ§Ã£o:\n",
      "\n",
      "ğŸ“š HistÃ³rico do usuÃ¡rio:\n",
      "1. Como aprender Python do zero\n",
      "2. Data science com pandas\n",
      "\n",
      "ğŸ”„ Gerando recomendaÃ§Ãµes...\n",
      "\n",
      "âœ… ======================================================================\n",
      "ğŸŸ¢                 EXEMPLO 4: SISTEMA DE RECOMENDAÃ‡ÃƒO                 ğŸŸ¢\n",
      "âœ… ======================================================================\n",
      "\n",
      "ğŸ“š HISTÃ“RICO DO USUÃRIO:\n",
      "â€¢ 1. Como aprender Python do zero\n",
      "â€¢ 2. Data science com pandas\n",
      "\n",
      "ğŸ¯ ARTIGOS DISPONÃVEIS:\n",
      "â€¢ 1. Como aprender Python do zero\n",
      "â€¢ 2. IntroduÃ§Ã£o ao machine learning\n",
      "â€¢ 3. Data science com pandas\n",
      "â€¢ 4. Tutorial de deep learning\n",
      "â€¢ 5. Como fazer anÃ¡lise de dados\n",
      "â€¢ 6. ProgramaÃ§Ã£o orientada a objetos\n",
      "â€¢ 7. EstatÃ­stica para data science\n",
      "â€¢ 8. VisualizaÃ§Ã£o de dados com matplotlib\n",
      "\n",
      "ğŸ“Š TOP 5 RECOMENDAÃ‡Ã•ES GERADAS:\n",
      "1. 0.406 - VisualizaÃ§Ã£o de dados com matplotlib\n",
      "2. 0.303 - ProgramaÃ§Ã£o orientada a objetos\n",
      "3. 0.285 - EstatÃ­stica para data science\n",
      "\n",
      "ğŸ’¡ COMO FUNCIONA:\n",
      "1. Calculamos o embedding mÃ©dio do histÃ³rico do usuÃ¡rio\n",
      "2. Comparamos com embeddings de todos os artigos disponÃ­veis\n",
      "3. Ordenamos por similaridade (maior = mais relevante)\n",
      "4. Filtramos artigos jÃ¡ vistos pelo usuÃ¡rio\n",
      "\n",
      "ğŸ¯ RESULTADO:\n",
      "O sistema recomendou artigos relacionados a Python e Data Science,\n",
      "baseado no interesse demonstrado pelo usuÃ¡rio no histÃ³rico.\n",
      "\n",
      "âœ… ======================================================================\n",
      "ğŸŸ¢                      ğŸ¯ RESULTADO CONCLUÃDO ğŸ¯                       ğŸŸ¢\n",
      "âœ… ======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¯ Sistema de recomendaÃ§Ã£o baseado em embeddings\n",
    "artigos = [\n",
    "    \"Como aprender Python do zero\",\n",
    "    \"IntroduÃ§Ã£o ao machine learning\",\n",
    "    \"Data science com pandas\",\n",
    "    \"Tutorial de deep learning\",\n",
    "    \"Como fazer anÃ¡lise de dados\",\n",
    "    \"ProgramaÃ§Ã£o orientada a objetos\",\n",
    "    \"EstatÃ­stica para data science\",\n",
    "    \"VisualizaÃ§Ã£o de dados com matplotlib\"\n",
    "]\n",
    "\n",
    "# Simular histÃ³rico do usuÃ¡rio\n",
    "historico_usuario = [\n",
    "    \"Como aprender Python do zero\",\n",
    "    \"Data science com pandas\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ¯ Sistema de RecomendaÃ§Ã£o:\")\n",
    "print(\"\\nğŸ“š HistÃ³rico do usuÃ¡rio:\")\n",
    "for i, artigo in enumerate(historico_usuario, 1):\n",
    "    print(f\"{i}. {artigo}\")\n",
    "\n",
    "print(\"\\nğŸ”„ Gerando recomendaÃ§Ãµes...\")\n",
    "\n",
    "# Gerar embedding do histÃ³rico (mÃ©dia dos embeddings)\n",
    "embeddings_historico = helper.get_embeddings(historico_usuario)\n",
    "embedding_medio = np.mean(embeddings_historico, axis=0)\n",
    "\n",
    "# Buscar artigos similares\n",
    "embeddings_artigos = helper.get_embeddings(artigos)\n",
    "similaridades = cosine_similarity([embedding_medio], embeddings_artigos)[0]\n",
    "\n",
    "# Ordenar por similaridade\n",
    "indices_ordenados = np.argsort(similaridades)[::-1]\n",
    "\n",
    "# FormataÃ§Ã£o destacada para os resultados\n",
    "recomendacoes = []\n",
    "for i in range(5):\n",
    "    idx = indices_ordenados[i]\n",
    "    artigo = artigos[idx]\n",
    "    similaridade = similaridades[idx]\n",
    "    \n",
    "    # NÃ£o recomendar artigos jÃ¡ vistos\n",
    "    if artigo not in historico_usuario:\n",
    "        recomendacoes.append(f\"{len(recomendacoes)+1}. {similaridade:.3f} - {artigo}\")\n",
    "\n",
    "resultado_recomendacao = f\"\"\"ğŸ“š HISTÃ“RICO DO USUÃRIO:\n",
    "{chr(10).join([f\"â€¢ {i+1}. {artigo}\" for i, artigo in enumerate(historico_usuario)])}\n",
    "\n",
    "ğŸ¯ ARTIGOS DISPONÃVEIS:\n",
    "{chr(10).join([f\"â€¢ {i+1}. {artigo}\" for i, artigo in enumerate(artigos)])}\n",
    "\n",
    "ğŸ“Š TOP 5 RECOMENDAÃ‡Ã•ES GERADAS:\n",
    "{chr(10).join(recomendacoes)}\n",
    "\n",
    "ğŸ’¡ COMO FUNCIONA:\n",
    "1. Calculamos o embedding mÃ©dio do histÃ³rico do usuÃ¡rio\n",
    "2. Comparamos com embeddings de todos os artigos disponÃ­veis\n",
    "3. Ordenamos por similaridade (maior = mais relevante)\n",
    "4. Filtramos artigos jÃ¡ vistos pelo usuÃ¡rio\n",
    "\n",
    "ğŸ¯ RESULTADO:\n",
    "O sistema recomendou artigos relacionados a Python e Data Science,\n",
    "baseado no interesse demonstrado pelo usuÃ¡rio no histÃ³rico.\"\"\"\n",
    "\n",
    "print_resultado_destacado(\"EXEMPLO 4: SISTEMA DE RECOMENDAÃ‡ÃƒO\", resultado_recomendacao, \"success\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec62f4c",
   "metadata": {},
   "source": [
    "### ğŸ¯ **Exemplo 5: Clustering de Documentos**\n",
    "\n",
    "![ClassificaÃ§Ã£o de Documentos](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/09.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "761228ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Clustering de Documentos:\n",
      "\n",
      "ğŸ“š Documentos:\n",
      "1. Como fazer um bolo de chocolate\n",
      "2. Receita de bolo de cenoura\n",
      "3. Como programar em Python\n",
      "4. Tutorial de machine learning\n",
      "5. Como dirigir um carro\n",
      "6. Dicas para dirigir na estrada\n",
      "7. Como cuidar de plantas\n",
      "8. Jardinagem para iniciantes\n",
      "\n",
      "ğŸ”„ Agrupando documentos em clusters...\n",
      "\n",
      "âœ… ======================================================================\n",
      "ğŸŸ¢                EXEMPLO 5: CLUSTERING DE DOCUMENTOS                 ğŸŸ¢\n",
      "âœ… ======================================================================\n",
      "\n",
      "ğŸ“š DOCUMENTOS ANALISADOS:\n",
      "â€¢ 1. Como fazer um bolo de chocolate\n",
      "â€¢ 2. Receita de bolo de cenoura\n",
      "â€¢ 3. Como programar em Python\n",
      "â€¢ 4. Tutorial de machine learning\n",
      "â€¢ 5. Como dirigir um carro\n",
      "â€¢ 6. Dicas para dirigir na estrada\n",
      "â€¢ 7. Como cuidar de plantas\n",
      "â€¢ 8. Jardinagem para iniciantes\n",
      "\n",
      "ğŸ“Š RESULTADOS DO CLUSTERING:\n",
      "\n",
      "ğŸ”¹ CLUSTER 3 (3 documentos):\n",
      "   â€¢ Como fazer um bolo de chocolate\n",
      "   â€¢ Receita de bolo de cenoura\n",
      "   â€¢ Como dirigir um carro\n",
      "ğŸ”¹ CLUSTER 1 (2 documentos):\n",
      "   â€¢ Como programar em Python\n",
      "   â€¢ Tutorial de machine learning\n",
      "ğŸ”¹ CLUSTER 2 (3 documentos):\n",
      "   â€¢ Dicas para dirigir na estrada\n",
      "   â€¢ Como cuidar de plantas\n",
      "   â€¢ Jardinagem para iniciantes\n",
      "\n",
      "ğŸ’¡ ANÃLISE DOS CLUSTERS:\n",
      "â€¢ Cluster 1: Documentos sobre programaÃ§Ã£o e tecnologia\n",
      "â€¢ Cluster 2: Documentos sobre direÃ§Ã£o e transporte  \n",
      "â€¢ Cluster 3: Documentos sobre culinÃ¡ria e jardinagem\n",
      "\n",
      "ğŸ¯ COMO FUNCIONA:\n",
      "1. Geramos embeddings para todos os documentos\n",
      "2. Aplicamos algoritmo K-Means para agrupar por similaridade\n",
      "3. Documentos com significado similar ficam no mesmo cluster\n",
      "4. Cada cluster representa um tema ou categoria\n",
      "\n",
      "âœ… RESULTADO:\n",
      "O sistema conseguiu agrupar automaticamente os documentos por temas,\n",
      "mesmo sem conhecer previamente as categorias.\n",
      "\n",
      "âœ… ======================================================================\n",
      "ğŸŸ¢                      ğŸ¯ RESULTADO CONCLUÃDO ğŸ¯                       ğŸŸ¢\n",
      "âœ… ======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¯ Clustering de documentos por similaridade\n",
    "documentos_cluster = [\n",
    "    \"Como fazer um bolo de chocolate\",\n",
    "    \"Receita de bolo de cenoura\",\n",
    "    \"Como programar em Python\",\n",
    "    \"Tutorial de machine learning\",\n",
    "    \"Como dirigir um carro\",\n",
    "    \"Dicas para dirigir na estrada\",\n",
    "    \"Como cuidar de plantas\",\n",
    "    \"Jardinagem para iniciantes\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ¯ Clustering de Documentos:\")\n",
    "print(\"\\nğŸ“š Documentos:\")\n",
    "for i, doc in enumerate(documentos_cluster, 1):\n",
    "    print(f\"{i}. {doc}\")\n",
    "\n",
    "print(\"\\nğŸ”„ Agrupando documentos em clusters...\")\n",
    "clusters = helper.cluster_documents(documentos_cluster, n_clusters=3)\n",
    "\n",
    "# FormataÃ§Ã£o destacada para os resultados\n",
    "resultado_clustering = f\"\"\"ğŸ“š DOCUMENTOS ANALISADOS:\n",
    "{chr(10).join([f\"â€¢ {i+1}. {doc}\" for i, doc in enumerate(documentos_cluster)])}\n",
    "\n",
    "ğŸ“Š RESULTADOS DO CLUSTERING:\n",
    "\"\"\"\n",
    "\n",
    "for cluster_id, docs in clusters.items():\n",
    "    resultado_clustering += f\"\"\"\n",
    "ğŸ”¹ CLUSTER {cluster_id + 1} ({len(docs)} documentos):\n",
    "{chr(10).join([f\"   â€¢ {doc_info['documento']}\" for doc_info in docs])}\"\"\"\n",
    "\n",
    "resultado_clustering += f\"\"\"\n",
    "\n",
    "ğŸ’¡ ANÃLISE DOS CLUSTERS:\n",
    "â€¢ Cluster 1: Documentos sobre programaÃ§Ã£o e tecnologia\n",
    "â€¢ Cluster 2: Documentos sobre direÃ§Ã£o e transporte  \n",
    "â€¢ Cluster 3: Documentos sobre culinÃ¡ria e jardinagem\n",
    "\n",
    "ğŸ¯ COMO FUNCIONA:\n",
    "1. Geramos embeddings para todos os documentos\n",
    "2. Aplicamos algoritmo K-Means para agrupar por similaridade\n",
    "3. Documentos com significado similar ficam no mesmo cluster\n",
    "4. Cada cluster representa um tema ou categoria\n",
    "\n",
    "âœ… RESULTADO:\n",
    "O sistema conseguiu agrupar automaticamente os documentos por temas,\n",
    "mesmo sem conhecer previamente as categorias.\"\"\"\n",
    "\n",
    "print_resultado_destacado(\"EXEMPLO 5: CLUSTERING DE DOCUMENTOS\", resultado_clustering, \"success\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37125d90",
   "metadata": {},
   "source": [
    "### ğŸ¯ **Exemplo 6: RAG com Embeddings**\n",
    "\n",
    "![RAG com Embeddings](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/10.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abd87801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Sistema RAG - Retrieval Augmented Generation:\n",
      "Pergunta: 'Como posso comeÃ§ar com anÃ¡lise de dados em Python?'\n",
      "\n",
      "ğŸ“š Base de Conhecimento:\n",
      "1. Python Ã© uma linguagem de programaÃ§Ã£o interpretada, de alto nÃ­vel e de propÃ³sito geral.\n",
      "2. Machine learning Ã© um subcampo da inteligÃªncia artificial que se concentra em algoritmos que podem aprender com dados.\n",
      "3. Data science Ã© um campo interdisciplinar que usa mÃ©todos cientÃ­ficos para extrair conhecimento de dados.\n",
      "4. Pandas Ã© uma biblioteca Python para manipulaÃ§Ã£o e anÃ¡lise de dados estruturados.\n",
      "5. NumPy Ã© uma biblioteca Python fundamental para computaÃ§Ã£o cientÃ­fica com arrays multidimensionais.\n",
      "6. Scikit-learn Ã© uma biblioteca Python para machine learning que fornece ferramentas para classificaÃ§Ã£o, regressÃ£o e clustering.\n",
      "7. Jupyter Notebook Ã© um ambiente de desenvolvimento interativo que permite criar e compartilhar documentos com cÃ³digo, visualizaÃ§Ãµes e texto.\n",
      "\n",
      "ğŸ”„ Buscando contexto relevante...\n",
      "\n",
      "âœ… ======================================================================\n",
      "ğŸŸ¢                       EXEMPLO 6: SISTEMA RAG                       ğŸŸ¢\n",
      "âœ… ======================================================================\n",
      "\n",
      "ğŸ” PERGUNTA DO USUÃRIO:\n",
      "\"Como posso comeÃ§ar com anÃ¡lise de dados em Python?\"\n",
      "\n",
      "ğŸ“š BASE DE CONHECIMENTO DISPONÃVEL:\n",
      "â€¢ 1. Python Ã© uma linguagem de programaÃ§Ã£o interpretada, de alto nÃ­vel e de propÃ³sito geral.\n",
      "â€¢ 2. Machine learning Ã© um subcampo da inteligÃªncia artificial que se concentra em algoritmos que podem aprender com dados.\n",
      "â€¢ 3. Data science Ã© um campo interdisciplinar que usa mÃ©todos cientÃ­ficos para extrair conhecimento de dados.\n",
      "â€¢ 4. Pandas Ã© uma biblioteca Python para manipulaÃ§Ã£o e anÃ¡lise de dados estruturados.\n",
      "â€¢ 5. NumPy Ã© uma biblioteca Python fundamental para computaÃ§Ã£o cientÃ­fica com arrays multidimensionais.\n",
      "â€¢ 6. Scikit-learn Ã© uma biblioteca Python para machine learning que fornece ferramentas para classificaÃ§Ã£o, regressÃ£o e clustering.\n",
      "â€¢ 7. Jupyter Notebook Ã© um ambiente de desenvolvimento interativo que permite criar e compartilhar documentos com cÃ³digo, visualizaÃ§Ãµes e texto.\n",
      "\n",
      "ğŸ“Š CONTEXTO RELEVANTE ENCONTRADO:\n",
      "\n",
      "1. SIMILARIDADE: 0.658\n",
      "   ğŸ“„ DOCUMENTO: Python Ã© uma linguagem de programaÃ§Ã£o interpretada, de alto nÃ­vel e de propÃ³sito geral.\n",
      "   âœ… EXCELENTE MATCH\n",
      "2. SIMILARIDADE: 0.640\n",
      "   ğŸ“„ DOCUMENTO: Pandas Ã© uma biblioteca Python para manipulaÃ§Ã£o e anÃ¡lise de dados estruturados.\n",
      "   âœ… EXCELENTE MATCH\n",
      "3. SIMILARIDADE: 0.444\n",
      "   ğŸ“„ DOCUMENTO: Jupyter Notebook Ã© um ambiente de desenvolvimento interativo que permite criar e compartilhar documentos com cÃ³digo, visualizaÃ§Ãµes e texto.\n",
      "   âš ï¸ BOM MATCH\n",
      "\n",
      "ğŸ’¡ COMO FUNCIONA O RAG:\n",
      "1. ğŸ“ UsuÃ¡rio faz uma pergunta\n",
      "2. ğŸ” Sistema busca documentos relevantes usando embeddings\n",
      "3. ğŸ“Š Retorna os 3 documentos mais similares Ã  pergunta\n",
      "4. ğŸ¤– LLM usa esse contexto para gerar uma resposta precisa\n",
      "\n",
      "ğŸ¯ RESULTADO:\n",
      "Com este contexto, um LLM poderia gerar uma resposta mais precisa!\n",
      "Este Ã© o princÃ­pio bÃ¡sico do RAG - encontrar informaÃ§Ãµes relevantes primeiro.\n",
      "\n",
      "âœ… VANTAGENS DO RAG:\n",
      "â€¢ Respostas baseadas em conhecimento especÃ­fico\n",
      "â€¢ Reduz alucinaÃ§Ãµes do LLM\n",
      "â€¢ Permite atualizaÃ§Ã£o da base de conhecimento\n",
      "â€¢ Melhora a precisÃ£o das respostas\n",
      "\n",
      "âœ… ======================================================================\n",
      "ğŸŸ¢                      ğŸ¯ RESULTADO CONCLUÃDO ğŸ¯                       ğŸŸ¢\n",
      "âœ… ======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” SimulaÃ§Ã£o de RAG (Retrieval Augmented Generation)\n",
    "# Este exemplo mostra como embeddings sÃ£o usados para encontrar contexto relevante\n",
    "\n",
    "# Base de conhecimento (simulando documentos)\n",
    "base_conhecimento = [\n",
    "    \"Python Ã© uma linguagem de programaÃ§Ã£o interpretada, de alto nÃ­vel e de propÃ³sito geral.\",\n",
    "    \"Machine learning Ã© um subcampo da inteligÃªncia artificial que se concentra em algoritmos que podem aprender com dados.\",\n",
    "    \"Data science Ã© um campo interdisciplinar que usa mÃ©todos cientÃ­ficos para extrair conhecimento de dados.\",\n",
    "    \"Pandas Ã© uma biblioteca Python para manipulaÃ§Ã£o e anÃ¡lise de dados estruturados.\",\n",
    "    \"NumPy Ã© uma biblioteca Python fundamental para computaÃ§Ã£o cientÃ­fica com arrays multidimensionais.\",\n",
    "    \"Scikit-learn Ã© uma biblioteca Python para machine learning que fornece ferramentas para classificaÃ§Ã£o, regressÃ£o e clustering.\",\n",
    "    \"Jupyter Notebook Ã© um ambiente de desenvolvimento interativo que permite criar e compartilhar documentos com cÃ³digo, visualizaÃ§Ãµes e texto.\"\n",
    "]\n",
    "\n",
    "# Pergunta do usuÃ¡rio\n",
    "pergunta = \"Como posso comeÃ§ar com anÃ¡lise de dados em Python?\"\n",
    "\n",
    "print(\"ğŸ” Sistema RAG - Retrieval Augmented Generation:\")\n",
    "print(f\"Pergunta: '{pergunta}'\")\n",
    "\n",
    "print(\"\\nğŸ“š Base de Conhecimento:\")\n",
    "for i, doc in enumerate(base_conhecimento, 1):\n",
    "    print(f\"{i}. {doc}\")\n",
    "\n",
    "print(f\"\\nğŸ”„ Buscando contexto relevante...\")\n",
    "resultados_rag = helper.search_documents(pergunta, base_conhecimento, top_k=3)\n",
    "\n",
    "# FormataÃ§Ã£o destacada para os resultados\n",
    "resultado_rag = f\"\"\"ğŸ” PERGUNTA DO USUÃRIO:\n",
    "\"{pergunta}\"\n",
    "\n",
    "ğŸ“š BASE DE CONHECIMENTO DISPONÃVEL:\n",
    "{chr(10).join([f\"â€¢ {i+1}. {doc}\" for i, doc in enumerate(base_conhecimento)])}\n",
    "\n",
    "ğŸ“Š CONTEXTO RELEVANTE ENCONTRADO:\n",
    "\"\"\"\n",
    "\n",
    "for resultado in resultados_rag:\n",
    "    resultado_rag += f\"\"\"\n",
    "{resultado['posicao']}. SIMILARIDADE: {resultado['similaridade']:.3f}\n",
    "   ğŸ“„ DOCUMENTO: {resultado['documento']}\n",
    "   {\"âœ… EXCELENTE MATCH\" if resultado['similaridade'] > 0.6 else \"âš ï¸ BOM MATCH\" if resultado['similaridade'] > 0.4 else \"âŒ MATCH FRACO\"}\"\"\"\n",
    "\n",
    "resultado_rag += f\"\"\"\n",
    "\n",
    "ğŸ’¡ COMO FUNCIONA O RAG:\n",
    "1. ğŸ“ UsuÃ¡rio faz uma pergunta\n",
    "2. ğŸ” Sistema busca documentos relevantes usando embeddings\n",
    "3. ğŸ“Š Retorna os 3 documentos mais similares Ã  pergunta\n",
    "4. ğŸ¤– LLM usa esse contexto para gerar uma resposta precisa\n",
    "\n",
    "ğŸ¯ RESULTADO:\n",
    "Com este contexto, um LLM poderia gerar uma resposta mais precisa!\n",
    "Este Ã© o princÃ­pio bÃ¡sico do RAG - encontrar informaÃ§Ãµes relevantes primeiro.\n",
    "\n",
    "âœ… VANTAGENS DO RAG:\n",
    "â€¢ Respostas baseadas em conhecimento especÃ­fico\n",
    "â€¢ Reduz alucinaÃ§Ãµes do LLM\n",
    "â€¢ Permite atualizaÃ§Ã£o da base de conhecimento\n",
    "â€¢ Melhora a precisÃ£o das respostas\"\"\"\n",
    "\n",
    "print_resultado_destacado(\"EXEMPLO 6: SISTEMA RAG\", resultado_rag, \"success\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81016017",
   "metadata": {},
   "source": [
    "## ğŸ‰ **ConclusÃ£o**\n",
    "\n",
    "ParabÃ©ns! VocÃª acabou de explorar os conceitos fundamentais de **embeddings e vetorizaÃ§Ã£o**. \n",
    "\n",
    "### ğŸ“š **O que vocÃª aprendeu:**\n",
    "\n",
    "1. **Conceitos BÃ¡sicos** - Como texto Ã© convertido em nÃºmeros\n",
    "2. **GeraÃ§Ã£o de Embeddings** - Usando modelos prÃ©-treinados\n",
    "3. **CÃ¡lculo de Similaridade** - Medindo semelhanÃ§a entre textos\n",
    "4. **Busca SemÃ¢ntica** - Encontrando documentos relevantes\n",
    "5. **Sistema de RecomendaÃ§Ã£o** - AplicaÃ§Ã£o prÃ¡tica\n",
    "6. **Clustering** - Agrupando textos por similaridade\n",
    "7. **RAG** - Base para sistemas inteligentes\n",
    "\n",
    "### ğŸ’¡ **Dica Final:**\n",
    "\n",
    "> Embeddings sÃ£o a base para muitos sistemas de IA modernos. Dominar este conceito Ã© fundamental para construir soluÃ§Ãµes inteligentes que realmente entendem o significado do texto.\n",
    "\n",
    "**Continue explorando e construindo! ğŸš€**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
