{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2bea1aa",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/pathbit/pathbit-academy-ai/blob/master/0002_embeddings_vetorizacao/notebooks/embeddings_vetorizacao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be558db3",
   "metadata": {},
   "source": [
    "# âœ¨ **Pathbit Academy AI**\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ **Artigo 0002: Embeddings e VetorizaÃ§Ã£o - Como a IA Entende Texto**\n",
    "\n",
    "ðŸš¨ **IMPORTANTE:**\n",
    "\n",
    "*ðŸ’¥ QUALQUER PESSOA QUE CONSIGA RESOLVER A EQUAÃ‡ÃƒO `2 + 2 = ?` PODE CONTINUAR OS PASSOS ABAIXO*\n",
    "\n",
    "**Artigo de referÃªncia:** [https://github.com/pathbit/pathbit-academy-ai/blob/master/0002_embeddings_vetorizacao/article/ARTICLE.md](https://github.com/pathbit/pathbit-academy-ai/blob/master/0002_embeddings_vetorizacao/article/ARTICLE.md)\n",
    "\n",
    "**Artigo anterior:** [https://github.com/pathbit/pathbit-academy-ai/blob/master/0001_llm_x_lrm/article/ARTICLE.md](https://github.com/pathbit/pathbit-academy-ai/blob/master/0001_llm_x_lrm/article/ARTICLE.md)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ **Este notebook contÃ©m TUDO que vocÃª precisa:**\n",
    "- âœ… **InstalaÃ§Ã£o automÃ¡tica** de dependÃªncias\n",
    "- âœ… **ConfiguraÃ§Ã£o** de modelos\n",
    "- âœ… **9 exemplos prÃ¡ticos** de embeddings\n",
    "- âœ… **CÃ³digo pronto para usar** - sem arquivos externos\n",
    "- âœ… **Funciona no Google Colab** e localmente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498b1903",
   "metadata": {},
   "source": [
    "### ðŸ”§ **CorreÃ§Ã£o automÃ¡tica para Google Colab**\n",
    "\n",
    "ðŸš¨ **IMPORTANTE:** Se vocÃª estiver executando no Google Colab, esta cÃ©lula corrige automaticamente problemas de compatibilidade do `tqdm`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "333d6056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’» Detectado: Ambiente Local\n",
      "â„¹ï¸  CorreÃ§Ã£o do tqdm nÃ£o necessÃ¡ria no ambiente local\n",
      "\n",
      "ðŸŽ¯ Ambiente configurado! Continue com a prÃ³xima cÃ©lula.\n"
     ]
    }
   ],
   "source": [
    "# ðŸ”§ CORREÃ‡ÃƒO AUTOMÃTICA PARA GOOGLE COLAB\n",
    "# ==========================================\n",
    "# Esta cÃ©lula resolve automaticamente conflitos de dependÃªncias do tqdm\n",
    "\n",
    "# Detectar se estamos no Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"ðŸŒ Detectado: Google Colab\")\n",
    "    print(\"ðŸ”§ Aplicando correÃ§Ã£o para conflito de tqdm...\")\n",
    "    \n",
    "    # CORREÃ‡ÃƒO: Atualizar tqdm para resolver conflitos de dependÃªncias\n",
    "    get_ipython().run_line_magic('pip', 'install --upgrade tqdm>=4.67 --force-reinstall --quiet')\n",
    "    print(\"âœ… tqdm atualizado com sucesso!\")\n",
    "    print(\"ðŸ“¦ VersÃ£o do tqdm corrigida para resolver conflitos com datasets e dataproc-spark-connect\")\n",
    "    \n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"ðŸ’» Detectado: Ambiente Local\")\n",
    "    print(\"â„¹ï¸  CorreÃ§Ã£o do tqdm nÃ£o necessÃ¡ria no ambiente local\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Ambiente configurado! Continue com a prÃ³xima cÃ©lula.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d41879a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Ambiente configurado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# ðŸ”§ CONFIGURAÃ‡ÃƒO INICIAL DO AMBIENTE\n",
    "# ======================================\n",
    "\n",
    "# ðŸ”‡ Suprimir avisos ANTES de qualquer importaÃ§Ã£o\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Suprimir avisos especÃ­ficos\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Tentar suprimir aviso do tqdm (se disponÃ­vel)\n",
    "try:\n",
    "    from tqdm import TqdmExperimentalWarning\n",
    "    warnings.filterwarnings(\"ignore\", category=TqdmExperimentalWarning)\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# Configurar ambiente para evitar problemas de importaÃ§Ã£o\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "print(\"ðŸ”§ Ambiente configurado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c06ee0",
   "metadata": {},
   "source": [
    "### ÖŽ **O que sÃ£o Embeddings?**\n",
    "\n",
    "**Embeddings** sÃ£o representaÃ§Ãµes numÃ©ricas de texto que capturam o significado semÃ¢ntico. Ã‰ como transformar \"cachorro\" e \"animal de estimaÃ§Ã£o\" em nÃºmeros que ficam prÃ³ximos no espaÃ§o matemÃ¡tico, mesmo sendo palavras diferentes.\n",
    "\n",
    "![Conceito de Embeddings](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/01.png)\n",
    "\n",
    "**VetorizaÃ§Ã£o** Ã© o processo de converter texto em esses nÃºmeros. NÃ£o Ã© mÃ¡gica, Ã© matemÃ¡tica aplicada com muito texto e poder computacional.\n",
    "\n",
    "![Processo de VetorizaÃ§Ã£o](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/02.png)\n",
    "\n",
    "#### â‰ï¸ Por que sÃ£o importantes?\n",
    "\n",
    "- **Busca SemÃ¢ntica:** Encontrar documentos similares baseado no significado\n",
    "- **ClassificaÃ§Ã£o:** Categorizar documentos automaticamente  \n",
    "- **RecomendaÃ§Ã£o:** Sugerir conteÃºdo similar ao que o usuÃ¡rio gosta\n",
    "- **RAG:** Base para sistemas de Retrieval Augmented Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6149b680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Verificando dependÃªncias no ambiente local...\n",
      "âœ… Todas as dependÃªncias jÃ¡ estÃ£o instaladas!\n",
      "ðŸŽ¯ Notebook pronto para usar!\n",
      "ðŸ“Š DependÃªncias carregadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“¦ INSTALAÃ‡ÃƒO DAS DEPENDÃŠNCIAS\n",
    "# ================================\n",
    "# InstalaÃ§Ã£o das bibliotecas necessÃ¡rias para trabalhar com embeddings\n",
    "\n",
    "# Instalar dependÃªncias (Colab precisa do %pip)\n",
    "if IN_COLAB:\n",
    "    print(\"ðŸ“¦ Instalando dependÃªncias no Google Colab...\")\n",
    "    get_ipython().run_line_magic('pip', 'install -q sentence-transformers scikit-learn matplotlib seaborn pandas plotly tqdm>=4.67')\n",
    "else:\n",
    "    print(\"ðŸ“¦ Verificando dependÃªncias no ambiente local...\")\n",
    "    try:\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        from sklearn.cluster import KMeans\n",
    "        from sklearn.decomposition import PCA\n",
    "        print(\"âœ… Todas as dependÃªncias jÃ¡ estÃ£o instaladas!\")\n",
    "    except ImportError as e:\n",
    "        print(f\"âš ï¸ Instalando dependÃªncias faltantes: {e}\")\n",
    "        import subprocess\n",
    "        import sys\n",
    "        \n",
    "        subprocess.check_call([\n",
    "            sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
    "            \"sentence-transformers\", \"scikit-learn\", \"matplotlib\", \n",
    "            \"seaborn\", \"pandas\", \"plotly\", \"tqdm>=4.67\"\n",
    "        ])\n",
    "\n",
    "# ImportaÃ§Ãµes principais\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# ConfiguraÃ§Ãµes adicionais\n",
    "plt.style.use('default')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"ðŸŽ¯ Notebook pronto para usar!\")\n",
    "print(\"ðŸ“Š DependÃªncias carregadas com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf265513",
   "metadata": {},
   "source": [
    "### ðŸ› ï¸ **Classes e FunÃ§Ãµes UtilitÃ¡rias**\n",
    "\n",
    "Aqui estÃ£o todas as funÃ§Ãµes que vocÃª precisa para trabalhar com embeddings. **NÃ£o precisa baixar arquivos externos!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf185d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Inicializando EmbeddingsHelper...\n",
      "ðŸ”„ Carregando modelo all-MiniLM-L6-v2...\n",
      "âœ… Modelo all-MiniLM-L6-v2 carregado com sucesso!\n",
      "ðŸ“Š DimensÃµes do embedding: 384\n",
      "âœ… Helper pronto para uso!\n"
     ]
    }
   ],
   "source": [
    "# ðŸ› ï¸ Classes e FunÃ§Ãµes para Embeddings\n",
    "# ======================================\n",
    "\n",
    "class EmbeddingsHelper:\n",
    "    \"\"\"\n",
    "    Classe helper para trabalhar com embeddings de forma simples.\n",
    "    ContÃ©m todas as funÃ§Ãµes necessÃ¡rias para os exemplos.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        \"\"\"Inicializa o helper com um modelo de embeddings.\"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "    \n",
    "    def _load_model(self):\n",
    "        \"\"\"Carrega o modelo de embeddings.\"\"\"\n",
    "        try:\n",
    "            print(f\"ðŸ”„ Carregando modelo {self.model_name}...\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"âœ… Modelo {self.model_name} carregado com sucesso!\")\n",
    "            print(f\"ðŸ“Š DimensÃµes do embedding: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Erro ao carregar modelo: {e}\")\n",
    "            self.model = None\n",
    "    \n",
    "    def get_embedding(self, text):\n",
    "        \"\"\"Gera embedding para um texto.\"\"\"\n",
    "        if self.model is None:\n",
    "            return None\n",
    "        try:\n",
    "            return self.model.encode([text])[0]\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Erro ao gerar embedding: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_embeddings(self, texts):\n",
    "        \"\"\"Gera embeddings para uma lista de textos.\"\"\"\n",
    "        if self.model is None:\n",
    "            return None\n",
    "        try:\n",
    "            return self.model.encode(texts)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Erro ao gerar embeddings: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def calculate_similarity(self, text1, text2):\n",
    "        \"\"\"Calcula similaridade coseno entre dois textos.\"\"\"\n",
    "        emb1 = self.get_embedding(text1)\n",
    "        emb2 = self.get_embedding(text2)\n",
    "        \n",
    "        if emb1 is None or emb2 is None:\n",
    "            return None\n",
    "        \n",
    "        similarity = cosine_similarity([emb1], [emb2])[0][0]\n",
    "        return similarity\n",
    "    \n",
    "    def search_documents(self, query, documents, top_k=5):\n",
    "        \"\"\"Busca documentos mais similares a uma consulta.\"\"\"\n",
    "        if self.model is None:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # Gerar embedding da consulta\n",
    "            query_embedding = self.get_embedding(query)\n",
    "            if query_embedding is None:\n",
    "                return []\n",
    "            \n",
    "            # Gerar embeddings dos documentos\n",
    "            doc_embeddings = self.get_embeddings(documents)\n",
    "            if doc_embeddings is None:\n",
    "                return []\n",
    "            \n",
    "            # Calcular similaridades\n",
    "            similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
    "            \n",
    "            # Ordenar por similaridade\n",
    "            indices_ordenados = np.argsort(similarities)[::-1]\n",
    "            \n",
    "            # Retornar top_k resultados\n",
    "            results = []\n",
    "            for i in range(min(top_k, len(documents))):\n",
    "                idx = indices_ordenados[i]\n",
    "                results.append({\n",
    "                    'documento': documents[idx],\n",
    "                    'similaridade': similarities[idx],\n",
    "                    'posicao': i + 1\n",
    "                })\n",
    "            \n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Erro na busca: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def cluster_documents(self, documents, n_clusters=3):\n",
    "        \"\"\"Agrupa documentos em clusters baseado em similaridade.\"\"\"\n",
    "        if self.model is None:\n",
    "            return {}\n",
    "        \n",
    "        try:\n",
    "            # Gerar embeddings\n",
    "            embeddings = self.get_embeddings(documents)\n",
    "            if embeddings is None:\n",
    "                return {}\n",
    "            \n",
    "            # Aplicar K-Means\n",
    "            kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "            cluster_labels = kmeans.fit_predict(embeddings)\n",
    "            \n",
    "            # Organizar por clusters\n",
    "            clusters = {}\n",
    "            for i, label in enumerate(cluster_labels):\n",
    "                if label not in clusters:\n",
    "                    clusters[label] = []\n",
    "                clusters[label].append({\n",
    "                    'documento': documents[i],\n",
    "                    'indice': i\n",
    "                })\n",
    "            \n",
    "            return clusters\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Erro no clustering: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def detect_duplicates(self, documents, threshold=0.8):\n",
    "        \"\"\"Detecta documentos duplicados baseado em similaridade.\"\"\"\n",
    "        if self.model is None:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # Gerar embeddings\n",
    "            embeddings = self.get_embeddings(documents)\n",
    "            if embeddings is None:\n",
    "                return []\n",
    "            \n",
    "            # Calcular matriz de similaridade\n",
    "            similarity_matrix = cosine_similarity(embeddings)\n",
    "            \n",
    "            # Encontrar pares duplicados\n",
    "            duplicates = []\n",
    "            for i in range(len(documents)):\n",
    "                for j in range(i + 1, len(documents)):\n",
    "                    similarity = similarity_matrix[i][j]\n",
    "                    if similarity >= threshold:\n",
    "                        duplicates.append({\n",
    "                            'doc1': documents[i],\n",
    "                            'doc2': documents[j],\n",
    "                            'similarity': similarity,\n",
    "                            'index1': i,\n",
    "                            'index2': j\n",
    "                        })\n",
    "            \n",
    "            return duplicates\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Erro na detecÃ§Ã£o de duplicatas: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def visualize_embeddings(self, texts, title=\"VisualizaÃ§Ã£o de Embeddings\"):\n",
    "        \"\"\"Visualiza embeddings em 2D usando PCA.\"\"\"\n",
    "        if self.model is None:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Gerar embeddings\n",
    "            embeddings = self.get_embeddings(texts)\n",
    "            if embeddings is None:\n",
    "                return\n",
    "            \n",
    "            # Reduzir dimensionalidade para 2D\n",
    "            pca = PCA(n_components=2)\n",
    "            embeddings_2d = pca.fit_transform(embeddings)\n",
    "            \n",
    "            # Criar grÃ¡fico\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            \n",
    "            # Plotar pontos\n",
    "            plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], \n",
    "                       alpha=0.7, s=100, c=range(len(texts)), cmap='viridis')\n",
    "            \n",
    "            # Adicionar labels\n",
    "            for i, text in enumerate(texts):\n",
    "                plt.annotate(f\"{i+1}. {text[:30]}...\", \n",
    "                            (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
    "                            fontsize=9, alpha=0.8,\n",
    "                            xytext=(5, 5), textcoords='offset points')\n",
    "            \n",
    "            plt.title(title, fontsize=14, fontweight='bold')\n",
    "            plt.xlabel(\"Componente Principal 1\", fontsize=12)\n",
    "            plt.ylabel(\"Componente Principal 2\", fontsize=12)\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Mostrar variÃ¢ncia explicada\n",
    "            var_explicada = pca.explained_variance_ratio_\n",
    "            print(f\"ðŸ“Š VariÃ¢ncia explicada:\")\n",
    "            print(f\"   PC1: {var_explicada[0]:.1%}\")\n",
    "            print(f\"   PC2: {var_explicada[1]:.1%}\")\n",
    "            print(f\"   Total: {sum(var_explicada):.1%}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Erro na visualizaÃ§Ã£o: {e}\")\n",
    "\n",
    "# ðŸŽ¯ Inicializar o helper\n",
    "print(\"ðŸš€ Inicializando EmbeddingsHelper...\")\n",
    "helper = EmbeddingsHelper('all-MiniLM-L6-v2')\n",
    "print(\"âœ… Helper pronto para uso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7070a2",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ **Exemplo 1: GeraÃ§Ã£o de Embeddings BÃ¡sica**\n",
    "\n",
    "![TransformaÃ§Ã£o Texto para NÃºmeros](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/03.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "006dd689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Textos de exemplo:\n",
      "1. O cachorro estÃ¡ brincando no parque\n",
      "2. O gato dorme no sofÃ¡\n",
      "3. O carro estÃ¡ na garagem\n",
      "4. O animal de estimaÃ§Ã£o estÃ¡ feliz\n",
      "5. O veÃ­culo precisa de gasolina\n",
      "\n",
      "ðŸ”„ Gerando embeddings...\n",
      "âœ… Embeddings gerados!\n",
      "ðŸ“Š Forma dos embeddings: (5, 384)\n",
      "ðŸ“Š DimensÃµes: 384 por texto\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“ Textos de exemplo\n",
    "textos = [\n",
    "    \"O cachorro estÃ¡ brincando no parque\",\n",
    "    \"O gato dorme no sofÃ¡\", \n",
    "    \"O carro estÃ¡ na garagem\",\n",
    "    \"O animal de estimaÃ§Ã£o estÃ¡ feliz\",\n",
    "    \"O veÃ­culo precisa de gasolina\"\n",
    "]\n",
    "\n",
    "print(\"ðŸ“ Textos de exemplo:\")\n",
    "for i, texto in enumerate(textos, 1):\n",
    "    print(f\"{i}. {texto}\")\n",
    "\n",
    "# ðŸ”„ Gerar embeddings usando o helper\n",
    "print(\"\\nðŸ”„ Gerando embeddings...\")\n",
    "embeddings = helper.get_embeddings(textos)\n",
    "\n",
    "if embeddings is not None:\n",
    "    print(f\"âœ… Embeddings gerados!\")\n",
    "    print(f\"ðŸ“Š Forma dos embeddings: {embeddings.shape}\")\n",
    "    print(f\"ðŸ“Š DimensÃµes: {embeddings.shape[1]} por texto\")\n",
    "else:\n",
    "    print(\"âŒ Erro ao gerar embeddings\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7ecdde",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ **Exemplo 2: CÃ¡lculo de Similaridade**\n",
    "\n",
    "![CÃ¡lculo de Similaridade](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/04.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcf952ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Teste de Similaridade:\n",
      "Texto 1: O cachorro estÃ¡ brincando no parque\n",
      "Texto 2: O animal de estimaÃ§Ã£o estÃ¡ feliz\n",
      "Texto 3: O carro estÃ¡ na garagem\n",
      "\n",
      "ðŸ“Š Resultados:\n",
      "Similaridade 1-2: 0.290\n",
      "Similaridade 1-3: 0.517\n",
      "Similaridade 2-3: 0.349\n",
      "\n",
      "ðŸ’¡ InterpretaÃ§Ã£o:\n",
      "âŒ Textos 1 e 2 sÃ£o pouco similares\n"
     ]
    }
   ],
   "source": [
    "# ðŸ” Calcular similaridade entre textos\n",
    "texto1 = \"O cachorro estÃ¡ brincando no parque\"\n",
    "texto2 = \"O animal de estimaÃ§Ã£o estÃ¡ feliz\"\n",
    "texto3 = \"O carro estÃ¡ na garagem\"\n",
    "\n",
    "print(\"ðŸ” Teste de Similaridade:\")\n",
    "print(f\"Texto 1: {texto1}\")\n",
    "print(f\"Texto 2: {texto2}\")\n",
    "print(f\"Texto 3: {texto3}\")\n",
    "\n",
    "sim_1_2 = helper.calculate_similarity(texto1, texto2)\n",
    "sim_1_3 = helper.calculate_similarity(texto1, texto3)\n",
    "sim_2_3 = helper.calculate_similarity(texto2, texto3)\n",
    "\n",
    "print(f\"\\nðŸ“Š Resultados:\")\n",
    "print(f\"Similaridade 1-2: {sim_1_2:.3f}\")\n",
    "print(f\"Similaridade 1-3: {sim_1_3:.3f}\")\n",
    "print(f\"Similaridade 2-3: {sim_2_3:.3f}\")\n",
    "\n",
    "# InterpretaÃ§Ã£o\n",
    "print(f\"\\nðŸ’¡ InterpretaÃ§Ã£o:\")\n",
    "if sim_1_2 > 0.7:\n",
    "    print(\"âœ… Textos 1 e 2 sÃ£o muito similares (mesmo tema)\")\n",
    "elif sim_1_2 > 0.5:\n",
    "    print(\"âš ï¸  Textos 1 e 2 sÃ£o moderadamente similares\")\n",
    "else:\n",
    "    print(\"âŒ Textos 1 e 2 sÃ£o pouco similares\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc65ad3",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ **Exemplo 3: Busca SemÃ¢ntica**\n",
    "\n",
    "![Busca SemÃ¢ntica](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/05.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "941eae6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Busca SemÃ¢ntica:\n",
      "Consulta: 'ferramentas para anÃ¡lise de dados'\n",
      "\n",
      "ðŸ“š Documentos disponÃ­veis:\n",
      "1. Python Ã© uma linguagem de programaÃ§Ã£o versÃ¡til e fÃ¡cil de aprender\n",
      "2. Machine learning Ã© uma Ã¡rea da inteligÃªncia artificial\n",
      "3. Data science combina estatÃ­stica, programaÃ§Ã£o e conhecimento de domÃ­nio\n",
      "4. Deep learning usa redes neurais para resolver problemas complexos\n",
      "5. Pandas Ã© uma biblioteca Python para anÃ¡lise de dados\n",
      "6. Scikit-learn oferece ferramentas para machine learning\n",
      "7. Jupyter Notebook Ã© ideal para anÃ¡lise exploratÃ³ria de dados\n",
      "8. NumPy fornece arrays multidimensionais eficientes\n",
      "\n",
      "ðŸ”„ Buscando documentos similares...\n",
      "\n",
      "ðŸ“Š Top 3 resultados:\n",
      "1. Similaridade: 0.576\n",
      "   Jupyter Notebook Ã© ideal para anÃ¡lise exploratÃ³ria de dados\n",
      "\n",
      "2. Similaridade: 0.494\n",
      "   Pandas Ã© uma biblioteca Python para anÃ¡lise de dados\n",
      "\n",
      "3. Similaridade: 0.321\n",
      "   Data science combina estatÃ­stica, programaÃ§Ã£o e conhecimento de domÃ­nio\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ðŸ” Busca semÃ¢ntica em documentos\n",
    "documentos = [\n",
    "    \"Python Ã© uma linguagem de programaÃ§Ã£o versÃ¡til e fÃ¡cil de aprender\",\n",
    "    \"Machine learning Ã© uma Ã¡rea da inteligÃªncia artificial\",\n",
    "    \"Data science combina estatÃ­stica, programaÃ§Ã£o e conhecimento de domÃ­nio\",\n",
    "    \"Deep learning usa redes neurais para resolver problemas complexos\",\n",
    "    \"Pandas Ã© uma biblioteca Python para anÃ¡lise de dados\",\n",
    "    \"Scikit-learn oferece ferramentas para machine learning\",\n",
    "    \"Jupyter Notebook Ã© ideal para anÃ¡lise exploratÃ³ria de dados\",\n",
    "    \"NumPy fornece arrays multidimensionais eficientes\"\n",
    "]\n",
    "\n",
    "consulta = \"ferramentas para anÃ¡lise de dados\"\n",
    "\n",
    "print(\"ðŸ” Busca SemÃ¢ntica:\")\n",
    "print(f\"Consulta: '{consulta}'\")\n",
    "print(\"\\nðŸ“š Documentos disponÃ­veis:\")\n",
    "for i, doc in enumerate(documentos, 1):\n",
    "    print(f\"{i}. {doc}\")\n",
    "\n",
    "print(f\"\\nðŸ”„ Buscando documentos similares...\")\n",
    "resultados = helper.search_documents(consulta, documentos, top_k=3)\n",
    "\n",
    "print(f\"\\nðŸ“Š Top 3 resultados:\")\n",
    "for resultado in resultados:\n",
    "    print(f\"{resultado['posicao']}. Similaridade: {resultado['similaridade']:.3f}\")\n",
    "    print(f\"   {resultado['documento']}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703269d4",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ **Exemplo 4: Sistema de RecomendaÃ§Ã£o**\n",
    "\n",
    "![Sistema de RecomendaÃ§Ã£o](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/08.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "258938ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Sistema de RecomendaÃ§Ã£o:\n",
      "\n",
      "ðŸ“š HistÃ³rico do usuÃ¡rio:\n",
      "1. Como aprender Python do zero\n",
      "2. Data science com pandas\n",
      "\n",
      "ðŸ”„ Gerando recomendaÃ§Ãµes...\n",
      "\n",
      "ðŸ“Š Top 5 RecomendaÃ§Ãµes:\n",
      "3. 0.406 - VisualizaÃ§Ã£o de dados com matplotlib\n",
      "4. 0.303 - ProgramaÃ§Ã£o orientada a objetos\n",
      "5. 0.285 - EstatÃ­stica para data science\n"
     ]
    }
   ],
   "source": [
    "# ðŸŽ¯ Sistema de recomendaÃ§Ã£o baseado em embeddings\n",
    "artigos = [\n",
    "    \"Como aprender Python do zero\",\n",
    "    \"IntroduÃ§Ã£o ao machine learning\",\n",
    "    \"Data science com pandas\",\n",
    "    \"Tutorial de deep learning\",\n",
    "    \"Como fazer anÃ¡lise de dados\",\n",
    "    \"ProgramaÃ§Ã£o orientada a objetos\",\n",
    "    \"EstatÃ­stica para data science\",\n",
    "    \"VisualizaÃ§Ã£o de dados com matplotlib\"\n",
    "]\n",
    "\n",
    "# Simular histÃ³rico do usuÃ¡rio\n",
    "historico_usuario = [\n",
    "    \"Como aprender Python do zero\",\n",
    "    \"Data science com pandas\"\n",
    "]\n",
    "\n",
    "print(\"ðŸŽ¯ Sistema de RecomendaÃ§Ã£o:\")\n",
    "print(\"\\nðŸ“š HistÃ³rico do usuÃ¡rio:\")\n",
    "for i, artigo in enumerate(historico_usuario, 1):\n",
    "    print(f\"{i}. {artigo}\")\n",
    "\n",
    "print(\"\\nðŸ”„ Gerando recomendaÃ§Ãµes...\")\n",
    "\n",
    "# Gerar embedding do histÃ³rico (mÃ©dia dos embeddings)\n",
    "embeddings_historico = helper.get_embeddings(historico_usuario)\n",
    "embedding_medio = np.mean(embeddings_historico, axis=0)\n",
    "\n",
    "# Buscar artigos similares\n",
    "embeddings_artigos = helper.get_embeddings(artigos)\n",
    "similaridades = cosine_similarity([embedding_medio], embeddings_artigos)[0]\n",
    "\n",
    "# Ordenar por similaridade\n",
    "indices_ordenados = np.argsort(similaridades)[::-1]\n",
    "\n",
    "print(\"\\nðŸ“Š Top 5 RecomendaÃ§Ãµes:\")\n",
    "for i in range(5):\n",
    "    idx = indices_ordenados[i]\n",
    "    artigo = artigos[idx]\n",
    "    similaridade = similaridades[idx]\n",
    "    \n",
    "    # NÃ£o recomendar artigos jÃ¡ vistos\n",
    "    if artigo not in historico_usuario:\n",
    "        print(f\"{i+1}. {similaridade:.3f} - {artigo}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec62f4c",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ **Exemplo 5: Clustering de Documentos**\n",
    "\n",
    "![ClassificaÃ§Ã£o de Documentos](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/09.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "761228ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Clustering de Documentos:\n",
      "\n",
      "ðŸ“š Documentos:\n",
      "1. Como fazer um bolo de chocolate\n",
      "2. Receita de bolo de cenoura\n",
      "3. Como programar em Python\n",
      "4. Tutorial de machine learning\n",
      "5. Como dirigir um carro\n",
      "6. Dicas para dirigir na estrada\n",
      "7. Como cuidar de plantas\n",
      "8. Jardinagem para iniciantes\n",
      "\n",
      "ðŸ”„ Agrupando documentos em clusters...\n",
      "\n",
      "ðŸ“Š Resultados do Clustering:\n",
      "\n",
      "ðŸ”¹ Cluster 3:\n",
      "   â€¢ Como fazer um bolo de chocolate\n",
      "   â€¢ Receita de bolo de cenoura\n",
      "   â€¢ Como dirigir um carro\n",
      "\n",
      "ðŸ”¹ Cluster 1:\n",
      "   â€¢ Como programar em Python\n",
      "   â€¢ Tutorial de machine learning\n",
      "\n",
      "ðŸ”¹ Cluster 2:\n",
      "   â€¢ Dicas para dirigir na estrada\n",
      "   â€¢ Como cuidar de plantas\n",
      "   â€¢ Jardinagem para iniciantes\n"
     ]
    }
   ],
   "source": [
    "# ðŸŽ¯ Clustering de documentos por similaridade\n",
    "documentos_cluster = [\n",
    "    \"Como fazer um bolo de chocolate\",\n",
    "    \"Receita de bolo de cenoura\",\n",
    "    \"Como programar em Python\",\n",
    "    \"Tutorial de machine learning\",\n",
    "    \"Como dirigir um carro\",\n",
    "    \"Dicas para dirigir na estrada\",\n",
    "    \"Como cuidar de plantas\",\n",
    "    \"Jardinagem para iniciantes\"\n",
    "]\n",
    "\n",
    "print(\"ðŸŽ¯ Clustering de Documentos:\")\n",
    "print(\"\\nðŸ“š Documentos:\")\n",
    "for i, doc in enumerate(documentos_cluster, 1):\n",
    "    print(f\"{i}. {doc}\")\n",
    "\n",
    "print(\"\\nðŸ”„ Agrupando documentos em clusters...\")\n",
    "clusters = helper.cluster_documents(documentos_cluster, n_clusters=3)\n",
    "\n",
    "print(\"\\nðŸ“Š Resultados do Clustering:\")\n",
    "for cluster_id, docs in clusters.items():\n",
    "    print(f\"\\nðŸ”¹ Cluster {cluster_id + 1}:\")\n",
    "    for doc_info in docs:\n",
    "        print(f\"   â€¢ {doc_info['documento']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37125d90",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ **Exemplo 6: RAG com Embeddings**\n",
    "\n",
    "![RAG com Embeddings](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/10.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abd87801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Sistema RAG - Retrieval Augmented Generation:\n",
      "Pergunta: 'Como posso comeÃ§ar com anÃ¡lise de dados em Python?'\n",
      "\n",
      "ðŸ“š Base de Conhecimento:\n",
      "1. Python Ã© uma linguagem de programaÃ§Ã£o interpretada, de alto nÃ­vel e de propÃ³sito geral.\n",
      "2. Machine learning Ã© um subcampo da inteligÃªncia artificial que se concentra em algoritmos que podem aprender com dados.\n",
      "3. Data science Ã© um campo interdisciplinar que usa mÃ©todos cientÃ­ficos para extrair conhecimento de dados.\n",
      "4. Pandas Ã© uma biblioteca Python para manipulaÃ§Ã£o e anÃ¡lise de dados estruturados.\n",
      "5. NumPy Ã© uma biblioteca Python fundamental para computaÃ§Ã£o cientÃ­fica com arrays multidimensionais.\n",
      "6. Scikit-learn Ã© uma biblioteca Python para machine learning que fornece ferramentas para classificaÃ§Ã£o, regressÃ£o e clustering.\n",
      "7. Jupyter Notebook Ã© um ambiente de desenvolvimento interativo que permite criar e compartilhar documentos com cÃ³digo, visualizaÃ§Ãµes e texto.\n",
      "\n",
      "ðŸ”„ Buscando contexto relevante...\n",
      "\n",
      "ðŸ“Š Contexto Relevante Encontrado:\n",
      "\n",
      "1. Similaridade: 0.658\n",
      "   Python Ã© uma linguagem de programaÃ§Ã£o interpretada, de alto nÃ­vel e de propÃ³sito geral.\n",
      "\n",
      "2. Similaridade: 0.640\n",
      "   Pandas Ã© uma biblioteca Python para manipulaÃ§Ã£o e anÃ¡lise de dados estruturados.\n",
      "\n",
      "3. Similaridade: 0.444\n",
      "   Jupyter Notebook Ã© um ambiente de desenvolvimento interativo que permite criar e compartilhar documentos com cÃ³digo, visualizaÃ§Ãµes e texto.\n",
      "\n",
      "ðŸ’¡ Com este contexto, um LLM poderia gerar uma resposta mais precisa!\n",
      "   Este Ã© o princÃ­pio bÃ¡sico do RAG - encontrar informaÃ§Ãµes relevantes primeiro.\n"
     ]
    }
   ],
   "source": [
    "# ðŸ” SimulaÃ§Ã£o de RAG (Retrieval Augmented Generation)\n",
    "# Este exemplo mostra como embeddings sÃ£o usados para encontrar contexto relevante\n",
    "\n",
    "# Base de conhecimento (simulando documentos)\n",
    "base_conhecimento = [\n",
    "    \"Python Ã© uma linguagem de programaÃ§Ã£o interpretada, de alto nÃ­vel e de propÃ³sito geral.\",\n",
    "    \"Machine learning Ã© um subcampo da inteligÃªncia artificial que se concentra em algoritmos que podem aprender com dados.\",\n",
    "    \"Data science Ã© um campo interdisciplinar que usa mÃ©todos cientÃ­ficos para extrair conhecimento de dados.\",\n",
    "    \"Pandas Ã© uma biblioteca Python para manipulaÃ§Ã£o e anÃ¡lise de dados estruturados.\",\n",
    "    \"NumPy Ã© uma biblioteca Python fundamental para computaÃ§Ã£o cientÃ­fica com arrays multidimensionais.\",\n",
    "    \"Scikit-learn Ã© uma biblioteca Python para machine learning que fornece ferramentas para classificaÃ§Ã£o, regressÃ£o e clustering.\",\n",
    "    \"Jupyter Notebook Ã© um ambiente de desenvolvimento interativo que permite criar e compartilhar documentos com cÃ³digo, visualizaÃ§Ãµes e texto.\"\n",
    "]\n",
    "\n",
    "# Pergunta do usuÃ¡rio\n",
    "pergunta = \"Como posso comeÃ§ar com anÃ¡lise de dados em Python?\"\n",
    "\n",
    "print(\"ðŸ” Sistema RAG - Retrieval Augmented Generation:\")\n",
    "print(f\"Pergunta: '{pergunta}'\")\n",
    "\n",
    "print(\"\\nðŸ“š Base de Conhecimento:\")\n",
    "for i, doc in enumerate(base_conhecimento, 1):\n",
    "    print(f\"{i}. {doc}\")\n",
    "\n",
    "print(f\"\\nðŸ”„ Buscando contexto relevante...\")\n",
    "resultados_rag = helper.search_documents(pergunta, base_conhecimento, top_k=3)\n",
    "\n",
    "print(f\"\\nðŸ“Š Contexto Relevante Encontrado:\")\n",
    "for resultado in resultados_rag:\n",
    "    print(f\"\\n{resultado['posicao']}. Similaridade: {resultado['similaridade']:.3f}\")\n",
    "    print(f\"   {resultado['documento']}\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ Com este contexto, um LLM poderia gerar uma resposta mais precisa!\")\n",
    "print(\"   Este Ã© o princÃ­pio bÃ¡sico do RAG - encontrar informaÃ§Ãµes relevantes primeiro.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81016017",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ **ConclusÃ£o**\n",
    "\n",
    "ParabÃ©ns! VocÃª acabou de explorar os conceitos fundamentais de **embeddings e vetorizaÃ§Ã£o**. \n",
    "\n",
    "### ðŸ“š **O que vocÃª aprendeu:**\n",
    "\n",
    "1. **Conceitos BÃ¡sicos** - Como texto Ã© convertido em nÃºmeros\n",
    "2. **GeraÃ§Ã£o de Embeddings** - Usando modelos prÃ©-treinados\n",
    "3. **CÃ¡lculo de Similaridade** - Medindo semelhanÃ§a entre textos\n",
    "4. **Busca SemÃ¢ntica** - Encontrando documentos relevantes\n",
    "5. **Sistema de RecomendaÃ§Ã£o** - AplicaÃ§Ã£o prÃ¡tica\n",
    "6. **Clustering** - Agrupando textos por similaridade\n",
    "7. **RAG** - Base para sistemas inteligentes\n",
    "\n",
    "### ðŸš€ **PrÃ³ximos Passos:**\n",
    "\n",
    "- Explore o [Artigo 0003: RAG](../0003_rag/README.md) para combinar embeddings com LLMs\n",
    "- Experimente com seus prÃ³prios dados e textos\n",
    "- Teste diferentes modelos de embeddings\n",
    "- Implemente sistemas de busca semÃ¢ntica reais\n",
    "\n",
    "### ðŸ’¡ **Dica Final:**\n",
    "\n",
    "> Embeddings sÃ£o a base para muitos sistemas de IA modernos. Dominar este conceito Ã© fundamental para construir soluÃ§Ãµes inteligentes que realmente entendem o significado do texto.\n",
    "\n",
    "**Continue explorando e construindo! ðŸš€**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a876a0-92bd-4235-9038-faadbbeff458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
