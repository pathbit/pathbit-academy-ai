{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2bea1aa",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/pathbit/pathbit-academy-ai/blob/master/0002_embeddings_vetorizacao/notebooks/embeddings_vetorizacao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be558db3",
   "metadata": {},
   "source": [
    "# ✨ **Pathbit Academy AI**\n",
    "---\n",
    "\n",
    "## 🎯 **Artigo 0002: Embeddings e Vetorização - Como a IA Entende Texto**\n",
    "\n",
    "🚨 **IMPORTANTE:**\n",
    "\n",
    "*💥 QUALQUER PESSOA QUE CONSIGA RESOLVER A EQUAÇÃO `2 + 2 = ?` PODE CONTINUAR OS PASSOS ABAIXO*\n",
    "\n",
    "**Artigo de referência:** [https://github.com/pathbit/pathbit-academy-ai/blob/master/0002_embeddings_vetorizacao/article/ARTICLE.md](https://github.com/pathbit/pathbit-academy-ai/blob/master/0002_embeddings_vetorizacao/article/ARTICLE.md)\n",
    "\n",
    "**Artigo anterior:** [https://github.com/pathbit/pathbit-academy-ai/blob/master/0001_llm_x_lrm/article/ARTICLE.md](https://github.com/pathbit/pathbit-academy-ai/blob/master/0001_llm_x_lrm/article/ARTICLE.md)\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 **Este notebook contém TUDO que você precisa:**\n",
    "- ✅ **Instalação automática** de dependências\n",
    "- ✅ **Configuração** de modelos\n",
    "- ✅ **9 exemplos práticos** de embeddings\n",
    "- ✅ **Código pronto para usar** - sem arquivos externos\n",
    "- ✅ **Funciona no Google Colab** e localmente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498b1903",
   "metadata": {},
   "source": [
    "### 🔧 **Correção automática para Google Colab**\n",
    "\n",
    "🚨 **IMPORTANTE:** Se você estiver executando no Google Colab, esta célula corrige automaticamente problemas de compatibilidade do `tqdm`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "333d6056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💻 Detectado: Ambiente Local\n",
      "ℹ️  Correção do tqdm não necessária no ambiente local\n",
      "\n",
      "🎯 Ambiente configurado! Continue com a próxima célula.\n"
     ]
    }
   ],
   "source": [
    "# 🔧 CORREÇÃO AUTOMÁTICA PARA GOOGLE COLAB\n",
    "# ==========================================\n",
    "# Esta célula resolve automaticamente conflitos de dependências do tqdm\n",
    "\n",
    "# Detectar se estamos no Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"🌐 Detectado: Google Colab\")\n",
    "    print(\"🔧 Aplicando correção para conflito de tqdm...\")\n",
    "    \n",
    "    # CORREÇÃO: Atualizar tqdm para resolver conflitos de dependências\n",
    "    get_ipython().run_line_magic('pip', 'install --upgrade tqdm>=4.67 --force-reinstall --quiet')\n",
    "    print(\"✅ tqdm atualizado com sucesso!\")\n",
    "    print(\"📦 Versão do tqdm corrigida para resolver conflitos com datasets e dataproc-spark-connect\")\n",
    "    \n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"💻 Detectado: Ambiente Local\")\n",
    "    print(\"ℹ️  Correção do tqdm não necessária no ambiente local\")\n",
    "\n",
    "print(\"\\n🎯 Ambiente configurado! Continue com a próxima célula.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d41879a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Ambiente configurado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# 🔧 CONFIGURAÇÃO INICIAL DO AMBIENTE\n",
    "# ======================================\n",
    "\n",
    "# 🔇 Suprimir avisos ANTES de qualquer importação\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Suprimir avisos específicos\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Tentar suprimir aviso do tqdm (se disponível)\n",
    "try:\n",
    "    from tqdm import TqdmExperimentalWarning\n",
    "    warnings.filterwarnings(\"ignore\", category=TqdmExperimentalWarning)\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# Configurar ambiente para evitar problemas de importação\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "print(\"🔧 Ambiente configurado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c06ee0",
   "metadata": {},
   "source": [
    "### ֎ **O que são Embeddings?**\n",
    "\n",
    "**Embeddings** são representações numéricas de texto que capturam o significado semântico. É como transformar \"cachorro\" e \"animal de estimação\" em números que ficam próximos no espaço matemático, mesmo sendo palavras diferentes.\n",
    "\n",
    "![Conceito de Embeddings](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/01.png)\n",
    "\n",
    "**Vetorização** é o processo de converter texto em esses números. Não é mágica, é matemática aplicada com muito texto e poder computacional.\n",
    "\n",
    "![Processo de Vetorização](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/02.png)\n",
    "\n",
    "#### ⁉️ Por que são importantes?\n",
    "\n",
    "- **Busca Semântica:** Encontrar documentos similares baseado no significado\n",
    "- **Classificação:** Categorizar documentos automaticamente  \n",
    "- **Recomendação:** Sugerir conteúdo similar ao que o usuário gosta\n",
    "- **RAG:** Base para sistemas de Retrieval Augmented Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6149b680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Verificando dependências no ambiente local...\n",
      "✅ Todas as dependências já estão instaladas!\n",
      "🎯 Notebook pronto para usar!\n",
      "📊 Dependências carregadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# 📦 INSTALAÇÃO DAS DEPENDÊNCIAS\n",
    "# ================================\n",
    "# Instalação das bibliotecas necessárias para trabalhar com embeddings\n",
    "\n",
    "# Instalar dependências (Colab precisa do %pip)\n",
    "if IN_COLAB:\n",
    "    print(\"📦 Instalando dependências no Google Colab...\")\n",
    "    get_ipython().run_line_magic('pip', 'install -q sentence-transformers scikit-learn matplotlib seaborn pandas plotly tqdm>=4.67')\n",
    "else:\n",
    "    print(\"📦 Verificando dependências no ambiente local...\")\n",
    "    try:\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        from sklearn.cluster import KMeans\n",
    "        from sklearn.decomposition import PCA\n",
    "        print(\"✅ Todas as dependências já estão instaladas!\")\n",
    "    except ImportError as e:\n",
    "        print(f\"⚠️ Instalando dependências faltantes: {e}\")\n",
    "        import subprocess\n",
    "        import sys\n",
    "        \n",
    "        subprocess.check_call([\n",
    "            sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
    "            \"sentence-transformers\", \"scikit-learn\", \"matplotlib\", \n",
    "            \"seaborn\", \"pandas\", \"plotly\", \"tqdm>=4.67\"\n",
    "        ])\n",
    "\n",
    "# Importações principais\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Configurações adicionais\n",
    "plt.style.use('default')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"🎯 Notebook pronto para usar!\")\n",
    "print(\"📊 Dependências carregadas com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf265513",
   "metadata": {},
   "source": [
    "### 🛠️ **Classes e Funções Utilitárias**\n",
    "\n",
    "Aqui estão todas as funções que você precisa para trabalhar com embeddings. **Não precisa baixar arquivos externos!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf185d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Inicializando EmbeddingsHelper...\n",
      "🔄 Carregando modelo all-MiniLM-L6-v2...\n",
      "✅ Modelo all-MiniLM-L6-v2 carregado com sucesso!\n",
      "📊 Dimensões do embedding: 384\n",
      "✅ Helper pronto para uso!\n"
     ]
    }
   ],
   "source": [
    "# 🛠️ Classes e Funções para Embeddings\n",
    "# ======================================\n",
    "\n",
    "class EmbeddingsHelper:\n",
    "    \"\"\"\n",
    "    Classe helper para trabalhar com embeddings de forma simples.\n",
    "    Contém todas as funções necessárias para os exemplos.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        \"\"\"Inicializa o helper com um modelo de embeddings.\"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "    \n",
    "    def _load_model(self):\n",
    "        \"\"\"Carrega o modelo de embeddings.\"\"\"\n",
    "        try:\n",
    "            print(f\"🔄 Carregando modelo {self.model_name}...\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"✅ Modelo {self.model_name} carregado com sucesso!\")\n",
    "            print(f\"📊 Dimensões do embedding: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erro ao carregar modelo: {e}\")\n",
    "            self.model = None\n",
    "    \n",
    "    def get_embedding(self, text):\n",
    "        \"\"\"Gera embedding para um texto.\"\"\"\n",
    "        if self.model is None:\n",
    "            return None\n",
    "        try:\n",
    "            return self.model.encode([text])[0]\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erro ao gerar embedding: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_embeddings(self, texts):\n",
    "        \"\"\"Gera embeddings para uma lista de textos.\"\"\"\n",
    "        if self.model is None:\n",
    "            return None\n",
    "        try:\n",
    "            return self.model.encode(texts)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erro ao gerar embeddings: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def calculate_similarity(self, text1, text2):\n",
    "        \"\"\"Calcula similaridade coseno entre dois textos.\"\"\"\n",
    "        emb1 = self.get_embedding(text1)\n",
    "        emb2 = self.get_embedding(text2)\n",
    "        \n",
    "        if emb1 is None or emb2 is None:\n",
    "            return None\n",
    "        \n",
    "        similarity = cosine_similarity([emb1], [emb2])[0][0]\n",
    "        return similarity\n",
    "    \n",
    "    def search_documents(self, query, documents, top_k=5):\n",
    "        \"\"\"Busca documentos mais similares a uma consulta.\"\"\"\n",
    "        if self.model is None:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # Gerar embedding da consulta\n",
    "            query_embedding = self.get_embedding(query)\n",
    "            if query_embedding is None:\n",
    "                return []\n",
    "            \n",
    "            # Gerar embeddings dos documentos\n",
    "            doc_embeddings = self.get_embeddings(documents)\n",
    "            if doc_embeddings is None:\n",
    "                return []\n",
    "            \n",
    "            # Calcular similaridades\n",
    "            similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
    "            \n",
    "            # Ordenar por similaridade\n",
    "            indices_ordenados = np.argsort(similarities)[::-1]\n",
    "            \n",
    "            # Retornar top_k resultados\n",
    "            results = []\n",
    "            for i in range(min(top_k, len(documents))):\n",
    "                idx = indices_ordenados[i]\n",
    "                results.append({\n",
    "                    'documento': documents[idx],\n",
    "                    'similaridade': similarities[idx],\n",
    "                    'posicao': i + 1\n",
    "                })\n",
    "            \n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erro na busca: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def cluster_documents(self, documents, n_clusters=3):\n",
    "        \"\"\"Agrupa documentos em clusters baseado em similaridade.\"\"\"\n",
    "        if self.model is None:\n",
    "            return {}\n",
    "        \n",
    "        try:\n",
    "            # Gerar embeddings\n",
    "            embeddings = self.get_embeddings(documents)\n",
    "            if embeddings is None:\n",
    "                return {}\n",
    "            \n",
    "            # Aplicar K-Means\n",
    "            kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "            cluster_labels = kmeans.fit_predict(embeddings)\n",
    "            \n",
    "            # Organizar por clusters\n",
    "            clusters = {}\n",
    "            for i, label in enumerate(cluster_labels):\n",
    "                if label not in clusters:\n",
    "                    clusters[label] = []\n",
    "                clusters[label].append({\n",
    "                    'documento': documents[i],\n",
    "                    'indice': i\n",
    "                })\n",
    "            \n",
    "            return clusters\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erro no clustering: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def detect_duplicates(self, documents, threshold=0.8):\n",
    "        \"\"\"Detecta documentos duplicados baseado em similaridade.\"\"\"\n",
    "        if self.model is None:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # Gerar embeddings\n",
    "            embeddings = self.get_embeddings(documents)\n",
    "            if embeddings is None:\n",
    "                return []\n",
    "            \n",
    "            # Calcular matriz de similaridade\n",
    "            similarity_matrix = cosine_similarity(embeddings)\n",
    "            \n",
    "            # Encontrar pares duplicados\n",
    "            duplicates = []\n",
    "            for i in range(len(documents)):\n",
    "                for j in range(i + 1, len(documents)):\n",
    "                    similarity = similarity_matrix[i][j]\n",
    "                    if similarity >= threshold:\n",
    "                        duplicates.append({\n",
    "                            'doc1': documents[i],\n",
    "                            'doc2': documents[j],\n",
    "                            'similarity': similarity,\n",
    "                            'index1': i,\n",
    "                            'index2': j\n",
    "                        })\n",
    "            \n",
    "            return duplicates\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erro na detecção de duplicatas: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def visualize_embeddings(self, texts, title=\"Visualização de Embeddings\"):\n",
    "        \"\"\"Visualiza embeddings em 2D usando PCA.\"\"\"\n",
    "        if self.model is None:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Gerar embeddings\n",
    "            embeddings = self.get_embeddings(texts)\n",
    "            if embeddings is None:\n",
    "                return\n",
    "            \n",
    "            # Reduzir dimensionalidade para 2D\n",
    "            pca = PCA(n_components=2)\n",
    "            embeddings_2d = pca.fit_transform(embeddings)\n",
    "            \n",
    "            # Criar gráfico\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            \n",
    "            # Plotar pontos\n",
    "            plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], \n",
    "                       alpha=0.7, s=100, c=range(len(texts)), cmap='viridis')\n",
    "            \n",
    "            # Adicionar labels\n",
    "            for i, text in enumerate(texts):\n",
    "                plt.annotate(f\"{i+1}. {text[:30]}...\", \n",
    "                            (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
    "                            fontsize=9, alpha=0.8,\n",
    "                            xytext=(5, 5), textcoords='offset points')\n",
    "            \n",
    "            plt.title(title, fontsize=14, fontweight='bold')\n",
    "            plt.xlabel(\"Componente Principal 1\", fontsize=12)\n",
    "            plt.ylabel(\"Componente Principal 2\", fontsize=12)\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Mostrar variância explicada\n",
    "            var_explicada = pca.explained_variance_ratio_\n",
    "            print(f\"📊 Variância explicada:\")\n",
    "            print(f\"   PC1: {var_explicada[0]:.1%}\")\n",
    "            print(f\"   PC2: {var_explicada[1]:.1%}\")\n",
    "            print(f\"   Total: {sum(var_explicada):.1%}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erro na visualização: {e}\")\n",
    "\n",
    "# 🎯 Inicializar o helper\n",
    "print(\"🚀 Inicializando EmbeddingsHelper...\")\n",
    "helper = EmbeddingsHelper('all-MiniLM-L6-v2')\n",
    "print(\"✅ Helper pronto para uso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7070a2",
   "metadata": {},
   "source": [
    "### 🎯 **Exemplo 1: Geração de Embeddings Básica**\n",
    "\n",
    "![Transformação Texto para Números](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/03.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "006dd689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Textos de exemplo:\n",
      "1. O cachorro está brincando no parque\n",
      "2. O gato dorme no sofá\n",
      "3. O carro está na garagem\n",
      "4. O animal de estimação está feliz\n",
      "5. O veículo precisa de gasolina\n",
      "\n",
      "🔄 Gerando embeddings...\n",
      "✅ Embeddings gerados!\n",
      "📊 Forma dos embeddings: (5, 384)\n",
      "📊 Dimensões: 384 por texto\n"
     ]
    }
   ],
   "source": [
    "# 📝 Textos de exemplo\n",
    "textos = [\n",
    "    \"O cachorro está brincando no parque\",\n",
    "    \"O gato dorme no sofá\", \n",
    "    \"O carro está na garagem\",\n",
    "    \"O animal de estimação está feliz\",\n",
    "    \"O veículo precisa de gasolina\"\n",
    "]\n",
    "\n",
    "print(\"📝 Textos de exemplo:\")\n",
    "for i, texto in enumerate(textos, 1):\n",
    "    print(f\"{i}. {texto}\")\n",
    "\n",
    "# 🔄 Gerar embeddings usando o helper\n",
    "print(\"\\n🔄 Gerando embeddings...\")\n",
    "embeddings = helper.get_embeddings(textos)\n",
    "\n",
    "if embeddings is not None:\n",
    "    print(f\"✅ Embeddings gerados!\")\n",
    "    print(f\"📊 Forma dos embeddings: {embeddings.shape}\")\n",
    "    print(f\"📊 Dimensões: {embeddings.shape[1]} por texto\")\n",
    "else:\n",
    "    print(\"❌ Erro ao gerar embeddings\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7ecdde",
   "metadata": {},
   "source": [
    "### 🎯 **Exemplo 2: Cálculo de Similaridade**\n",
    "\n",
    "![Cálculo de Similaridade](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/04.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcf952ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Teste de Similaridade:\n",
      "Texto 1: O cachorro está brincando no parque\n",
      "Texto 2: O animal de estimação está feliz\n",
      "Texto 3: O carro está na garagem\n",
      "\n",
      "📊 Resultados:\n",
      "Similaridade 1-2: 0.290\n",
      "Similaridade 1-3: 0.517\n",
      "Similaridade 2-3: 0.349\n",
      "\n",
      "💡 Interpretação:\n",
      "❌ Textos 1 e 2 são pouco similares\n"
     ]
    }
   ],
   "source": [
    "# 🔍 Calcular similaridade entre textos\n",
    "texto1 = \"O cachorro está brincando no parque\"\n",
    "texto2 = \"O animal de estimação está feliz\"\n",
    "texto3 = \"O carro está na garagem\"\n",
    "\n",
    "print(\"🔍 Teste de Similaridade:\")\n",
    "print(f\"Texto 1: {texto1}\")\n",
    "print(f\"Texto 2: {texto2}\")\n",
    "print(f\"Texto 3: {texto3}\")\n",
    "\n",
    "sim_1_2 = helper.calculate_similarity(texto1, texto2)\n",
    "sim_1_3 = helper.calculate_similarity(texto1, texto3)\n",
    "sim_2_3 = helper.calculate_similarity(texto2, texto3)\n",
    "\n",
    "print(f\"\\n📊 Resultados:\")\n",
    "print(f\"Similaridade 1-2: {sim_1_2:.3f}\")\n",
    "print(f\"Similaridade 1-3: {sim_1_3:.3f}\")\n",
    "print(f\"Similaridade 2-3: {sim_2_3:.3f}\")\n",
    "\n",
    "# Interpretação\n",
    "print(f\"\\n💡 Interpretação:\")\n",
    "if sim_1_2 > 0.7:\n",
    "    print(\"✅ Textos 1 e 2 são muito similares (mesmo tema)\")\n",
    "elif sim_1_2 > 0.5:\n",
    "    print(\"⚠️  Textos 1 e 2 são moderadamente similares\")\n",
    "else:\n",
    "    print(\"❌ Textos 1 e 2 são pouco similares\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc65ad3",
   "metadata": {},
   "source": [
    "### 🎯 **Exemplo 3: Busca Semântica**\n",
    "\n",
    "![Busca Semântica](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/05.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "941eae6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Busca Semântica:\n",
      "Consulta: 'ferramentas para análise de dados'\n",
      "\n",
      "📚 Documentos disponíveis:\n",
      "1. Python é uma linguagem de programação versátil e fácil de aprender\n",
      "2. Machine learning é uma área da inteligência artificial\n",
      "3. Data science combina estatística, programação e conhecimento de domínio\n",
      "4. Deep learning usa redes neurais para resolver problemas complexos\n",
      "5. Pandas é uma biblioteca Python para análise de dados\n",
      "6. Scikit-learn oferece ferramentas para machine learning\n",
      "7. Jupyter Notebook é ideal para análise exploratória de dados\n",
      "8. NumPy fornece arrays multidimensionais eficientes\n",
      "\n",
      "🔄 Buscando documentos similares...\n",
      "\n",
      "📊 Top 3 resultados:\n",
      "1. Similaridade: 0.576\n",
      "   Jupyter Notebook é ideal para análise exploratória de dados\n",
      "\n",
      "2. Similaridade: 0.494\n",
      "   Pandas é uma biblioteca Python para análise de dados\n",
      "\n",
      "3. Similaridade: 0.321\n",
      "   Data science combina estatística, programação e conhecimento de domínio\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 🔍 Busca semântica em documentos\n",
    "documentos = [\n",
    "    \"Python é uma linguagem de programação versátil e fácil de aprender\",\n",
    "    \"Machine learning é uma área da inteligência artificial\",\n",
    "    \"Data science combina estatística, programação e conhecimento de domínio\",\n",
    "    \"Deep learning usa redes neurais para resolver problemas complexos\",\n",
    "    \"Pandas é uma biblioteca Python para análise de dados\",\n",
    "    \"Scikit-learn oferece ferramentas para machine learning\",\n",
    "    \"Jupyter Notebook é ideal para análise exploratória de dados\",\n",
    "    \"NumPy fornece arrays multidimensionais eficientes\"\n",
    "]\n",
    "\n",
    "consulta = \"ferramentas para análise de dados\"\n",
    "\n",
    "print(\"🔍 Busca Semântica:\")\n",
    "print(f\"Consulta: '{consulta}'\")\n",
    "print(\"\\n📚 Documentos disponíveis:\")\n",
    "for i, doc in enumerate(documentos, 1):\n",
    "    print(f\"{i}. {doc}\")\n",
    "\n",
    "print(f\"\\n🔄 Buscando documentos similares...\")\n",
    "resultados = helper.search_documents(consulta, documentos, top_k=3)\n",
    "\n",
    "print(f\"\\n📊 Top 3 resultados:\")\n",
    "for resultado in resultados:\n",
    "    print(f\"{resultado['posicao']}. Similaridade: {resultado['similaridade']:.3f}\")\n",
    "    print(f\"   {resultado['documento']}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703269d4",
   "metadata": {},
   "source": [
    "### 🎯 **Exemplo 4: Sistema de Recomendação**\n",
    "\n",
    "![Sistema de Recomendação](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/08.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "258938ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Sistema de Recomendação:\n",
      "\n",
      "📚 Histórico do usuário:\n",
      "1. Como aprender Python do zero\n",
      "2. Data science com pandas\n",
      "\n",
      "🔄 Gerando recomendações...\n",
      "\n",
      "📊 Top 5 Recomendações:\n",
      "3. 0.406 - Visualização de dados com matplotlib\n",
      "4. 0.303 - Programação orientada a objetos\n",
      "5. 0.285 - Estatística para data science\n"
     ]
    }
   ],
   "source": [
    "# 🎯 Sistema de recomendação baseado em embeddings\n",
    "artigos = [\n",
    "    \"Como aprender Python do zero\",\n",
    "    \"Introdução ao machine learning\",\n",
    "    \"Data science com pandas\",\n",
    "    \"Tutorial de deep learning\",\n",
    "    \"Como fazer análise de dados\",\n",
    "    \"Programação orientada a objetos\",\n",
    "    \"Estatística para data science\",\n",
    "    \"Visualização de dados com matplotlib\"\n",
    "]\n",
    "\n",
    "# Simular histórico do usuário\n",
    "historico_usuario = [\n",
    "    \"Como aprender Python do zero\",\n",
    "    \"Data science com pandas\"\n",
    "]\n",
    "\n",
    "print(\"🎯 Sistema de Recomendação:\")\n",
    "print(\"\\n📚 Histórico do usuário:\")\n",
    "for i, artigo in enumerate(historico_usuario, 1):\n",
    "    print(f\"{i}. {artigo}\")\n",
    "\n",
    "print(\"\\n🔄 Gerando recomendações...\")\n",
    "\n",
    "# Gerar embedding do histórico (média dos embeddings)\n",
    "embeddings_historico = helper.get_embeddings(historico_usuario)\n",
    "embedding_medio = np.mean(embeddings_historico, axis=0)\n",
    "\n",
    "# Buscar artigos similares\n",
    "embeddings_artigos = helper.get_embeddings(artigos)\n",
    "similaridades = cosine_similarity([embedding_medio], embeddings_artigos)[0]\n",
    "\n",
    "# Ordenar por similaridade\n",
    "indices_ordenados = np.argsort(similaridades)[::-1]\n",
    "\n",
    "print(\"\\n📊 Top 5 Recomendações:\")\n",
    "for i in range(5):\n",
    "    idx = indices_ordenados[i]\n",
    "    artigo = artigos[idx]\n",
    "    similaridade = similaridades[idx]\n",
    "    \n",
    "    # Não recomendar artigos já vistos\n",
    "    if artigo not in historico_usuario:\n",
    "        print(f\"{i+1}. {similaridade:.3f} - {artigo}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec62f4c",
   "metadata": {},
   "source": [
    "### 🎯 **Exemplo 5: Clustering de Documentos**\n",
    "\n",
    "![Classificação de Documentos](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/09.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "761228ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Clustering de Documentos:\n",
      "\n",
      "📚 Documentos:\n",
      "1. Como fazer um bolo de chocolate\n",
      "2. Receita de bolo de cenoura\n",
      "3. Como programar em Python\n",
      "4. Tutorial de machine learning\n",
      "5. Como dirigir um carro\n",
      "6. Dicas para dirigir na estrada\n",
      "7. Como cuidar de plantas\n",
      "8. Jardinagem para iniciantes\n",
      "\n",
      "🔄 Agrupando documentos em clusters...\n",
      "\n",
      "📊 Resultados do Clustering:\n",
      "\n",
      "🔹 Cluster 3:\n",
      "   • Como fazer um bolo de chocolate\n",
      "   • Receita de bolo de cenoura\n",
      "   • Como dirigir um carro\n",
      "\n",
      "🔹 Cluster 1:\n",
      "   • Como programar em Python\n",
      "   • Tutorial de machine learning\n",
      "\n",
      "🔹 Cluster 2:\n",
      "   • Dicas para dirigir na estrada\n",
      "   • Como cuidar de plantas\n",
      "   • Jardinagem para iniciantes\n"
     ]
    }
   ],
   "source": [
    "# 🎯 Clustering de documentos por similaridade\n",
    "documentos_cluster = [\n",
    "    \"Como fazer um bolo de chocolate\",\n",
    "    \"Receita de bolo de cenoura\",\n",
    "    \"Como programar em Python\",\n",
    "    \"Tutorial de machine learning\",\n",
    "    \"Como dirigir um carro\",\n",
    "    \"Dicas para dirigir na estrada\",\n",
    "    \"Como cuidar de plantas\",\n",
    "    \"Jardinagem para iniciantes\"\n",
    "]\n",
    "\n",
    "print(\"🎯 Clustering de Documentos:\")\n",
    "print(\"\\n📚 Documentos:\")\n",
    "for i, doc in enumerate(documentos_cluster, 1):\n",
    "    print(f\"{i}. {doc}\")\n",
    "\n",
    "print(\"\\n🔄 Agrupando documentos em clusters...\")\n",
    "clusters = helper.cluster_documents(documentos_cluster, n_clusters=3)\n",
    "\n",
    "print(\"\\n📊 Resultados do Clustering:\")\n",
    "for cluster_id, docs in clusters.items():\n",
    "    print(f\"\\n🔹 Cluster {cluster_id + 1}:\")\n",
    "    for doc_info in docs:\n",
    "        print(f\"   • {doc_info['documento']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37125d90",
   "metadata": {},
   "source": [
    "### 🎯 **Exemplo 6: RAG com Embeddings**\n",
    "\n",
    "![RAG com Embeddings](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/10.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abd87801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Sistema RAG - Retrieval Augmented Generation:\n",
      "Pergunta: 'Como posso começar com análise de dados em Python?'\n",
      "\n",
      "📚 Base de Conhecimento:\n",
      "1. Python é uma linguagem de programação interpretada, de alto nível e de propósito geral.\n",
      "2. Machine learning é um subcampo da inteligência artificial que se concentra em algoritmos que podem aprender com dados.\n",
      "3. Data science é um campo interdisciplinar que usa métodos científicos para extrair conhecimento de dados.\n",
      "4. Pandas é uma biblioteca Python para manipulação e análise de dados estruturados.\n",
      "5. NumPy é uma biblioteca Python fundamental para computação científica com arrays multidimensionais.\n",
      "6. Scikit-learn é uma biblioteca Python para machine learning que fornece ferramentas para classificação, regressão e clustering.\n",
      "7. Jupyter Notebook é um ambiente de desenvolvimento interativo que permite criar e compartilhar documentos com código, visualizações e texto.\n",
      "\n",
      "🔄 Buscando contexto relevante...\n",
      "\n",
      "📊 Contexto Relevante Encontrado:\n",
      "\n",
      "1. Similaridade: 0.658\n",
      "   Python é uma linguagem de programação interpretada, de alto nível e de propósito geral.\n",
      "\n",
      "2. Similaridade: 0.640\n",
      "   Pandas é uma biblioteca Python para manipulação e análise de dados estruturados.\n",
      "\n",
      "3. Similaridade: 0.444\n",
      "   Jupyter Notebook é um ambiente de desenvolvimento interativo que permite criar e compartilhar documentos com código, visualizações e texto.\n",
      "\n",
      "💡 Com este contexto, um LLM poderia gerar uma resposta mais precisa!\n",
      "   Este é o princípio básico do RAG - encontrar informações relevantes primeiro.\n"
     ]
    }
   ],
   "source": [
    "# 🔍 Simulação de RAG (Retrieval Augmented Generation)\n",
    "# Este exemplo mostra como embeddings são usados para encontrar contexto relevante\n",
    "\n",
    "# Base de conhecimento (simulando documentos)\n",
    "base_conhecimento = [\n",
    "    \"Python é uma linguagem de programação interpretada, de alto nível e de propósito geral.\",\n",
    "    \"Machine learning é um subcampo da inteligência artificial que se concentra em algoritmos que podem aprender com dados.\",\n",
    "    \"Data science é um campo interdisciplinar que usa métodos científicos para extrair conhecimento de dados.\",\n",
    "    \"Pandas é uma biblioteca Python para manipulação e análise de dados estruturados.\",\n",
    "    \"NumPy é uma biblioteca Python fundamental para computação científica com arrays multidimensionais.\",\n",
    "    \"Scikit-learn é uma biblioteca Python para machine learning que fornece ferramentas para classificação, regressão e clustering.\",\n",
    "    \"Jupyter Notebook é um ambiente de desenvolvimento interativo que permite criar e compartilhar documentos com código, visualizações e texto.\"\n",
    "]\n",
    "\n",
    "# Pergunta do usuário\n",
    "pergunta = \"Como posso começar com análise de dados em Python?\"\n",
    "\n",
    "print(\"🔍 Sistema RAG - Retrieval Augmented Generation:\")\n",
    "print(f\"Pergunta: '{pergunta}'\")\n",
    "\n",
    "print(\"\\n📚 Base de Conhecimento:\")\n",
    "for i, doc in enumerate(base_conhecimento, 1):\n",
    "    print(f\"{i}. {doc}\")\n",
    "\n",
    "print(f\"\\n🔄 Buscando contexto relevante...\")\n",
    "resultados_rag = helper.search_documents(pergunta, base_conhecimento, top_k=3)\n",
    "\n",
    "print(f\"\\n📊 Contexto Relevante Encontrado:\")\n",
    "for resultado in resultados_rag:\n",
    "    print(f\"\\n{resultado['posicao']}. Similaridade: {resultado['similaridade']:.3f}\")\n",
    "    print(f\"   {resultado['documento']}\")\n",
    "\n",
    "print(f\"\\n💡 Com este contexto, um LLM poderia gerar uma resposta mais precisa!\")\n",
    "print(\"   Este é o princípio básico do RAG - encontrar informações relevantes primeiro.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81016017",
   "metadata": {},
   "source": [
    "## 🎉 **Conclusão**\n",
    "\n",
    "Parabéns! Você acabou de explorar os conceitos fundamentais de **embeddings e vetorização**. \n",
    "\n",
    "### 📚 **O que você aprendeu:**\n",
    "\n",
    "1. **Conceitos Básicos** - Como texto é convertido em números\n",
    "2. **Geração de Embeddings** - Usando modelos pré-treinados\n",
    "3. **Cálculo de Similaridade** - Medindo semelhança entre textos\n",
    "4. **Busca Semântica** - Encontrando documentos relevantes\n",
    "5. **Sistema de Recomendação** - Aplicação prática\n",
    "6. **Clustering** - Agrupando textos por similaridade\n",
    "7. **RAG** - Base para sistemas inteligentes\n",
    "\n",
    "### 🚀 **Próximos Passos:**\n",
    "\n",
    "- Explore o [Artigo 0003: RAG](../0003_rag/README.md) para combinar embeddings com LLMs\n",
    "- Experimente com seus próprios dados e textos\n",
    "- Teste diferentes modelos de embeddings\n",
    "- Implemente sistemas de busca semântica reais\n",
    "\n",
    "### 💡 **Dica Final:**\n",
    "\n",
    "> Embeddings são a base para muitos sistemas de IA modernos. Dominar este conceito é fundamental para construir soluções inteligentes que realmente entendem o significado do texto.\n",
    "\n",
    "**Continue explorando e construindo! 🚀**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a876a0-92bd-4235-9038-faadbbeff458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
