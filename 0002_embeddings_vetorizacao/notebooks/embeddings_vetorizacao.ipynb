{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2bea1aa",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/pathbit/pathbit-academy-ai/blob/master/0002_embeddings_vetorizacao/notebooks/embeddings_vetorizacao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be558db3",
   "metadata": {},
   "source": [
    "# ✨ **Pathbit Academy AI**\n",
    "---\n",
    "\n",
    "## 🎯 **Artigo 0002: Embeddings e Vetorização - Como a IA Entende Texto**\n",
    "\n",
    "🚨 **IMPORTANTE:**\n",
    "\n",
    "*💥 QUALQUER PESSOA QUE CONSIGA RESOLVER A EQUAÇÃO `2 + 2 = ?` PODE CONTINUAR OS PASSOS ABAIXO*\n",
    "\n",
    "**Artigo de referência:** [https://github.com/pathbit/pathbit-academy-ai/blob/master/0002_embeddings_vetorizacao/article/ARTICLE.md](https://github.com/pathbit/pathbit-academy-ai/blob/master/0002_embeddings_vetorizacao/article/ARTICLE.md)\n",
    "\n",
    "**Artigo anterior:** [https://github.com/pathbit/pathbit-academy-ai/blob/master/0001_llm_x_lrm/article/ARTICLE.md](https://github.com/pathbit/pathbit-academy-ai/blob/master/0001_llm_x_lrm/article/ARTICLE.md)\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 **Este notebook contém TUDO que você precisa:**\n",
    "- ✅ **Instalação automática** de dependências\n",
    "- ✅ **Configuração** de modelos\n",
    "- ✅ **9 exemplos práticos** de embeddings\n",
    "- ✅ **Código pronto para usar** - sem arquivos externos\n",
    "- ✅ **Funciona no Google Colab** e localmente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498b1903",
   "metadata": {},
   "source": [
    "### 🔧 **Correção automática para Google Colab**\n",
    "\n",
    "🚨 **IMPORTANTE:** Se você estiver executando no Google Colab, esta célula corrige automaticamente problemas de compatibilidade do `tqdm`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "333d6056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💻 Detectado: Ambiente Local\n",
      "ℹ️  Correção do tqdm não necessária no ambiente local\n",
      "\n",
      "🎯 Ambiente configurado! Continue com a próxima célula.\n"
     ]
    }
   ],
   "source": [
    "# 🔧 CORREÇÃO AUTOMÁTICA PARA GOOGLE COLAB\n",
    "# ==========================================\n",
    "# Esta célula resolve automaticamente conflitos de dependências do tqdm\n",
    "\n",
    "# Detectar se estamos no Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"🌐 Detectado: Google Colab\")\n",
    "    print(\"🔧 Aplicando correção para conflito de tqdm...\")\n",
    "    \n",
    "    # CORREÇÃO: Atualizar tqdm para resolver conflitos de dependências\n",
    "    get_ipython().run_line_magic('pip', 'install --upgrade tqdm>=4.67 --force-reinstall --quiet')\n",
    "    print(\"✅ tqdm atualizado com sucesso!\")\n",
    "    print(\"📦 Versão do tqdm corrigida para resolver conflitos com datasets e dataproc-spark-connect\")\n",
    "    \n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"💻 Detectado: Ambiente Local\")\n",
    "    print(\"ℹ️  Correção do tqdm não necessária no ambiente local\")\n",
    "\n",
    "print(\"\\n🎯 Ambiente configurado! Continue com a próxima célula.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d41879a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Ambiente configurado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# 🔧 CONFIGURAÇÃO INICIAL DO AMBIENTE\n",
    "# ======================================\n",
    "\n",
    "# 🔇 Suprimir avisos ANTES de qualquer importação\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Suprimir avisos específicos\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Tentar suprimir aviso do tqdm (se disponível)\n",
    "try:\n",
    "    from tqdm import TqdmExperimentalWarning\n",
    "    warnings.filterwarnings(\"ignore\", category=TqdmExperimentalWarning)\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# Configurar ambiente para evitar problemas de importação\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "print(\"🔧 Ambiente configurado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c06ee0",
   "metadata": {},
   "source": [
    "### ֎ **O que são Embeddings?**\n",
    "\n",
    "**Embeddings** são representações numéricas de texto que capturam o significado semântico. É como transformar \"cachorro\" e \"animal de estimação\" em números que ficam próximos no espaço matemático, mesmo sendo palavras diferentes.\n",
    "\n",
    "![Conceito de Embeddings](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/01.png)\n",
    "\n",
    "**Vetorização** é o processo de converter texto em esses números. Não é mágica, é matemática aplicada com muito texto e poder computacional.\n",
    "\n",
    "![Processo de Vetorização](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/02.png)\n",
    "\n",
    "#### ⁉️ Por que são importantes?\n",
    "\n",
    "- **Busca Semântica:** Encontrar documentos similares baseado no significado\n",
    "- **Classificação:** Categorizar documentos automaticamente  \n",
    "- **Recomendação:** Sugerir conteúdo similar ao que o usuário gosta\n",
    "- **RAG:** Base para sistemas de Retrieval Augmented Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6149b680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Verificando dependências no ambiente local...\n",
      "✅ Todas as dependências já estão instaladas!\n",
      "🎯 Notebook pronto para usar!\n",
      "📊 Dependências carregadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# 📦 INSTALAÇÃO DAS DEPENDÊNCIAS\n",
    "# ================================\n",
    "# Instalação das bibliotecas necessárias para trabalhar com embeddings\n",
    "\n",
    "# Instalar dependências (Colab precisa do %pip)\n",
    "if IN_COLAB:\n",
    "    print(\"📦 Instalando dependências no Google Colab...\")\n",
    "    get_ipython().run_line_magic('pip', 'install -q sentence-transformers scikit-learn matplotlib seaborn pandas plotly tqdm>=4.67')\n",
    "else:\n",
    "    print(\"📦 Verificando dependências no ambiente local...\")\n",
    "    try:\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        from sklearn.cluster import KMeans\n",
    "        from sklearn.decomposition import PCA\n",
    "        print(\"✅ Todas as dependências já estão instaladas!\")\n",
    "    except ImportError as e:\n",
    "        print(f\"⚠️ Instalando dependências faltantes: {e}\")\n",
    "        import subprocess\n",
    "        import sys\n",
    "        \n",
    "        subprocess.check_call([\n",
    "            sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
    "            \"sentence-transformers\", \"scikit-learn\", \"matplotlib\", \n",
    "            \"seaborn\", \"pandas\", \"plotly\", \"tqdm>=4.67\"\n",
    "        ])\n",
    "\n",
    "# Importações principais\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Configurações adicionais\n",
    "plt.style.use('default')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"🎯 Notebook pronto para usar!\")\n",
    "print(\"📊 Dependências carregadas com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceb452ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ ======================================================================\n",
      "🟢                        TESTE DE FORMATAÇÃO                         🟢\n",
      "✅ ======================================================================\n",
      "\n",
      "Esta é uma demonstração da nova formatação visual que será usada em todos os resultados importantes do notebook!\n",
      "\n",
      "✅ ======================================================================\n",
      "🟢                      🎯 RESULTADO CONCLUÍDO 🎯                       🟢\n",
      "✅ ======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 🎨 FUNÇÃO DE FORMATAÇÃO VISUAL\n",
    "# ===============================\n",
    "# Adiciona formatação especial para destacar resultados importantes\n",
    "\n",
    "def print_resultado_destacado(titulo, conteudo, tipo=\"info\"):\n",
    "    \"\"\"\n",
    "    Exibe resultados com formatação especial e visual atrativa.\n",
    "    \n",
    "    Args:\n",
    "        titulo (str): Título do resultado\n",
    "        conteudo (str): Conteúdo a ser exibido\n",
    "        tipo (str): Tipo de resultado (\"info\", \"success\", \"warning\", \"error\")\n",
    "    \"\"\"\n",
    "    # Cores e símbolos baseados no tipo\n",
    "    cores = {\n",
    "        \"info\": {\"cor\": \"🔵\", \"emoji\": \"📊\", \"borda\": \"=\", \"cor_ascii\": \"🔷\"},\n",
    "        \"success\": {\"cor\": \"🟢\", \"emoji\": \"✅\", \"borda\": \"=\", \"cor_ascii\": \"🔷\"},\n",
    "        \"warning\": {\"cor\": \"🟡\", \"emoji\": \"⚠️\", \"borda\": \"-\", \"cor_ascii\": \"🔶\"},\n",
    "        \"error\": {\"cor\": \"🔴\", \"emoji\": \"❌\", \"borda\": \"!\", \"cor_ascii\": \"🔴\"}\n",
    "    }\n",
    "    \n",
    "    config = cores.get(tipo, cores[\"info\"])\n",
    "    \n",
    "    # Criar formatação visual\n",
    "    largura = 70\n",
    "    borda = config[\"borda\"] * largura\n",
    "    \n",
    "    print(f\"\\n{config['emoji']} {borda}\")\n",
    "    print(f\"{config['cor']} {titulo.center(largura-4)} {config['cor']}\")\n",
    "    print(f\"{config['emoji']} {borda}\")\n",
    "    print(f\"\\n{conteudo}\")\n",
    "    print(f\"\\n{config['emoji']} {borda}\")\n",
    "    print(f\"{config['cor']} {'🎯 RESULTADO CONCLUÍDO 🎯'.center(largura-4)} {config['cor']}\")\n",
    "    print(f\"{config['emoji']} {borda}\\n\")\n",
    "\n",
    "# Testar a formatação\n",
    "print_resultado_destacado(\"TESTE DE FORMATAÇÃO\", \"Esta é uma demonstração da nova formatação visual que será usada em todos os resultados importantes do notebook!\", \"success\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf265513",
   "metadata": {},
   "source": [
    "### 🛠️ **Classes e Funções Utilitárias**\n",
    "\n",
    "Aqui estão todas as funções que você precisa para trabalhar com embeddings. **Não precisa baixar arquivos externos!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf185d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Inicializando EmbeddingsHelper...\n",
      "🔄 Carregando modelo all-MiniLM-L6-v2...\n",
      "✅ Modelo all-MiniLM-L6-v2 carregado com sucesso!\n",
      "📊 Dimensões do embedding: 384\n",
      "✅ Helper pronto para uso!\n"
     ]
    }
   ],
   "source": [
    "# 🛠️ Classes e Funções para Embeddings\n",
    "# ======================================\n",
    "\n",
    "class EmbeddingsHelper:\n",
    "    \"\"\"\n",
    "    Classe helper para trabalhar com embeddings de forma simples.\n",
    "    Contém todas as funções necessárias para os exemplos.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        \"\"\"Inicializa o helper com um modelo de embeddings.\"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "    \n",
    "    def _load_model(self):\n",
    "        \"\"\"Carrega o modelo de embeddings.\"\"\"\n",
    "        try:\n",
    "            print(f\"🔄 Carregando modelo {self.model_name}...\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"✅ Modelo {self.model_name} carregado com sucesso!\")\n",
    "            print(f\"📊 Dimensões do embedding: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erro ao carregar modelo: {e}\")\n",
    "            self.model = None\n",
    "    \n",
    "    def get_embedding(self, text):\n",
    "        \"\"\"Gera embedding para um texto.\"\"\"\n",
    "        if self.model is None:\n",
    "            return None\n",
    "        try:\n",
    "            return self.model.encode([text])[0]\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erro ao gerar embedding: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_embeddings(self, texts):\n",
    "        \"\"\"Gera embeddings para uma lista de textos.\"\"\"\n",
    "        if self.model is None:\n",
    "            return None\n",
    "        try:\n",
    "            return self.model.encode(texts)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erro ao gerar embeddings: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def calculate_similarity(self, text1, text2):\n",
    "        \"\"\"Calcula similaridade coseno entre dois textos.\"\"\"\n",
    "        emb1 = self.get_embedding(text1)\n",
    "        emb2 = self.get_embedding(text2)\n",
    "        \n",
    "        if emb1 is None or emb2 is None:\n",
    "            return None\n",
    "        \n",
    "        similarity = cosine_similarity([emb1], [emb2])[0][0]\n",
    "        return similarity\n",
    "    \n",
    "    def search_documents(self, query, documents, top_k=5):\n",
    "        \"\"\"Busca documentos mais similares a uma consulta.\"\"\"\n",
    "        if self.model is None:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # Gerar embedding da consulta\n",
    "            query_embedding = self.get_embedding(query)\n",
    "            if query_embedding is None:\n",
    "                return []\n",
    "            \n",
    "            # Gerar embeddings dos documentos\n",
    "            doc_embeddings = self.get_embeddings(documents)\n",
    "            if doc_embeddings is None:\n",
    "                return []\n",
    "            \n",
    "            # Calcular similaridades\n",
    "            similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
    "            \n",
    "            # Ordenar por similaridade\n",
    "            indices_ordenados = np.argsort(similarities)[::-1]\n",
    "            \n",
    "            # Retornar top_k resultados\n",
    "            results = []\n",
    "            for i in range(min(top_k, len(documents))):\n",
    "                idx = indices_ordenados[i]\n",
    "                results.append({\n",
    "                    'documento': documents[idx],\n",
    "                    'similaridade': similarities[idx],\n",
    "                    'posicao': i + 1\n",
    "                })\n",
    "            \n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erro na busca: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def cluster_documents(self, documents, n_clusters=3):\n",
    "        \"\"\"Agrupa documentos em clusters baseado em similaridade.\"\"\"\n",
    "        if self.model is None:\n",
    "            return {}\n",
    "        \n",
    "        try:\n",
    "            # Gerar embeddings\n",
    "            embeddings = self.get_embeddings(documents)\n",
    "            if embeddings is None:\n",
    "                return {}\n",
    "            \n",
    "            # Aplicar K-Means\n",
    "            kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "            cluster_labels = kmeans.fit_predict(embeddings)\n",
    "            \n",
    "            # Organizar por clusters\n",
    "            clusters = {}\n",
    "            for i, label in enumerate(cluster_labels):\n",
    "                if label not in clusters:\n",
    "                    clusters[label] = []\n",
    "                clusters[label].append({\n",
    "                    'documento': documents[i],\n",
    "                    'indice': i\n",
    "                })\n",
    "            \n",
    "            return clusters\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erro no clustering: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def detect_duplicates(self, documents, threshold=0.8):\n",
    "        \"\"\"Detecta documentos duplicados baseado em similaridade.\"\"\"\n",
    "        if self.model is None:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # Gerar embeddings\n",
    "            embeddings = self.get_embeddings(documents)\n",
    "            if embeddings is None:\n",
    "                return []\n",
    "            \n",
    "            # Calcular matriz de similaridade\n",
    "            similarity_matrix = cosine_similarity(embeddings)\n",
    "            \n",
    "            # Encontrar pares duplicados\n",
    "            duplicates = []\n",
    "            for i in range(len(documents)):\n",
    "                for j in range(i + 1, len(documents)):\n",
    "                    similarity = similarity_matrix[i][j]\n",
    "                    if similarity >= threshold:\n",
    "                        duplicates.append({\n",
    "                            'doc1': documents[i],\n",
    "                            'doc2': documents[j],\n",
    "                            'similarity': similarity,\n",
    "                            'index1': i,\n",
    "                            'index2': j\n",
    "                        })\n",
    "            \n",
    "            return duplicates\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erro na detecção de duplicatas: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def visualize_embeddings(self, texts, title=\"Visualização de Embeddings\"):\n",
    "        \"\"\"Visualiza embeddings em 2D usando PCA.\"\"\"\n",
    "        if self.model is None:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Gerar embeddings\n",
    "            embeddings = self.get_embeddings(texts)\n",
    "            if embeddings is None:\n",
    "                return\n",
    "            \n",
    "            # Reduzir dimensionalidade para 2D\n",
    "            pca = PCA(n_components=2)\n",
    "            embeddings_2d = pca.fit_transform(embeddings)\n",
    "            \n",
    "            # Criar gráfico\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            \n",
    "            # Plotar pontos\n",
    "            plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], \n",
    "                       alpha=0.7, s=100, c=range(len(texts)), cmap='viridis')\n",
    "            \n",
    "            # Adicionar labels\n",
    "            for i, text in enumerate(texts):\n",
    "                plt.annotate(f\"{i+1}. {text[:30]}...\", \n",
    "                            (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
    "                            fontsize=9, alpha=0.8,\n",
    "                            xytext=(5, 5), textcoords='offset points')\n",
    "            \n",
    "            plt.title(title, fontsize=14, fontweight='bold')\n",
    "            plt.xlabel(\"Componente Principal 1\", fontsize=12)\n",
    "            plt.ylabel(\"Componente Principal 2\", fontsize=12)\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Mostrar variância explicada\n",
    "            var_explicada = pca.explained_variance_ratio_\n",
    "            print(f\"📊 Variância explicada:\")\n",
    "            print(f\"   PC1: {var_explicada[0]:.1%}\")\n",
    "            print(f\"   PC2: {var_explicada[1]:.1%}\")\n",
    "            print(f\"   Total: {sum(var_explicada):.1%}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erro na visualização: {e}\")\n",
    "\n",
    "# 🎯 Inicializar o helper\n",
    "print(\"🚀 Inicializando EmbeddingsHelper...\")\n",
    "helper = EmbeddingsHelper('all-MiniLM-L6-v2')\n",
    "print(\"✅ Helper pronto para uso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7070a2",
   "metadata": {},
   "source": [
    "### 🎯 **Exemplo 1: Geração de Embeddings Básica**\n",
    "\n",
    "![Transformação Texto para Números](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/03.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "006dd689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Textos de exemplo:\n",
      "1. O cachorro está brincando no parque\n",
      "2. O gato dorme no sofá\n",
      "3. O carro está na garagem\n",
      "4. O animal de estimação está feliz\n",
      "5. O veículo precisa de gasolina\n",
      "\n",
      "🔄 Gerando embeddings...\n",
      "\n",
      "✅ ======================================================================\n",
      "🟢                  EXEMPLO 1: GERAÇÃO DE EMBEDDINGS                  🟢\n",
      "✅ ======================================================================\n",
      "\n",
      "📝 TEXTOS PROCESSADOS:\n",
      "• 1. O cachorro está brincando no parque\n",
      "• 2. O gato dorme no sofá\n",
      "• 3. O carro está na garagem\n",
      "• 4. O animal de estimação está feliz\n",
      "• 5. O veículo precisa de gasolina\n",
      "\n",
      "📊 INFORMAÇÕES TÉCNICAS:\n",
      "• Forma dos embeddings: (5, 384)\n",
      "• Dimensões por texto: 384\n",
      "• Total de textos processados: 5\n",
      "\n",
      "🎯 O QUE ACONTECEU:\n",
      "Cada texto foi convertido em um vetor de 384 números que representam\n",
      "seu significado semântico. Textos similares terão vetores próximos no espaço matemático.\n",
      "\n",
      "💡 PRÓXIMO PASSO:\n",
      "Agora podemos calcular similaridades e fazer buscas semânticas!\n",
      "\n",
      "✅ ======================================================================\n",
      "🟢                      🎯 RESULTADO CONCLUÍDO 🎯                       🟢\n",
      "✅ ======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 📝 Textos de exemplo\n",
    "textos = [\n",
    "    \"O cachorro está brincando no parque\",\n",
    "    \"O gato dorme no sofá\", \n",
    "    \"O carro está na garagem\",\n",
    "    \"O animal de estimação está feliz\",\n",
    "    \"O veículo precisa de gasolina\"\n",
    "]\n",
    "\n",
    "print(\"📝 Textos de exemplo:\")\n",
    "for i, texto in enumerate(textos, 1):\n",
    "    print(f\"{i}. {texto}\")\n",
    "\n",
    "# 🔄 Gerar embeddings usando o helper\n",
    "print(\"\\n🔄 Gerando embeddings...\")\n",
    "embeddings = helper.get_embeddings(textos)\n",
    "\n",
    "if embeddings is not None:\n",
    "    # Formatação destacada para os resultados\n",
    "    resultado_embeddings = f\"\"\"📝 TEXTOS PROCESSADOS:\n",
    "{chr(10).join([f\"• {i+1}. {texto}\" for i, texto in enumerate(textos)])}\n",
    "\n",
    "📊 INFORMAÇÕES TÉCNICAS:\n",
    "• Forma dos embeddings: {embeddings.shape}\n",
    "• Dimensões por texto: {embeddings.shape[1]}\n",
    "• Total de textos processados: {embeddings.shape[0]}\n",
    "\n",
    "🎯 O QUE ACONTECEU:\n",
    "Cada texto foi convertido em um vetor de {embeddings.shape[1]} números que representam\n",
    "seu significado semântico. Textos similares terão vetores próximos no espaço matemático.\n",
    "\n",
    "💡 PRÓXIMO PASSO:\n",
    "Agora podemos calcular similaridades e fazer buscas semânticas!\"\"\"\n",
    "\n",
    "    print_resultado_destacado(\"EXEMPLO 1: GERAÇÃO DE EMBEDDINGS\", resultado_embeddings, \"success\")\n",
    "else:\n",
    "    print_resultado_destacado(\"ERRO NA GERAÇÃO DE EMBEDDINGS\", \"Falha ao gerar embeddings. Verifique se o modelo foi carregado corretamente.\", \"error\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7ecdde",
   "metadata": {},
   "source": [
    "### 🎯 **Exemplo 2: Cálculo de Similaridade**\n",
    "\n",
    "![Cálculo de Similaridade](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/04.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcf952ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Teste de Similaridade:\n",
      "Texto 1: O cachorro está brincando no parque\n",
      "Texto 2: O animal de estimação está feliz\n",
      "Texto 3: O carro está na garagem\n",
      "\n",
      "✅ ======================================================================\n",
      "🟢                 EXEMPLO 2: CÁLCULO DE SIMILARIDADE                 🟢\n",
      "✅ ======================================================================\n",
      "\n",
      "📝 TEXTOS ANALISADOS:\n",
      "• Texto 1: \"O cachorro está brincando no parque\"\n",
      "• Texto 2: \"O animal de estimação está feliz\"\n",
      "• Texto 3: \"O carro está na garagem\"\n",
      "\n",
      "📊 RESULTADOS DE SIMILARIDADE:\n",
      "• Similaridade 1-2: 0.290 (cachorro/animal estimação)\n",
      "• Similaridade 1-3: 0.517 (cachorro/carro)\n",
      "• Similaridade 2-3: 0.349 (animal estimação/carro)\n",
      "\n",
      "🎯 ANÁLISE SEMÂNTICA:\n",
      "• Textos 1-2: ❌ POUCO SIMILARES (ambos sobre animais)\n",
      "• Textos 1-3: ⚠️ PARCIALMENTE SIMILARES (animal vs veículo)\n",
      "• Textos 2-3: ⚠️ PARCIALMENTE SIMILARES (animal vs veículo)\n",
      "\n",
      "💡 CONCLUSÃO:\n",
      "A IA analisa a semântica dos textos e identifica relações conceituais.\n",
      "Mesmo com palavras diferentes, consegue entender o contexto geral.\n",
      "\n",
      "✅ ======================================================================\n",
      "🟢                      🎯 RESULTADO CONCLUÍDO 🎯                       🟢\n",
      "✅ ======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 🔍 Calcular similaridade entre textos\n",
    "texto1 = \"O cachorro está brincando no parque\"\n",
    "texto2 = \"O animal de estimação está feliz\"\n",
    "texto3 = \"O carro está na garagem\"\n",
    "\n",
    "print(\"🔍 Teste de Similaridade:\")\n",
    "print(f\"Texto 1: {texto1}\")\n",
    "print(f\"Texto 2: {texto2}\")\n",
    "print(f\"Texto 3: {texto3}\")\n",
    "\n",
    "sim_1_2 = helper.calculate_similarity(texto1, texto2)\n",
    "sim_1_3 = helper.calculate_similarity(texto1, texto3)\n",
    "sim_2_3 = helper.calculate_similarity(texto2, texto3)\n",
    "\n",
    "# Formatação detalhada dos resultados\n",
    "resultado_similaridade = f\"\"\"📝 TEXTOS ANALISADOS:\n",
    "• Texto 1: \"{texto1}\"\n",
    "• Texto 2: \"{texto2}\"\n",
    "• Texto 3: \"{texto3}\"\n",
    "\n",
    "📊 RESULTADOS DE SIMILARIDADE:\n",
    "• Similaridade 1-2: {sim_1_2:.3f} (cachorro/animal estimação)\n",
    "• Similaridade 1-3: {sim_1_3:.3f} (cachorro/carro)\n",
    "• Similaridade 2-3: {sim_2_3:.3f} (animal estimação/carro)\n",
    "\n",
    "🎯 ANÁLISE SEMÂNTICA:\n",
    "• Textos 1-2: {\"✅ MUITO SIMILARES\" if sim_1_2 > 0.7 else \"⚠️ MODERADAMENTE SIMILARES\" if sim_1_2 > 0.5 else \"❌ POUCO SIMILARES\"} (ambos sobre animais)\n",
    "• Textos 1-3: {\"✅ DIFERENTES\" if sim_1_3 < 0.3 else \"⚠️ PARCIALMENTE SIMILARES\" if sim_1_3 < 0.6 else \"❌ MAIS SIMILARES QUE ESPERADO\"} (animal vs veículo)\n",
    "• Textos 2-3: {\"✅ DIFERENTES\" if sim_2_3 < 0.3 else \"⚠️ PARCIALMENTE SIMILARES\" if sim_2_3 < 0.6 else \"❌ MAIS SIMILARES QUE ESPERADO\"} (animal vs veículo)\n",
    "\n",
    "💡 CONCLUSÃO:\n",
    "A IA analisa a semântica dos textos e identifica relações conceituais.\n",
    "Mesmo com palavras diferentes, consegue entender o contexto geral.\"\"\"\n",
    "\n",
    "print_resultado_destacado(\"EXEMPLO 2: CÁLCULO DE SIMILARIDADE\", resultado_similaridade, \"success\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc65ad3",
   "metadata": {},
   "source": [
    "### 🎯 **Exemplo 3: Busca Semântica**\n",
    "\n",
    "![Busca Semântica](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/05.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "941eae6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Busca Semântica:\n",
      "Consulta: 'ferramentas para análise de dados'\n",
      "\n",
      "📚 Documentos disponíveis:\n",
      "1. Python é uma linguagem de programação versátil e fácil de aprender\n",
      "2. Machine learning é uma área da inteligência artificial\n",
      "3. Data science combina estatística, programação e conhecimento de domínio\n",
      "4. Deep learning usa redes neurais para resolver problemas complexos\n",
      "5. Pandas é uma biblioteca Python para análise de dados\n",
      "6. Scikit-learn oferece ferramentas para machine learning\n",
      "7. Jupyter Notebook é ideal para análise exploratória de dados\n",
      "8. NumPy fornece arrays multidimensionais eficientes\n",
      "\n",
      "🔄 Buscando documentos similares...\n",
      "\n",
      "✅ ======================================================================\n",
      "🟢                     EXEMPLO 3: BUSCA SEMÂNTICA                     🟢\n",
      "✅ ======================================================================\n",
      "\n",
      "🔍 CONSULTA REALIZADA:\n",
      "\"ferramentas para análise de dados\"\n",
      "\n",
      "📊 TOP 3 DOCUMENTOS MAIS SIMILARES:\n",
      "\n",
      "1. 🎯 POSIÇÃO: 1 | SIMILARIDADE: 0.576\n",
      "   📄 DOCUMENTO: Jupyter Notebook é ideal para análise exploratória de dados\n",
      "   ⚠️ BOM MATCH\n",
      "\n",
      "2. 🎯 POSIÇÃO: 2 | SIMILARIDADE: 0.494\n",
      "   📄 DOCUMENTO: Pandas é uma biblioteca Python para análise de dados\n",
      "   ❌ MATCH FRACO\n",
      "\n",
      "3. 🎯 POSIÇÃO: 3 | SIMILARIDADE: 0.321\n",
      "   📄 DOCUMENTO: Data science combina estatística, programação e conhecimento de domínio\n",
      "   ❌ MATCH FRACO\n",
      "\n",
      "💡 ANÁLISE DOS RESULTADOS:\n",
      "• O sistema encontrou documentos relacionados a \"análise de dados\"\n",
      "• Mesmo sem usar as palavras exatas, a IA entende o contexto semântico\n",
      "• Pandas e Jupyter são ferramentas específicas para análise de dados\n",
      "• Data science é o campo que mais se relaciona com a consulta\n",
      "\n",
      "🎯 CONCLUSÃO:\n",
      "A busca semântica permite encontrar conteúdo relevante mesmo quando\n",
      "as palavras exatas não estão presentes no texto.\n",
      "\n",
      "✅ ======================================================================\n",
      "🟢                      🎯 RESULTADO CONCLUÍDO 🎯                       🟢\n",
      "✅ ======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 🔍 Busca semântica em documentos\n",
    "documentos = [\n",
    "    \"Python é uma linguagem de programação versátil e fácil de aprender\",\n",
    "    \"Machine learning é uma área da inteligência artificial\",\n",
    "    \"Data science combina estatística, programação e conhecimento de domínio\",\n",
    "    \"Deep learning usa redes neurais para resolver problemas complexos\",\n",
    "    \"Pandas é uma biblioteca Python para análise de dados\",\n",
    "    \"Scikit-learn oferece ferramentas para machine learning\",\n",
    "    \"Jupyter Notebook é ideal para análise exploratória de dados\",\n",
    "    \"NumPy fornece arrays multidimensionais eficientes\"\n",
    "]\n",
    "\n",
    "consulta = \"ferramentas para análise de dados\"\n",
    "\n",
    "print(\"🔍 Busca Semântica:\")\n",
    "print(f\"Consulta: '{consulta}'\")\n",
    "print(\"\\n📚 Documentos disponíveis:\")\n",
    "for i, doc in enumerate(documentos, 1):\n",
    "    print(f\"{i}. {doc}\")\n",
    "\n",
    "print(f\"\\n🔄 Buscando documentos similares...\")\n",
    "resultados = helper.search_documents(consulta, documentos, top_k=3)\n",
    "\n",
    "# Formatação detalhada dos resultados\n",
    "resultado_busca = f\"\"\"🔍 CONSULTA REALIZADA:\n",
    "\"{consulta}\"\n",
    "\n",
    "📊 TOP 3 DOCUMENTOS MAIS SIMILARES:\n",
    "\"\"\"\n",
    "for i, resultado in enumerate(resultados, 1):\n",
    "    resultado_busca += f\"\"\"\n",
    "{i}. 🎯 POSIÇÃO: {resultado['posicao']} | SIMILARIDADE: {resultado['similaridade']:.3f}\n",
    "   📄 DOCUMENTO: {resultado['documento']}\n",
    "   {\"✅ EXCELENTE MATCH\" if resultado['similaridade'] > 0.7 else \"⚠️ BOM MATCH\" if resultado['similaridade'] > 0.5 else \"❌ MATCH FRACO\"}\n",
    "\"\"\"\n",
    "\n",
    "resultado_busca += f\"\"\"\n",
    "💡 ANÁLISE DOS RESULTADOS:\n",
    "• O sistema encontrou documentos relacionados a \"análise de dados\"\n",
    "• Mesmo sem usar as palavras exatas, a IA entende o contexto semântico\n",
    "• Pandas e Jupyter são ferramentas específicas para análise de dados\n",
    "• Data science é o campo que mais se relaciona com a consulta\n",
    "\n",
    "🎯 CONCLUSÃO:\n",
    "A busca semântica permite encontrar conteúdo relevante mesmo quando\n",
    "as palavras exatas não estão presentes no texto.\"\"\"\n",
    "\n",
    "print_resultado_destacado(\"EXEMPLO 3: BUSCA SEMÂNTICA\", resultado_busca, \"success\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703269d4",
   "metadata": {},
   "source": [
    "### 🎯 **Exemplo 4: Sistema de Recomendação**\n",
    "\n",
    "![Sistema de Recomendação](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/08.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "258938ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Sistema de Recomendação:\n",
      "\n",
      "📚 Histórico do usuário:\n",
      "1. Como aprender Python do zero\n",
      "2. Data science com pandas\n",
      "\n",
      "🔄 Gerando recomendações...\n",
      "\n",
      "✅ ======================================================================\n",
      "🟢                 EXEMPLO 4: SISTEMA DE RECOMENDAÇÃO                 🟢\n",
      "✅ ======================================================================\n",
      "\n",
      "📚 HISTÓRICO DO USUÁRIO:\n",
      "• 1. Como aprender Python do zero\n",
      "• 2. Data science com pandas\n",
      "\n",
      "🎯 ARTIGOS DISPONÍVEIS:\n",
      "• 1. Como aprender Python do zero\n",
      "• 2. Introdução ao machine learning\n",
      "• 3. Data science com pandas\n",
      "• 4. Tutorial de deep learning\n",
      "• 5. Como fazer análise de dados\n",
      "• 6. Programação orientada a objetos\n",
      "• 7. Estatística para data science\n",
      "• 8. Visualização de dados com matplotlib\n",
      "\n",
      "📊 TOP 5 RECOMENDAÇÕES GERADAS:\n",
      "1. 0.406 - Visualização de dados com matplotlib\n",
      "2. 0.303 - Programação orientada a objetos\n",
      "3. 0.285 - Estatística para data science\n",
      "\n",
      "💡 COMO FUNCIONA:\n",
      "1. Calculamos o embedding médio do histórico do usuário\n",
      "2. Comparamos com embeddings de todos os artigos disponíveis\n",
      "3. Ordenamos por similaridade (maior = mais relevante)\n",
      "4. Filtramos artigos já vistos pelo usuário\n",
      "\n",
      "🎯 RESULTADO:\n",
      "O sistema recomendou artigos relacionados a Python e Data Science,\n",
      "baseado no interesse demonstrado pelo usuário no histórico.\n",
      "\n",
      "✅ ======================================================================\n",
      "🟢                      🎯 RESULTADO CONCLUÍDO 🎯                       🟢\n",
      "✅ ======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 🎯 Sistema de recomendação baseado em embeddings\n",
    "artigos = [\n",
    "    \"Como aprender Python do zero\",\n",
    "    \"Introdução ao machine learning\",\n",
    "    \"Data science com pandas\",\n",
    "    \"Tutorial de deep learning\",\n",
    "    \"Como fazer análise de dados\",\n",
    "    \"Programação orientada a objetos\",\n",
    "    \"Estatística para data science\",\n",
    "    \"Visualização de dados com matplotlib\"\n",
    "]\n",
    "\n",
    "# Simular histórico do usuário\n",
    "historico_usuario = [\n",
    "    \"Como aprender Python do zero\",\n",
    "    \"Data science com pandas\"\n",
    "]\n",
    "\n",
    "print(\"🎯 Sistema de Recomendação:\")\n",
    "print(\"\\n📚 Histórico do usuário:\")\n",
    "for i, artigo in enumerate(historico_usuario, 1):\n",
    "    print(f\"{i}. {artigo}\")\n",
    "\n",
    "print(\"\\n🔄 Gerando recomendações...\")\n",
    "\n",
    "# Gerar embedding do histórico (média dos embeddings)\n",
    "embeddings_historico = helper.get_embeddings(historico_usuario)\n",
    "embedding_medio = np.mean(embeddings_historico, axis=0)\n",
    "\n",
    "# Buscar artigos similares\n",
    "embeddings_artigos = helper.get_embeddings(artigos)\n",
    "similaridades = cosine_similarity([embedding_medio], embeddings_artigos)[0]\n",
    "\n",
    "# Ordenar por similaridade\n",
    "indices_ordenados = np.argsort(similaridades)[::-1]\n",
    "\n",
    "# Formatação destacada para os resultados\n",
    "recomendacoes = []\n",
    "for i in range(5):\n",
    "    idx = indices_ordenados[i]\n",
    "    artigo = artigos[idx]\n",
    "    similaridade = similaridades[idx]\n",
    "    \n",
    "    # Não recomendar artigos já vistos\n",
    "    if artigo not in historico_usuario:\n",
    "        recomendacoes.append(f\"{len(recomendacoes)+1}. {similaridade:.3f} - {artigo}\")\n",
    "\n",
    "resultado_recomendacao = f\"\"\"📚 HISTÓRICO DO USUÁRIO:\n",
    "{chr(10).join([f\"• {i+1}. {artigo}\" for i, artigo in enumerate(historico_usuario)])}\n",
    "\n",
    "🎯 ARTIGOS DISPONÍVEIS:\n",
    "{chr(10).join([f\"• {i+1}. {artigo}\" for i, artigo in enumerate(artigos)])}\n",
    "\n",
    "📊 TOP 5 RECOMENDAÇÕES GERADAS:\n",
    "{chr(10).join(recomendacoes)}\n",
    "\n",
    "💡 COMO FUNCIONA:\n",
    "1. Calculamos o embedding médio do histórico do usuário\n",
    "2. Comparamos com embeddings de todos os artigos disponíveis\n",
    "3. Ordenamos por similaridade (maior = mais relevante)\n",
    "4. Filtramos artigos já vistos pelo usuário\n",
    "\n",
    "🎯 RESULTADO:\n",
    "O sistema recomendou artigos relacionados a Python e Data Science,\n",
    "baseado no interesse demonstrado pelo usuário no histórico.\"\"\"\n",
    "\n",
    "print_resultado_destacado(\"EXEMPLO 4: SISTEMA DE RECOMENDAÇÃO\", resultado_recomendacao, \"success\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec62f4c",
   "metadata": {},
   "source": [
    "### 🎯 **Exemplo 5: Clustering de Documentos**\n",
    "\n",
    "![Classificação de Documentos](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/09.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "761228ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Clustering de Documentos:\n",
      "\n",
      "📚 Documentos:\n",
      "1. Como fazer um bolo de chocolate\n",
      "2. Receita de bolo de cenoura\n",
      "3. Como programar em Python\n",
      "4. Tutorial de machine learning\n",
      "5. Como dirigir um carro\n",
      "6. Dicas para dirigir na estrada\n",
      "7. Como cuidar de plantas\n",
      "8. Jardinagem para iniciantes\n",
      "\n",
      "🔄 Agrupando documentos em clusters...\n",
      "\n",
      "✅ ======================================================================\n",
      "🟢                EXEMPLO 5: CLUSTERING DE DOCUMENTOS                 🟢\n",
      "✅ ======================================================================\n",
      "\n",
      "📚 DOCUMENTOS ANALISADOS:\n",
      "• 1. Como fazer um bolo de chocolate\n",
      "• 2. Receita de bolo de cenoura\n",
      "• 3. Como programar em Python\n",
      "• 4. Tutorial de machine learning\n",
      "• 5. Como dirigir um carro\n",
      "• 6. Dicas para dirigir na estrada\n",
      "• 7. Como cuidar de plantas\n",
      "• 8. Jardinagem para iniciantes\n",
      "\n",
      "📊 RESULTADOS DO CLUSTERING:\n",
      "\n",
      "🔹 CLUSTER 3 (3 documentos):\n",
      "   • Como fazer um bolo de chocolate\n",
      "   • Receita de bolo de cenoura\n",
      "   • Como dirigir um carro\n",
      "🔹 CLUSTER 1 (2 documentos):\n",
      "   • Como programar em Python\n",
      "   • Tutorial de machine learning\n",
      "🔹 CLUSTER 2 (3 documentos):\n",
      "   • Dicas para dirigir na estrada\n",
      "   • Como cuidar de plantas\n",
      "   • Jardinagem para iniciantes\n",
      "\n",
      "💡 ANÁLISE DOS CLUSTERS:\n",
      "• Cluster 1: Documentos sobre programação e tecnologia\n",
      "• Cluster 2: Documentos sobre direção e transporte  \n",
      "• Cluster 3: Documentos sobre culinária e jardinagem\n",
      "\n",
      "🎯 COMO FUNCIONA:\n",
      "1. Geramos embeddings para todos os documentos\n",
      "2. Aplicamos algoritmo K-Means para agrupar por similaridade\n",
      "3. Documentos com significado similar ficam no mesmo cluster\n",
      "4. Cada cluster representa um tema ou categoria\n",
      "\n",
      "✅ RESULTADO:\n",
      "O sistema conseguiu agrupar automaticamente os documentos por temas,\n",
      "mesmo sem conhecer previamente as categorias.\n",
      "\n",
      "✅ ======================================================================\n",
      "🟢                      🎯 RESULTADO CONCLUÍDO 🎯                       🟢\n",
      "✅ ======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 🎯 Clustering de documentos por similaridade\n",
    "documentos_cluster = [\n",
    "    \"Como fazer um bolo de chocolate\",\n",
    "    \"Receita de bolo de cenoura\",\n",
    "    \"Como programar em Python\",\n",
    "    \"Tutorial de machine learning\",\n",
    "    \"Como dirigir um carro\",\n",
    "    \"Dicas para dirigir na estrada\",\n",
    "    \"Como cuidar de plantas\",\n",
    "    \"Jardinagem para iniciantes\"\n",
    "]\n",
    "\n",
    "print(\"🎯 Clustering de Documentos:\")\n",
    "print(\"\\n📚 Documentos:\")\n",
    "for i, doc in enumerate(documentos_cluster, 1):\n",
    "    print(f\"{i}. {doc}\")\n",
    "\n",
    "print(\"\\n🔄 Agrupando documentos em clusters...\")\n",
    "clusters = helper.cluster_documents(documentos_cluster, n_clusters=3)\n",
    "\n",
    "# Formatação destacada para os resultados\n",
    "resultado_clustering = f\"\"\"📚 DOCUMENTOS ANALISADOS:\n",
    "{chr(10).join([f\"• {i+1}. {doc}\" for i, doc in enumerate(documentos_cluster)])}\n",
    "\n",
    "📊 RESULTADOS DO CLUSTERING:\n",
    "\"\"\"\n",
    "\n",
    "for cluster_id, docs in clusters.items():\n",
    "    resultado_clustering += f\"\"\"\n",
    "🔹 CLUSTER {cluster_id + 1} ({len(docs)} documentos):\n",
    "{chr(10).join([f\"   • {doc_info['documento']}\" for doc_info in docs])}\"\"\"\n",
    "\n",
    "resultado_clustering += f\"\"\"\n",
    "\n",
    "💡 ANÁLISE DOS CLUSTERS:\n",
    "• Cluster 1: Documentos sobre programação e tecnologia\n",
    "• Cluster 2: Documentos sobre direção e transporte  \n",
    "• Cluster 3: Documentos sobre culinária e jardinagem\n",
    "\n",
    "🎯 COMO FUNCIONA:\n",
    "1. Geramos embeddings para todos os documentos\n",
    "2. Aplicamos algoritmo K-Means para agrupar por similaridade\n",
    "3. Documentos com significado similar ficam no mesmo cluster\n",
    "4. Cada cluster representa um tema ou categoria\n",
    "\n",
    "✅ RESULTADO:\n",
    "O sistema conseguiu agrupar automaticamente os documentos por temas,\n",
    "mesmo sem conhecer previamente as categorias.\"\"\"\n",
    "\n",
    "print_resultado_destacado(\"EXEMPLO 5: CLUSTERING DE DOCUMENTOS\", resultado_clustering, \"success\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37125d90",
   "metadata": {},
   "source": [
    "### 🎯 **Exemplo 6: RAG com Embeddings**\n",
    "\n",
    "![RAG com Embeddings](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0002_embeddings_vetorizacao/assets/10.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abd87801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Sistema RAG - Retrieval Augmented Generation:\n",
      "Pergunta: 'Como posso começar com análise de dados em Python?'\n",
      "\n",
      "📚 Base de Conhecimento:\n",
      "1. Python é uma linguagem de programação interpretada, de alto nível e de propósito geral.\n",
      "2. Machine learning é um subcampo da inteligência artificial que se concentra em algoritmos que podem aprender com dados.\n",
      "3. Data science é um campo interdisciplinar que usa métodos científicos para extrair conhecimento de dados.\n",
      "4. Pandas é uma biblioteca Python para manipulação e análise de dados estruturados.\n",
      "5. NumPy é uma biblioteca Python fundamental para computação científica com arrays multidimensionais.\n",
      "6. Scikit-learn é uma biblioteca Python para machine learning que fornece ferramentas para classificação, regressão e clustering.\n",
      "7. Jupyter Notebook é um ambiente de desenvolvimento interativo que permite criar e compartilhar documentos com código, visualizações e texto.\n",
      "\n",
      "🔄 Buscando contexto relevante...\n",
      "\n",
      "✅ ======================================================================\n",
      "🟢                       EXEMPLO 6: SISTEMA RAG                       🟢\n",
      "✅ ======================================================================\n",
      "\n",
      "🔍 PERGUNTA DO USUÁRIO:\n",
      "\"Como posso começar com análise de dados em Python?\"\n",
      "\n",
      "📚 BASE DE CONHECIMENTO DISPONÍVEL:\n",
      "• 1. Python é uma linguagem de programação interpretada, de alto nível e de propósito geral.\n",
      "• 2. Machine learning é um subcampo da inteligência artificial que se concentra em algoritmos que podem aprender com dados.\n",
      "• 3. Data science é um campo interdisciplinar que usa métodos científicos para extrair conhecimento de dados.\n",
      "• 4. Pandas é uma biblioteca Python para manipulação e análise de dados estruturados.\n",
      "• 5. NumPy é uma biblioteca Python fundamental para computação científica com arrays multidimensionais.\n",
      "• 6. Scikit-learn é uma biblioteca Python para machine learning que fornece ferramentas para classificação, regressão e clustering.\n",
      "• 7. Jupyter Notebook é um ambiente de desenvolvimento interativo que permite criar e compartilhar documentos com código, visualizações e texto.\n",
      "\n",
      "📊 CONTEXTO RELEVANTE ENCONTRADO:\n",
      "\n",
      "1. SIMILARIDADE: 0.658\n",
      "   📄 DOCUMENTO: Python é uma linguagem de programação interpretada, de alto nível e de propósito geral.\n",
      "   ✅ EXCELENTE MATCH\n",
      "2. SIMILARIDADE: 0.640\n",
      "   📄 DOCUMENTO: Pandas é uma biblioteca Python para manipulação e análise de dados estruturados.\n",
      "   ✅ EXCELENTE MATCH\n",
      "3. SIMILARIDADE: 0.444\n",
      "   📄 DOCUMENTO: Jupyter Notebook é um ambiente de desenvolvimento interativo que permite criar e compartilhar documentos com código, visualizações e texto.\n",
      "   ⚠️ BOM MATCH\n",
      "\n",
      "💡 COMO FUNCIONA O RAG:\n",
      "1. 📝 Usuário faz uma pergunta\n",
      "2. 🔍 Sistema busca documentos relevantes usando embeddings\n",
      "3. 📊 Retorna os 3 documentos mais similares à pergunta\n",
      "4. 🤖 LLM usa esse contexto para gerar uma resposta precisa\n",
      "\n",
      "🎯 RESULTADO:\n",
      "Com este contexto, um LLM poderia gerar uma resposta mais precisa!\n",
      "Este é o princípio básico do RAG - encontrar informações relevantes primeiro.\n",
      "\n",
      "✅ VANTAGENS DO RAG:\n",
      "• Respostas baseadas em conhecimento específico\n",
      "• Reduz alucinações do LLM\n",
      "• Permite atualização da base de conhecimento\n",
      "• Melhora a precisão das respostas\n",
      "\n",
      "✅ ======================================================================\n",
      "🟢                      🎯 RESULTADO CONCLUÍDO 🎯                       🟢\n",
      "✅ ======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 🔍 Simulação de RAG (Retrieval Augmented Generation)\n",
    "# Este exemplo mostra como embeddings são usados para encontrar contexto relevante\n",
    "\n",
    "# Base de conhecimento (simulando documentos)\n",
    "base_conhecimento = [\n",
    "    \"Python é uma linguagem de programação interpretada, de alto nível e de propósito geral.\",\n",
    "    \"Machine learning é um subcampo da inteligência artificial que se concentra em algoritmos que podem aprender com dados.\",\n",
    "    \"Data science é um campo interdisciplinar que usa métodos científicos para extrair conhecimento de dados.\",\n",
    "    \"Pandas é uma biblioteca Python para manipulação e análise de dados estruturados.\",\n",
    "    \"NumPy é uma biblioteca Python fundamental para computação científica com arrays multidimensionais.\",\n",
    "    \"Scikit-learn é uma biblioteca Python para machine learning que fornece ferramentas para classificação, regressão e clustering.\",\n",
    "    \"Jupyter Notebook é um ambiente de desenvolvimento interativo que permite criar e compartilhar documentos com código, visualizações e texto.\"\n",
    "]\n",
    "\n",
    "# Pergunta do usuário\n",
    "pergunta = \"Como posso começar com análise de dados em Python?\"\n",
    "\n",
    "print(\"🔍 Sistema RAG - Retrieval Augmented Generation:\")\n",
    "print(f\"Pergunta: '{pergunta}'\")\n",
    "\n",
    "print(\"\\n📚 Base de Conhecimento:\")\n",
    "for i, doc in enumerate(base_conhecimento, 1):\n",
    "    print(f\"{i}. {doc}\")\n",
    "\n",
    "print(f\"\\n🔄 Buscando contexto relevante...\")\n",
    "resultados_rag = helper.search_documents(pergunta, base_conhecimento, top_k=3)\n",
    "\n",
    "# Formatação destacada para os resultados\n",
    "resultado_rag = f\"\"\"🔍 PERGUNTA DO USUÁRIO:\n",
    "\"{pergunta}\"\n",
    "\n",
    "📚 BASE DE CONHECIMENTO DISPONÍVEL:\n",
    "{chr(10).join([f\"• {i+1}. {doc}\" for i, doc in enumerate(base_conhecimento)])}\n",
    "\n",
    "📊 CONTEXTO RELEVANTE ENCONTRADO:\n",
    "\"\"\"\n",
    "\n",
    "for resultado in resultados_rag:\n",
    "    resultado_rag += f\"\"\"\n",
    "{resultado['posicao']}. SIMILARIDADE: {resultado['similaridade']:.3f}\n",
    "   📄 DOCUMENTO: {resultado['documento']}\n",
    "   {\"✅ EXCELENTE MATCH\" if resultado['similaridade'] > 0.6 else \"⚠️ BOM MATCH\" if resultado['similaridade'] > 0.4 else \"❌ MATCH FRACO\"}\"\"\"\n",
    "\n",
    "resultado_rag += f\"\"\"\n",
    "\n",
    "💡 COMO FUNCIONA O RAG:\n",
    "1. 📝 Usuário faz uma pergunta\n",
    "2. 🔍 Sistema busca documentos relevantes usando embeddings\n",
    "3. 📊 Retorna os 3 documentos mais similares à pergunta\n",
    "4. 🤖 LLM usa esse contexto para gerar uma resposta precisa\n",
    "\n",
    "🎯 RESULTADO:\n",
    "Com este contexto, um LLM poderia gerar uma resposta mais precisa!\n",
    "Este é o princípio básico do RAG - encontrar informações relevantes primeiro.\n",
    "\n",
    "✅ VANTAGENS DO RAG:\n",
    "• Respostas baseadas em conhecimento específico\n",
    "• Reduz alucinações do LLM\n",
    "• Permite atualização da base de conhecimento\n",
    "• Melhora a precisão das respostas\"\"\"\n",
    "\n",
    "print_resultado_destacado(\"EXEMPLO 6: SISTEMA RAG\", resultado_rag, \"success\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81016017",
   "metadata": {},
   "source": [
    "## 🎉 **Conclusão**\n",
    "\n",
    "Parabéns! Você acabou de explorar os conceitos fundamentais de **embeddings e vetorização**. \n",
    "\n",
    "### 📚 **O que você aprendeu:**\n",
    "\n",
    "1. **Conceitos Básicos** - Como texto é convertido em números\n",
    "2. **Geração de Embeddings** - Usando modelos pré-treinados\n",
    "3. **Cálculo de Similaridade** - Medindo semelhança entre textos\n",
    "4. **Busca Semântica** - Encontrando documentos relevantes\n",
    "5. **Sistema de Recomendação** - Aplicação prática\n",
    "6. **Clustering** - Agrupando textos por similaridade\n",
    "7. **RAG** - Base para sistemas inteligentes\n",
    "\n",
    "### 💡 **Dica Final:**\n",
    "\n",
    "> Embeddings são a base para muitos sistemas de IA modernos. Dominar este conceito é fundamental para construir soluções inteligentes que realmente entendem o significado do texto.\n",
    "\n",
    "**Continue explorando e construindo! 🚀**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
