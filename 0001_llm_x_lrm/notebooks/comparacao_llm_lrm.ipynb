{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/pathbit/pathbit-academy-ai/blob/master/0001_llm_x_lrm%20/notebooks/comparacao_llm_lrm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CWaJaNkr5JB"
   },
   "source": [
    "# ‚ú® **Pathbit Academy AI**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xv670htP1LDr"
   },
   "source": [
    "üö® **IMPORTANTE:**\n",
    "\n",
    "*üí• QUALQUER PESSOA QUE CONSIGA RESOLVER A EQUA√á√ÉO `2 + 2 = ?` PODE CONTINUAR OS PASSOS ABAIXO*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IjPFjjMwyR7a"
   },
   "source": [
    "**Artigo de refer√™ncia:** [https://github.com/pathbit/pathbit-academy-ai/blob/master/0001_llm_x_lrm/article/ARTICLE.md](https://github.com/pathbit/pathbit-academy-ai/blob/master/0001_llm_x_lrm/article/ARTICLE.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVCGcybMsiqE"
   },
   "source": [
    "### ÷é **Compara√ß√£o LLM vs LRM**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtuur6nhxuec"
   },
   "source": [
    "#### ‚ÅâÔ∏è O que √© LLM de forma pr√°tica?\n",
    "\n",
    "**Foco:** gera√ß√£o de linguagem natural.\n",
    "Treinamento: enormes volumes de texto para aprender padr√µes lingu√≠sticos.\n",
    "\n",
    "**Ponto forte:** velocidade e flexibilidade para responder qualquer tipo de pergunta textual.\n",
    "\n",
    "**Ponto fraco:** racioc√≠nio profundo e consist√™ncia em decis√µes complexas.\n",
    "\n",
    "\n",
    "#### ‚ÅâÔ∏è O que √© LRM de forma pr√°tica?\n",
    "\n",
    "**Foco:** racioc√≠nio estruturado e resolu√ß√£o de problemas.\n",
    "Treinamento: combina dados textuais com t√©cnicas que for√ßam o modelo a explicar e validar seu racioc√≠nio (cadeia de pensamento, decomposi√ß√£o de problemas, verifica√ß√£o de hip√≥teses).\n",
    "\n",
    "**Ponto forte:** consist√™ncia em tomadas de decis√£o complexas.\n",
    "\n",
    "**Ponto fraco:** pode ser mais lento e caro que um LLM para tarefas simples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UR5UUSs1vSa9"
   },
   "source": [
    "#### ‚õ≥ Cria√ß√£o de conta no Groq\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZ0vnkOtvX_K"
   },
   "source": [
    "##### ‚ñ∂ Acessar o site abaixo para criar sua conta\n",
    "\n",
    "**[Groq.com](https://console.groq.com/)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwSYsld9wklD"
   },
   "source": [
    "##### ‚ñ∂ Criar uma `API KEY` para a sua conta\n",
    "\n",
    "![Cria√ß√£o API KEY](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0001_llm_x_lrm/assets/01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hW3KkWLhwmAF"
   },
   "source": [
    "##### ‚ñ∂ Copiar e salvar a Api Key em um lugar seguro\n",
    "\n",
    "> **Observa√ß√µes**: *Voc√™ pode acessar Api Keys criados atrav√©s deste link: [https://console.groq.com/keys](https://console.groq.com/keys)*\n",
    "\n",
    "![Copiar API KEY](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0001_llm_x_lrm/assets/02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBz8FBEFzVrg"
   },
   "source": [
    "##### ‚ñ∂ Adicionar a Api Key criada nas `secrets` do seu Notebook\n",
    "\n",
    "![Adicionar API KEY no Secrets](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0001_llm_x_lrm/assets/03.png)\n",
    "\n",
    "\n",
    "![Adicionar API KEY no Secrets](https://raw.githubusercontent.com/pathbit/pathbit-academy-ai/refs/heads/master/0001_llm_x_lrm/assets/04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqiwoNKc1GOU"
   },
   "source": [
    "#### ‚öôÔ∏è Configura√ß√£o do ambiente\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ñ∂ Corre√ß√£o autom√°tica para Google Colab\n",
    "\n",
    "üö® **IMPORTANTE:** Se voc√™ estiver executando no Google Colab, esta c√©lula corrige automaticamente problemas de compatibilidade do `tqdm`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß CORRE√á√ÉO AUTOM√ÅTICA PARA GOOGLE COLAB\n",
    "# ==========================================\n",
    "# Esta c√©lula resolve automaticamente conflitos de depend√™ncias do tqdm\n",
    "\n",
    "# Detectar se estamos no Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"üåê Detectado: Google Colab\")\n",
    "    print(\"üîß Aplicando corre√ß√£o para conflito de tqdm...\")\n",
    "    \n",
    "    # CORRE√á√ÉO: Atualizar tqdm para resolver conflitos de depend√™ncias\n",
    "    get_ipython().run_line_magic('pip', 'install --upgrade tqdm>=4.67 --force-reinstall --quiet')\n",
    "    print(\"‚úÖ tqdm atualizado com sucesso!\")\n",
    "    print(\"üì¶ Vers√£o do tqdm corrigida para resolver conflitos com datasets e dataproc-spark-connect\")\n",
    "    \n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"üíª Detectado: Ambiente Local\")\n",
    "    print(\"‚ÑπÔ∏è  Corre√ß√£o do tqdm n√£o necess√°ria no ambiente local\")\n",
    "\n",
    "print(\"\\nüéØ Ambiente configurado! Continue com a pr√≥xima c√©lula.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBglR7um29yg"
   },
   "source": [
    "##### ‚ñ∂ Instalar os pacotes que iremos utilizar neste projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ñ∂ Instalar depend√™ncias do projeto\n",
    "\n",
    "üì¶ **Instala√ß√£o das bibliotecas necess√°rias para o projeto.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ INSTALA√á√ÉO DAS DEPEND√äNCIAS\n",
    "# ===============================\n",
    "# Instala√ß√£o das bibliotecas necess√°rias para o projeto\n",
    "\n",
    "# Verificar a vers√£o do python\n",
    "import sys\n",
    "import os\n",
    "import site\n",
    "\n",
    "print(\"üìä Informa√ß√µes do ambiente:\")\n",
    "print(\"Caminho do Python:\", sys.executable)\n",
    "print(\"Vers√£o do Python:\", sys.version)\n",
    "print(\"PATH:\", os.environ.get('PATH', 'N√£o encontrado'))\n",
    "print(\"Sites de pacotes:\", site.getsitepackages())\n",
    "\n",
    "# Instalar a biblioteca do groq\n",
    "print(\"\\nüì¶ Instalando depend√™ncias...\")\n",
    "if IN_COLAB:\n",
    "    get_ipython().run_line_magic('pip', 'install -q groq')\n",
    "else:\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"groq\"])\n",
    "\n",
    "print(\"‚úÖ Instala√ß√£o conclu√≠da!\")\n",
    "print(\"üöÄ Pronto para usar a API do Groq!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zC78TBpW-9J_",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caminho do Python: /Users/elielsousa/Projects/pathbit/github/pathbit-academy-ai/0001_llm_x_lrm/.venv/bin/python3.12\n",
      "Vers√£o do Python: 3.12.7 (main, Oct 25 2024, 15:25:54) [Clang 16.0.0 (clang-1600.0.26.3)]\n",
      "PATH: /Users/elielsousa/Projects/pathbit/github/pathbit-academy-ai/0001_llm_x_lrm/.venv/bin:/Users/elielsousa/.codeium/windsurf/bin:/opt/homebrew/opt/openjdk@17/bin:/opt/homebrew/opt/ruby/bin:/Users/elielsousa/.gvm/pkgsets/go1.24.3/global/bin:/Users/elielsousa/.gvm/gos/go1.24.3/bin:/Users/elielsousa/.gvm/pkgsets/go1.24.3/global/overlay/bin:/Users/elielsousa/.gvm/bin:/Users/elielsousa/.pyenv/shims:/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/Library/Apple/usr/bin:/usr/local/share/dotnet:~/.dotnet/tools:/Users/elielsousa/.codeium/windsurf/bin:/opt/homebrew/opt/openjdk@17/bin:/opt/homebrew/opt/ruby/bin:/Users/elielsousa/.dotnet/tools:/Users/elielsousa/Library/Android/sdk/tools:/Users/elielsousa/Library/Android/sdk/platform-tools:/Users/elielsousa/.cursor/extensions/ms-python.debugpy-2025.10.0-darwin-arm64/bundled/scripts/noConfigScripts:/Users/elielsousa/Library/Android/sdk/tools:/Users/elielsousa/Library/Android/sdk/platform-tools\n",
      "Sites de pacotes: ['/Users/elielsousa/Projects/pathbit/github/pathbit-academy-ai/0001_llm_x_lrm/.venv/lib/python3.12/site-packages']\n"
     ]
    }
   ],
   "source": [
    "# üîß Corre√ß√£o autom√°tica para Google Colab\n",
    "# ==========================================\n",
    "\n",
    "# Detectar se estamos no Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"üåê Detectado: Google Colab\")\n",
    "    \n",
    "    # üîß CORRE√á√ÉO: Atualizar tqdm para resolver conflitos de depend√™ncias\n",
    "    print(\"üîß Aplicando corre√ß√£o para conflito de tqdm...\")\n",
    "    %pip install --upgrade tqdm>=4.67 --force-reinstall --quiet\n",
    "    print(\"‚úÖ tqdm atualizado com sucesso!\")\n",
    "    \n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"üíª Detectado: Ambiente Local\")\n",
    "\n",
    "# Verificar a vers√£o do python\n",
    "import sys\n",
    "import os\n",
    "import site\n",
    "\n",
    "print(\"\\nüìä Informa√ß√µes do ambiente:\")\n",
    "print(\"Caminho do Python:\", sys.executable)\n",
    "print(\"Vers√£o do Python:\", sys.version)\n",
    "print(\"PATH:\", os.environ.get('PATH', 'N√£o encontrado'))\n",
    "print(\"Sites de pacotes:\", site.getsitepackages())\n",
    "\n",
    "# Instalar a biblioteca do groq\n",
    "print(\"\\nüì¶ Instalando depend√™ncias...\")\n",
    "%pip install -q groq\n",
    "\n",
    "print(\"‚úÖ Instala√ß√£o conclu√≠da!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMx9g-Xf3pae"
   },
   "source": [
    "##### ‚ñ∂ Criar e recuperar a vari√°vel de ambiente para utilizar no Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KRkCX4pC3p3P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configura√ß√£o local carregada\n",
      "‚úÖ GROQ_API_KEY: gsk_P1******\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üöÄ Configura√ß√£o para execu√ß√£o local e Colab\n",
    "# ============================================\n",
    "\n",
    "# Adicionar o diret√≥rio src ao path para importar m√≥dulos locais\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Constante com o nome da secret adicionada no Notebook\n",
    "GROQ_API_KEY_NAME = \"GROQ_API_KEY\"\n",
    "\n",
    "# Importar configura√ß√£o local\n",
    "try:\n",
    "    from config_local import configurar_api_key, exibir_markdown, exibir_resposta_formatada\n",
    "    print(\"‚úÖ Configura√ß√£o local carregada\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  Executando em modo Colab\")\n",
    "    \n",
    "    # Fun√ß√µes para Colab\n",
    "    def configurar_api_key():\n",
    "        from google.colab import userdata\n",
    "        try:\n",
    "            groq_api_key = userdata.get(GROQ_API_KEY_NAME)\n",
    "            os.environ[GROQ_API_KEY_NAME] = groq_api_key\n",
    "            print(f\"‚úÖ {GROQ_API_KEY_NAME}: {os.environ[GROQ_API_KEY_NAME][:6]}******\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro ao configurar API Key: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def exibir_markdown(texto):\n",
    "        from IPython.display import Markdown, display\n",
    "        display(Markdown(texto))\n",
    "    \n",
    "    def exibir_resposta_formatada(modelo, pergunta, resposta, raciocinio=None, tempo=0.0):\n",
    "        from IPython.display import Markdown, display\n",
    "        texto_raciocinio = \"\"\n",
    "        if raciocinio:\n",
    "            texto_raciocinio = f\"\"\"\n",
    "        \n",
    "## üßê Racioc√≠nio\n",
    "================================================\n",
    "\n",
    "{raciocinio.strip()}\n",
    "\"\"\"\n",
    "        \n",
    "        texto_md = f\"\"\"\n",
    "## üß† Modelo: `{modelo}`\n",
    "**‚è± Tempo de execu√ß√£o:** {tempo:.2f}s{texto_raciocinio}\n",
    "\n",
    "### üì• Pergunta\n",
    "\n",
    "{pergunta.strip()}\n",
    "\n",
    "### üì§ Resposta\n",
    "\n",
    "{resposta.strip()}\n",
    "        \"\"\"\n",
    "        \n",
    "        exibir_markdown(texto_md)\n",
    "\n",
    "# Configurar API Key\n",
    "configurar_api_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvBbPHNVvd9P"
   },
   "source": [
    "##### ‚ñ∂ Validar se o Groq est√° funcionando corretamente\n",
    "\n",
    "‚ö†Ô∏è Este modelo `compound-beta` √© da pr√≥pria `Groq`, tem um resultado excelente at√© estes momentos dos meus testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IKUwA6xYvThe",
    "outputId": "11bc4202-b1e9-496c-b93a-e2a675ca1946"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## > Prompt do sistema\n",
       "REGRAS:\n",
       "\n",
       "++++\n",
       "\n",
       "Voc√™ √© um especialista da √°rea de intelig√™ncia artificial e est√° instruindo\n",
       "crian√ßas e adolescentes no per√≠odo escolar fundamental.\n",
       "\n",
       "  1. Utilize respostas f√°ceis para o seu p√∫blico.\n",
       "\n",
       "  2. Utilize exemplos pr√°ticos do dia-a-dia desse p√∫blico.\n",
       "\n",
       "  3. A resposta deve ser formatada no padr√£o Markdown, seus t√≠tulos devem come√ßar\n",
       "  com 3 \"#\", utilizar emojis e ter as quebras adequadas para separar bem cada\n",
       "  parte do texto, facilitando a leitura.\n",
       "\n",
       "  4. Voc√™ pode utiliar um pouco de linguagem t√©cnica at√© para que a pessoa tenha\n",
       "  interesse em continuar pesquisando sobre o tema e seus subtemas.\n",
       "\n",
       "++++\n",
       "\n",
       "## > Pergunta do usu√°rio\n",
       "Qual a diferen√ßa entre LLMs e LRMs?\n",
       "\n",
       "## > Prompt final enviado ao LLM\n",
       "REGRAS:\n",
       "\n",
       "++++\n",
       "\n",
       "Voc√™ √© um especialista da √°rea de intelig√™ncia artificial e est√° instruindo\n",
       "crian√ßas e adolescentes no per√≠odo escolar fundamental.\n",
       "\n",
       "  1. Utilize respostas f√°ceis para o seu p√∫blico.\n",
       "\n",
       "  2. Utilize exemplos pr√°ticos do dia-a-dia desse p√∫blico.\n",
       "\n",
       "  3. A resposta deve ser formatada no padr√£o Markdown, seus t√≠tulos devem come√ßar\n",
       "  com 3 \"#\", utilizar emojis e ter as quebras adequadas para separar bem cada\n",
       "  parte do texto, facilitando a leitura.\n",
       "\n",
       "  4. Voc√™ pode utiliar um pouco de linguagem t√©cnica at√© para que a pessoa tenha\n",
       "  interesse em continuar pesquisando sobre o tema e seus subtemas.\n",
       "\n",
       "++++\n",
       "\n",
       "USU√ÅRIO:\n",
       "\n",
       "Qual a diferen√ßa entre LLMs e LRMs?\n",
       "\n",
       "## > Resposta do LLM\n",
       "### Diferen√ßa entre LLMs e LRMs\n",
       "A diferen√ßa entre LLMs (Large Language Models) e LRMs (Large Response Models) √© que:\n",
       "\n",
       "*   **LLMs** s√£o modelos de linguagem que utilizam uma grande quantidade de dados e capacidade de processamento para aprender padr√µes e rela√ß√µes na linguagem, enquanto \n",
       "*   **LRMs** n√£o √© um termo amplamente utilizado, mas podemos considerar que se refere a modelos que geram respostas r√°pidas e eficientes.\n",
       "\n",
       "Em resumo, LLMs s√£o mais focados em aprender e representar a linguagem, enquanto LRMs s√£o projetados para gerar respostas r√°pidas e eficientes. \n",
       "\n",
       "### Exemplos Pr√°ticos\n",
       "Um exemplo de LLM √© um modelo que pode gerar textos coherentes e naturais, como um artigo de not√≠cias ou um conto. J√° um exemplo de LRM seria um modelo que pode responder rapidamente a perguntas frequentes, como um chatbot de suporte ao cliente.\n",
       "\n",
       "### Conclus√£o\n",
       "Portanto, a diferen√ßa entre LLMs e LRMs est√° no seu objetivo e aplica√ß√£o. LLMs s√£o mais focados em aprender e representar a linguagem, enquanto LRMs s√£o projetados para gerar respostas r√°pidas e eficientes. \n",
       "\n",
       "### Pr√≥ximos Passos\n",
       "Para saber mais sobre LLMs e LRMs, voc√™ pode pesquisar sobre as aplica√ß√µes e limita√ß√µes de cada um, e explorar como eles s√£o utilizados em diferentes √°reas, como processamento de linguagem natural, intelig√™ncia artificial e machine learning. Al√©m disso, voc√™ pode experimentar desenvolver seu pr√≥prio modelo de linguagem simples usando ferramentas como Python e bibliotecas de NLP. \n",
       "\n",
       "Lembre-se de que a aprendizagem √© um processo cont√≠nuo, e h√° sempre mais a aprender sobre esses fascinantes t√≥picos! üìöüíª\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Validar se o Groq est√° funcionando corretamente\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Importar os m√≥dulos\n",
    "import os\n",
    "from groq import Groq\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Configurar a API Key da Groq\n",
    "# (recomendo guardar em segredos do Colab)\n",
    "groq_api_key = os.environ[GROQ_API_KEY_NAME]\n",
    "client = Groq(api_key=groq_api_key)\n",
    "\n",
    "# Definir o modelo de LLM que iremos utilizar\n",
    "# Modelos: https://console.groq.com/docs/models\n",
    "LLM_MODEL = \"compound-beta\"\n",
    "\n",
    "# Criar a prompt do sistema\n",
    "prompt_sistema = \"\"\"\n",
    "REGRAS:\n",
    "\n",
    "++++\n",
    "\n",
    "Voc√™ √© um especialista da √°rea de intelig√™ncia artificial e est√° instruindo\n",
    "crian√ßas e adolescentes no per√≠odo escolar fundamental.\n",
    "\n",
    "  1. Utilize respostas f√°ceis para o seu p√∫blico.\n",
    "\n",
    "  2. Utilize exemplos pr√°ticos do dia-a-dia desse p√∫blico.\n",
    "\n",
    "  3. A resposta deve ser formatada no padr√£o Markdown, seus t√≠tulos devem come√ßar\n",
    "  com 3 \"#\", utilizar emojis e ter as quebras adequadas para separar bem cada\n",
    "  parte do texto, facilitando a leitura.\n",
    "\n",
    "  4. Voc√™ pode utiliar um pouco de linguagem t√©cnica at√© para que a pessoa tenha\n",
    "  interesse em continuar pesquisando sobre o tema e seus subtemas.\n",
    "\n",
    "++++\n",
    "\n",
    "\"\"\".strip()\n",
    "\n",
    "# Pergunta do usu√°rio\n",
    "pergunta_usuario = \"Qual a diferen√ßa entre LLMs e LRMs?\"\n",
    "\n",
    "# Criar o prompt final concatenado (para exibir ou logar)\n",
    "prompt_final = f\"{prompt_sistema}\\n\\nUSU√ÅRIO:\\n\\n{pergunta_usuario}\"\n",
    "\n",
    "# Montar mensagens no formato da Groq e chamar o modelo\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": prompt_sistema},\n",
    "    {\"role\": \"user\", \"content\": pergunta_usuario},\n",
    "]\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=LLM_MODEL,\n",
    "    messages=messages,\n",
    "    temperature=0.3,\n",
    "    max_completion_tokens=1024,\n",
    ")\n",
    "\n",
    "resposta_modelo = resp.choices[0].message.content\n",
    "\n",
    "# Visualizando o resultado formatado em Markdown\n",
    "display(Markdown(f\"\"\"\n",
    "## > Prompt do sistema\n",
    "{prompt_sistema}\n",
    "\n",
    "## > Pergunta do usu√°rio\n",
    "{pergunta_usuario}\n",
    "\n",
    "## > Prompt final enviado ao LLM\n",
    "{prompt_final}\n",
    "\n",
    "## > Resposta do LLM\n",
    "{resposta_modelo}\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAOrEU7q7F1J"
   },
   "source": [
    "### </> Criando as fun√ß√µes para utilizar modelos de LLM e LRM\n",
    "---\n",
    "\n",
    "**‚ÑπÔ∏èÔ∏è Observa√ß√µes:**\n",
    "\n",
    "*Tentei fazer a melhor documenta√ß√£o poss√≠vel para explicar o c√≥digo.*\n",
    "\n",
    "**‚ö†Ô∏è Importante:**\n",
    "\n",
    "*Para garantir os melhores resultados, o c√≥digo utiliza dois modelos de linguagem diferentes, cada um com uma finalidade espec√≠fica:*\n",
    "\n",
    "- **`Llama3-70B-8192:`** Um modelo mais gen√©rico, com um foco em compreens√£o de linguagem natural e tarefas de conversa√ß√£o. Ele √© ideal para interpretar o contexto do texto e gerar respostas fluentes e coerentes, garantindo que a comunica√ß√£o seja clara e natural. O `llama3-70b-8192` est√° focado gerar texto de forma flu√≠da e natural, como uma conversa, mas n√£o em resolver problemas l√≥gicos ou matem√°ticos complexos passo a passo como o outro modelo.\n",
    "\n",
    "- **`DeepSeek R1 Distill Llama 70B:`** Este modelo √© especializado em tarefas que exigem um racioc√≠nio complexo, como l√≥gica, matem√°tica e programa√ß√£o. Sua arquitetura √© otimizada para resolver problemas estruturados de forma eficiente. O `deepseek-r1-distill-llama-70b` √© um exemplo, focado em \"pensar\" passo a passo antes de chegar a uma resposta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d95kpV6QA3oc"
   },
   "source": [
    "> **FUN√á√ïES B√ÅSICAS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qd0IVDMn-MaJ"
   },
   "source": [
    "\n",
    "**1. Fun√ß√£o para recuperar o cliente do Groq**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2syPSkoZ8Tgg"
   },
   "outputs": [],
   "source": [
    "# Defini√ß√µes das fun√ß√µes auxiliares\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Importar os m√≥dulos\n",
    "import os\n",
    "import time\n",
    "from groq import Groq\n",
    "from typing import Tuple, Optional\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "def criar_cliente_groq() -> Groq:\n",
    "    \"\"\"\n",
    "    Cria o cliente da Groq usando a vari√°vel de ambiente GROQ_API_KEY.\n",
    "\n",
    "    Por que usar env var?\n",
    "    - Seguran√ßa: evita hardcode de chaves no notebook.\n",
    "    - Reprodutibilidade: o mesmo c√≥digo funciona em diferentes ambientes.\n",
    "    \"\"\"\n",
    "    groq_api_key = os.environ[GROQ_API_KEY_NAME]\n",
    "    if not groq_api_key:\n",
    "        raise RuntimeError(\n",
    "            \"GROQ_API_KEY n√£o definida. No Colab, use: os.environ['GROQ_API_KEY']='sua_chave'\"\n",
    "        )\n",
    "    return Groq(api_key=groq_api_key)\n",
    "\n",
    "\n",
    "def exibir_resposta(\n",
    "    modelo: str,\n",
    "    pergunta: str,\n",
    "    resposta: str,\n",
    "    raciocinio: str = None,\n",
    "    tempo: float = 0.0\n",
    "  ):\n",
    "    \"\"\"\n",
    "    Exibe sa√≠da formatada em Markdown no Jupyter/Colab.\n",
    "    - modelo     : nome do modelo utilizado (LLM ou LRM)\n",
    "    - pergunta   : texto enviado\n",
    "    - resposta   : resposta final ao usu√°rio\n",
    "    - raciocinio : cadeia de racioc√≠nio (opcional)\n",
    "    - tempo      : tempo total da execu√ß√£o\n",
    "    \"\"\"\n",
    "    texto_raciocinio = \"\"\n",
    "\n",
    "    if raciocinio:\n",
    "        texto_raciocinio += f\"\\n\\n\"\n",
    "        texto_raciocinio += f\"## üßê Racioc√≠nio                                \\n\"\n",
    "        texto_raciocinio += f\"================================================\\n\\n\"\n",
    "        texto_raciocinio += f\"{raciocinio.strip()}\"\n",
    "\n",
    "    texto_md = f\"\"\"\n",
    "## üß† Modelo: `{modelo}`\n",
    "**‚è± Tempo de execu√ß√£o:** {tempo:.2f}s\n",
    "\n",
    "{texto_raciocinio}\n",
    "\n",
    "### üì• Pergunta\n",
    "\n",
    "{pergunta.strip()}\n",
    "\n",
    "### üì§ Resposta\n",
    "\n",
    "{resposta.strip()}\n",
    "    \"\"\"\n",
    "\n",
    "    display(Markdown(texto_md))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcQRCQ4yAljB"
   },
   "source": [
    "> **LLM: FUN√á√ïES E TESTES**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMaq_7lW-r2R"
   },
   "source": [
    "**2. LLM: Fun√ß√£o para responder usando modelo llama3 do Groq**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VPoE6SHo-qCJ"
   },
   "outputs": [],
   "source": [
    "# Defini√ß√£o da fun√ß√£o para responder a pergunta usando LLM\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Importar os m√≥dulos\n",
    "import os\n",
    "import time\n",
    "from typing import Tuple, Optional\n",
    "from groq import Groq\n",
    "\n",
    "# ==============================\n",
    "# Fun√ß√£o: perguntar_llm\n",
    "# Objetivo: enviar pergunta a um modelo de LINGUAGEM (LLM)\n",
    "# Retorna: (texto_resposta, tempo_em_segundos)\n",
    "# ==============================\n",
    "def perguntar_llm(\n",
    "    pergunta: str,\n",
    "    modelo: str = \"llama-3.3-70b-versatile\", # Modelo padr√£o para linguagem natural\n",
    "    temperatura: float = 0.2,                # Controla a aleatoriedade da resposta\n",
    "    max_tokens_resposta: int = 1024,         # Limita tamanho da resposta (custo/lat√™ncia)\n",
    "    sistema: Optional[str] = None            # Regras ou persona opcionais\n",
    ") -> Tuple[str, float]:\n",
    "    \"\"\"\n",
    "    Envia uma pergunta para um modelo LLM.\n",
    "\n",
    "    Par√¢metros:\n",
    "    - pergunta           : texto enviado ao modelo.\n",
    "    - modelo             : modelo LLM para tarefas gerais (resumo, reescrita, Q&A).\n",
    "    - temperatura        : controla a \"criatividade\" (0.1‚Äì0.3 = mais determin√≠stico).\n",
    "    - max_tokens_resposta: limita tamanho da sa√≠da, evitando custo ou lentid√£o.\n",
    "    - sistema            : mensagem opcional para regras ou persona.\n",
    "\n",
    "    Retorna:\n",
    "    - texto: resposta final do modelo.\n",
    "    - tempo: tempo total da chamada em segundos.\n",
    "    \"\"\"\n",
    "    # cria o cliente autenticado\n",
    "    cliente = criar_cliente_groq()\n",
    "\n",
    "    # monta mensagens no formato da API (sistema opcional + usu√°rio obrigat√≥rio)\n",
    "    mensagens = []\n",
    "    if sistema:\n",
    "        mensagens.append({\"role\": \"system\", \"content\": sistema})\n",
    "\n",
    "    mensagens.append({\"role\": \"user\", \"content\": pergunta})\n",
    "\n",
    "    # marca in√≠cio para medir tempo de execu√ß√£o\n",
    "    inicio = time.perf_counter()\n",
    "\n",
    "    # chamada √† API da Groq\n",
    "    resposta = cliente.chat.completions.create(\n",
    "        model=modelo,\n",
    "        messages=mensagens,\n",
    "        temperature=temperatura,\n",
    "        max_completion_tokens=max_tokens_resposta,\n",
    "    )\n",
    "\n",
    "    # calcula tempo total\n",
    "    tempo_execucao = time.perf_counter() - inicio\n",
    "\n",
    "    # extrai conte√∫do textual da resposta\n",
    "    texto_resposta = resposta.choices[0].message.content.strip()\n",
    "\n",
    "    return modelo, texto_resposta, tempo_execucao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijpWGrbX_bX7"
   },
   "source": [
    "**3. LLM: Testando a fun√ß√£o para responder com LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "XxprzeEJ_bJL",
    "outputId": "be120c51-8c26-424b-916d-e74150d1123a"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## üß† Modelo: `llama-3.3-70b-versatile`\n",
       "**‚è± Tempo de execu√ß√£o:** 0.39s\n",
       "\n",
       "\n",
       "\n",
       "### üì• Pergunta\n",
       "\n",
       "Resuma em 2 frases, com linguagem neutra e direta: \n",
       "O Banco Central manteve a taxa Selic inalterada. Analistas projetam estabilidade\n",
       "nos pr√≥ximos meses, com aten√ß√£o √† infla√ß√£o de servi√ßos e ao mercado de trabalho.\n",
       "\n",
       "### üì§ Resposta\n",
       "\n",
       "O Banco Central decidiu manter a taxa Selic sem altera√ß√µes. Analistas preveem estabilidade nos pr√≥ximos meses, com foco na infla√ß√£o de servi√ßos e no desempenho do mercado de trabalho.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "## üß† Modelo: `llama-3.3-70b-versatile`\n",
       "**‚è± Tempo de execu√ß√£o:** 0.51s\n",
       "\n",
       "\n",
       "\n",
       "### üì• Pergunta\n",
       "\n",
       "Reescreva o resumo abaixo com tom mais informal e amig√°vel, mantendo precis√£o.\n",
       "\n",
       "RESUMO ORIGINAL:\n",
       "O Banco Central decidiu manter a taxa Selic sem altera√ß√µes. Analistas preveem estabilidade nos pr√≥ximos meses, com foco na infla√ß√£o de servi√ßos e no desempenho do mercado de trabalho.\n",
       "\n",
       "### üì§ Resposta\n",
       "\n",
       "## Resumo Reescrito\n",
       "\n",
       "O Banco Central resolveu n√£o mexer na taxa Selic. Os especialistas acham que as coisas v√£o continuar mais ou menos como est√£o nos pr√≥ximos meses. Eles est√£o de olho na infla√ß√£o, especialmente nos servi√ßos, e tamb√©m no que acontece com o mercado de trabalho.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Teste da fun√ß√£o para responder a pergunta usando LLM\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Importar os m√≥dulos\n",
    "import os\n",
    "import time\n",
    "from typing import Tuple, Optional\n",
    "from groq import Groq\n",
    "\n",
    "# LLM: resumo e reescrita de tom (usando perguntar_llm)\n",
    "texto = \"\"\"\n",
    "O Banco Central manteve a taxa Selic inalterada. Analistas projetam estabilidade\n",
    "nos pr√≥ximos meses, com aten√ß√£o √† infla√ß√£o de servi√ßos e ao mercado de trabalho.\n",
    "\"\"\"\n",
    "\n",
    "# Pedimos um RESUMO curto (linguagem neutra) ‚Äî tarefa t√≠pica de LLM\n",
    "prompt_resumo = f\"Resuma em 2 frases, com linguagem neutra e direta: {texto}\"\n",
    "modelo_resumo, resposta_resumo, tempo_resumo = perguntar_llm(\n",
    "    pergunta=prompt_resumo,\n",
    "    sistema=\"Responda em Markdown de forma clara e concisa.\"\n",
    ")\n",
    "\n",
    "exibir_resposta(\n",
    "    modelo=modelo_resumo,\n",
    "    pergunta=prompt_resumo,\n",
    "    resposta=resposta_resumo,\n",
    "    tempo=tempo_resumo\n",
    ")\n",
    "\n",
    "# Agora pedimos para REESCREVER o pr√≥prio resumo com outro tom.\n",
    "#   - IMPORTANTE: inclu√≠mos explicitamente o 'resumo' no prompt (o modelo n√£o ‚Äúlembra‚Äù sozinho).\n",
    "prompt_tom = (\n",
    "    \"Reescreva o resumo abaixo com tom mais informal e amig√°vel, mantendo precis√£o.\\n\\n\"\n",
    "    f\"RESUMO ORIGINAL:\\n{resposta_resumo}\"\n",
    ")\n",
    "modelo_tom, resposta_tom, tempo_tom = perguntar_llm(\n",
    "    pergunta=prompt_tom,\n",
    "    sistema=\"Responda em Markdown e use linguagem acess√≠vel; evite jarg√µes.\"\n",
    ")\n",
    "\n",
    "exibir_resposta(\n",
    "    modelo=modelo_tom,\n",
    "    pergunta=prompt_tom,\n",
    "    resposta=resposta_tom,\n",
    "    tempo=tempo_tom\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJs63UUhAwja"
   },
   "source": [
    "> **LRM: FUN√á√ïES E TESTES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYh2luuPAzrJ"
   },
   "source": [
    "**4. LRM: Fun√ß√£o para responder usando modelo deepseek do Groq**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pqYmYrwP-RoL"
   },
   "outputs": [],
   "source": [
    "# Defini√ß√£o da fun√ß√£o para responder a pergunta usando LRM\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Importar os m√≥dulos\n",
    "import os\n",
    "import time\n",
    "from typing import Tuple, Optional\n",
    "from groq import Groq\n",
    "\n",
    "# ==============================\n",
    "# Fun√ß√£o: perguntar_lrm\n",
    "# Objetivo: enviar pergunta a um modelo de RACIOC√çNIO (LRM)\n",
    "# Retorna: (texto_ao_usuario, cadeia_de_raciocinio, tempo_em_segundos)\n",
    "# ==============================\n",
    "def perguntar_lrm(\n",
    "    pergunta: str,\n",
    "    modelo: str = \"deepseek-r1-distill-llama-70b\",   # Modelo otimizado para racioc√≠nio\n",
    "    temperatura: float = 0.2,                        # Baixa varia√ß√£o para consist√™ncia\n",
    "    formato_raciocinio: Optional[str] = \"parsed\",    # 'parsed', 'raw', 'hidden' ou None\n",
    "    incluir_raciocinio: bool = True,                 # S√≥ usado se formato_raciocinio=None\n",
    "    max_tokens_resposta: int = 2000,                 # Limite da resposta final\n",
    "    max_tokens_raciocinio: Optional[int] = None,     # Limite da cadeia de racioc√≠nio\n",
    "    sistema: Optional[str] = None                    # Mensagem de sistema opcional\n",
    ") -> Tuple[str, Optional[str], float]:\n",
    "    \"\"\"\n",
    "    Envia uma pergunta a um modelo de racioc√≠nio (LRM) da Groq.\n",
    "\n",
    "    Comportamento:\n",
    "    - Se `formato_raciocinio` ‚àà {'parsed','raw','hidden'} ‚Üí usa `reasoning_format` e\n",
    "      **N√ÉO** envia `include_reasoning` (evita erro 400).\n",
    "      ‚Ä¢ 'parsed'  ‚Üí cadeia vem separada em `message.reasoning`\n",
    "      ‚Ä¢ 'raw'     ‚Üí cadeia vem crua, com marca√ß√µes\n",
    "      ‚Ä¢ 'hidden'  ‚Üí o modelo raciocina, mas n√£o retorna a cadeia\n",
    "    - Se `formato_raciocinio` for None ‚Üí n√£o envia `reasoning_format` e usa `include_reasoning`.\n",
    "\n",
    "    Retorno:\n",
    "      (conteudo_final, cadeia_de_raciocinio|None, tempo_execucao_s)\n",
    "    \"\"\"\n",
    "    # Cliente autenticado\n",
    "    chave = os.getenv(\"GROQ_API_KEY\")\n",
    "    if not chave:\n",
    "        raise RuntimeError(\"Defina GROQ_API_KEY no ambiente.\")\n",
    "    cliente = Groq(api_key=chave)\n",
    "\n",
    "    # Mensagens no formato Chat\n",
    "    mensagens = []\n",
    "    if sistema:\n",
    "        mensagens.append({\"role\": \"system\", \"content\": sistema})\n",
    "    mensagens.append({\"role\": \"user\", \"content\": pergunta})\n",
    "\n",
    "    # Monta kwargs din√¢micos conforme as regras da API\n",
    "    kwargs = {\n",
    "        \"model\": modelo,\n",
    "        \"messages\": mensagens,\n",
    "        \"temperature\": temperatura,\n",
    "        \"max_completion_tokens\": max_tokens_resposta,\n",
    "    }\n",
    "\n",
    "    # Se limite de tokens do racioc√≠nio foi definido, adiciona\n",
    "    if max_tokens_raciocinio is not None:\n",
    "        kwargs[\"max_reasoning_tokens\"] = max_tokens_raciocinio\n",
    "\n",
    "    # Regra de exclus√£o m√∫tua:\n",
    "    # - Se formato_raciocinio estiver definido, usa reasoning_format e IGNORA include_reasoning\n",
    "    # - Se formato_raciocinio for None, usa include_reasoning (sem reasoning_format)\n",
    "    if formato_raciocinio is not None:\n",
    "        kwargs[\"reasoning_format\"] = formato_raciocinio\n",
    "        # N√ÉO adicionar include_reasoning para evitar o erro 400\n",
    "    else:\n",
    "        kwargs[\"include_reasoning\"] = bool(incluir_raciocinio)\n",
    "\n",
    "    # Chamada e cron√¥metro\n",
    "    inicio = time.perf_counter()\n",
    "    resp = cliente.chat.completions.create(**kwargs)\n",
    "    tempo = time.perf_counter() - inicio\n",
    "\n",
    "    # Extra√ß√£o da resposta e (se houver) do racioc√≠nio\n",
    "    msg = resp.choices[0].message\n",
    "    conteudo = (msg.content or \"\").strip()\n",
    "\n",
    "    # A cadeia s√≥ vem quando:\n",
    "    # - usamos reasoning_format ('parsed'/'raw'), E\n",
    "    # - n√£o √© 'hidden'\n",
    "    if formato_raciocinio in (\"parsed\", \"raw\"):\n",
    "        raciocinio = getattr(msg, \"reasoning\", None)\n",
    "    else:\n",
    "        # Quando formato=None e include_reasoning=True, algumas combina√ß√µes\n",
    "        # podem retornar o racioc√≠nio embutido; a API nem sempre exp√µe em `reasoning`.\n",
    "        raciocinio = getattr(msg, \"reasoning\", None)\n",
    "\n",
    "    return modelo, conteudo, raciocinio, tempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eS76H1EDeJD"
   },
   "source": [
    "**5. LRM: Testando a fun√ß√£o para responder com LRM**\n",
    "\n",
    "-\n",
    "\n",
    "**‚ÑπÔ∏èÔ∏è IMPORTANTE:**\n",
    "\n",
    "> *Para ver como o modelo chegou √† resposta final, procure a se√ß√£o **üßê Racioc√≠nio.** Essa √© uma demonstra√ß√£o do poder dos modelos especializados em l√≥gica e racioc√≠nio.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3ejlx82kDZ2P",
    "outputId": "3cc94834-8e71-4ceb-ccd0-a2c2d0279ecc"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## üß† Modelo: `deepseek-r1-distill-llama-70b`\n",
       "**‚è± Tempo de execu√ß√£o:** 5.09s\n",
       "\n",
       "\n",
       "\n",
       "## üßê Racioc√≠nio                                \n",
       "================================================\n",
       "\n",
       "Ok, vamos l√°. Primeiro, preciso entender o perfil do investidor. Ele √© conservador, ent√£o provavelmente busca estabilidade e baixo risco. Seu objetivo √© ter uma renda previs√≠vel com baixa volatilidade. Isso me faz pensar que ele n√£o quer surpresas e valoriza a seguran√ßa do capital.\n",
       "\n",
       "Agora, vamos analisar as op√ß√µes dispon√≠veis: t√≠tulo atrelado ao CDI, prefixado curto e IPCA+ longo. Cada um tem suas caracter√≠sticas.\n",
       "\n",
       "Primeiro, o t√≠tulo atrelado ao CDI. Como o CDI est√° em 13,25% ao ano, isso oferece uma rentabilidade l√≠quida de aproximadamente 13,25% menos o imposto de renda. Considerando a al√≠quota de 15%, a rentabilidade l√≠quida seria de 11,25%. Isso √© bom, mas preciso considerar a infla√ß√£o projetada de 4%. Ent√£o, a rentabilidade real seria de 7,25%, o que √© positivo. No entanto, o risco de cr√©dito pode ser um problema se o emitente n√£o for confi√°vel. Al√©m disso, a liquidez pode ser um desafio, especialmente se precisar resgatar o dinheiro antes do vencimento.\n",
       "\n",
       "Em seguida, o prefixado curto. Com vencimento em 2026 e 2027, ele oferece uma rentabilidade menor, mas mais seguran√ßa. A rentabilidade l√≠quida seria de 11,25% menos a infla√ß√£o de 4%, resultando em 7,25% real. A vantagem aqui √© a menor exposi√ß√£o √† volatilidade das taxas de juros, j√° que o prazo √© curto. A liquidez tamb√©m √© melhor, pois t√≠tulos curtos costumam ter mais liquidez no mercado secund√°rio. Al√©m disso, o risco de cr√©dito √© menor, j√° que s√£o t√≠tulos do Tesouro Direto, considerados de baixo risco.\n",
       "\n",
       "Por fim, o IPCA+ longo. Com vencimento mais longo, ele oferece uma rentabilidade real de 4% mais a infla√ß√£o. Isso pode parecer atraente, mas o risco √© maior devido √† exposi√ß√£o √† infla√ß√£o. Se a infla√ß√£o ultrapassar a projetada, o investidor pode perder poder de compra. Al√©m disso, a liquidez pode ser um problema devido ao longo prazo, e a volatilidade maior pode afetar o valor do t√≠tulo.\n",
       "\n",
       "Considerando o perfil conservador do investidor, o prefixado curto parece mais adequado. Ele oferece uma rentabilidade decente com menor risco e melhor liquidez. Al√©m disso, o duration menor protege contra varia√ß√µes nas taxas de juros, o que √© importante para manter a estabilidade.\n",
       "\n",
       "Para a pol√≠tica de rebalanceamento, sugiro revisar a carteira anualmente e realocar recursos para manter a distribui√ß√£o entre os ativos, garantindo que o perfil de risco permane√ßa alinhado com o objetivo do investidor.\n",
       "\n",
       "Em resumo, o prefixado curto atende melhor √†s necessidades do investidor conservador, oferecendo renda previs√≠vel com baixa volatilidade e riscos controlados.\n",
       "\n",
       "### üì• Pergunta\n",
       "\n",
       "Voc√™ √© um analista de investimentos.\n",
       "\n",
       "Dado o cen√°rio:\n",
       "- {\"perfil\": \"conservador\", \"inflacao_projetada_aa\": 4.0, \"cdi_aa\": 13.25, \"vencimentos_anos\": [2026, 2027], \"objetivo\": \"renda previs√≠vel com baixa volatilidade\"}\n",
       "\n",
       "Decida entre:\n",
       "- t√≠tulo atrelado ao CDI;\n",
       "- prefixado curto;\n",
       "- IPCA+ longo.\n",
       "\n",
       "Importante:\n",
       "\n",
       "1. Resposta e racioc√≠nio sempre em portug√™s do brasil.\n",
       "2. Estruture o racioc√≠nio em etapas (riscos, liquidez, duration, sensibilidade √† infla√ß√£o).\n",
       "3. Apresente a recomenda√ß√£o final e uma pol√≠tica de rebalanceamento simples.\n",
       "4. Use n√∫meros aproximados e justificativas claras.\n",
       "\n",
       "### üì§ Resposta\n",
       "\n",
       "### An√°lise e Recomenda√ß√£o para Investimento\n",
       "\n",
       "#### 1. **Perfil do Investidor e Objetivo**\n",
       "   - **Perfil:** Conservador\n",
       "   - **Objetivo:** Renda previs√≠vel com baixa volatilidade\n",
       "\n",
       "#### 2. **Etapas de An√°lise**\n",
       "\n",
       "   ##### 2.1. **Riscos**\n",
       "   - **T√≠tulo atrelado ao CDI:** \n",
       "     - Risco de cr√©dito do emitente.\n",
       "     - Sensibilidade a mudan√ßas nas taxas de juros.\n",
       "   - **Prefixado Curto:** \n",
       "     - Baixo risco de cr√©dito (normalmente emitidos por institui√ß√µes seguras).\n",
       "     - Menor exposi√ß√£o a mudan√ßas nas taxas de juros devido ao prazo curto.\n",
       "   - **IPCA+ Longo:** \n",
       "     - Risco de infla√ß√£o superior √† projetada.\n",
       "     - Maior exposi√ß√£o a varia√ß√µes nas taxas de juros.\n",
       "\n",
       "   ##### 2.2. **Liquidez**\n",
       "   - **T√≠tulo atrelado ao CDI:** \n",
       "     - Liquidez moderada, dependendo do mercado secund√°rio.\n",
       "   - **Prefixado Curto:** \n",
       "     - Maior liquidez devido ao prazo curto e baixo risco.\n",
       "   - **IPCA+ Longo:** \n",
       "     - Menor liquidez devido ao prazo mais longo.\n",
       "\n",
       "   ##### 2.3. **Duration**\n",
       "   - **T√≠tulo atrelado ao CDI:** \n",
       "     - Duration mais longo, mais sens√≠vel a mudan√ßas nas taxas de juros.\n",
       "   - **Prefixado Curto:** \n",
       "     - Duration menor, menos sens√≠vel a mudan√ßas nas taxas de juros.\n",
       "   - **IPCA+ Longo:** \n",
       "     - Duration mais longo, mais sens√≠vel a mudan√ßas nas taxas de juros.\n",
       "\n",
       "   ##### 2.4. **Sensibilidade √† Infla√ß√£o**\n",
       "   - **T√≠tulo atrelado ao CDI:** \n",
       "     - Prote√ß√£o contra infla√ß√£o via rentabilidade atrelada ao CDI.\n",
       "   - **Prefixado Curto:** \n",
       "     - Menor prote√ß√£o contra infla√ß√£o devido ao prazo curto.\n",
       "   - **IPCA+ Longo:** \n",
       "     - Prote√ß√£o expl√≠cita contra infla√ß√£o, mas com risco de infla√ß√£o superior √† projetada.\n",
       "\n",
       "#### 3. **Recomenda√ß√£o Final**\n",
       "   - **Recomenda√ß√£o:** **Prefixado Curto**\n",
       "     - **Justificativa:** \n",
       "       - Oferece uma rentabilidade l√≠quida de aproximadamente 11,25% ao ano (considerando imposto de renda de 15%).\n",
       "       - Menor exposi√ß√£o a riscos de cr√©dito e mudan√ßas nas taxas de juros.\n",
       "       - Maior liquidez e menor duration, adequados ao perfil conservador do investidor.\n",
       "\n",
       "#### 4. **Pol√≠tica de Rebalanceamento**\n",
       "   - **Revis√£o Anual:** \n",
       "     - Verificar a distribui√ß√£o dos investimentos e realocar recursos para manter o perfil de risco desejado.\n",
       "     - Ajustar a carteira para manter a exposi√ß√£o adequada aos diferentes tipos de t√≠tulos.\n",
       "\n",
       "### Conclus√£o\n",
       "O **Prefixado Curto** √© a op√ß√£o mais adequada para o investidor conservador, oferecendo uma renda previs√≠vel com baixa volatilidade e riscos controlados. A pol√≠tica de rebalanceamento simples ajudar√° a manter a carteira alinhada com os objetivos do investidor.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testando a fun√ß√£o para responder a pergunta usando LRM\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Importar os m√≥dulos\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from typing import Tuple, Optional\n",
    "from groq import Groq\n",
    "\n",
    "cenario = {\n",
    "    \"perfil\": \"conservador\",\n",
    "    \"inflacao_projetada_aa\": 4.0,\n",
    "    \"cdi_aa\": 13.25,\n",
    "    \"vencimentos_anos\": [2026, 2027],\n",
    "    \"objetivo\": \"renda previs√≠vel com baixa volatilidade\",\n",
    "}\n",
    "cenario_fmt = json.dumps(cenario, ensure_ascii=False)\n",
    "\n",
    "prompt_lrm = f\"\"\"\n",
    "Voc√™ √© um analista de investimentos.\n",
    "\n",
    "Dado o cen√°rio:\n",
    "- {cenario_fmt}\n",
    "\n",
    "Decida entre:\n",
    "- t√≠tulo atrelado ao CDI;\n",
    "- prefixado curto;\n",
    "- IPCA+ longo.\n",
    "\n",
    "Importante:\n",
    "\n",
    "1. Resposta e racioc√≠nio sempre em portug√™s do brasil.\n",
    "2. Estruture o racioc√≠nio em etapas (riscos, liquidez, duration, sensibilidade √† infla√ß√£o).\n",
    "3. Apresente a recomenda√ß√£o final e uma pol√≠tica de rebalanceamento simples.\n",
    "4. Use n√∫meros aproximados e justificativas claras.\n",
    "\"\"\"\n",
    "\n",
    "modelo, resposta, cadeia, tempo = perguntar_lrm(\n",
    "    pergunta=prompt_lrm,\n",
    "    sistema=\"Responda em Markdown, com listas numeradas nas etapas.\"\n",
    ")\n",
    "\n",
    "exibir_resposta(\n",
    "    modelo=modelo,\n",
    "    pergunta=prompt_lrm,\n",
    "    resposta=resposta,\n",
    "    raciocinio=cadeia,\n",
    "    tempo=tempo\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIbj9yHPDx5l"
   },
   "source": [
    "### Comparando ÷é LLM vs LRM üß†\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hig7SEawnuX"
   },
   "source": [
    "> *Agora, utilizando o problema anterior, vamsos comparar a diferen√ßa entre os modelos com base em um mesmo contexto e/ou problema.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARtpn5Fc2VgT"
   },
   "source": [
    "#### CEN√ÅRIO 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "EFQKdnzCELm6",
    "outputId": "c882f408-d837-45e1-e5cd-86f0d6c5620a"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## üî¨ Compara√ß√£o Lado a Lado ‚Äî LLM vs LRM (MESMO prompt)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üìù Prompt usado nos dois modelos\n",
       "> \n",
       "Voc√™ √© um analista de investimentos.\n",
       "\n",
       "Dado o cen√°rio:\n",
       "- {\"perfil\": \"conservador\", \"inflacao_projetada_aa\": 5.0, \"cdi_aa\": 14.5, \"vencimentos_anos\": [2026, 2027], \"objetivo\": \"renda previs√≠vel com baixa volatilidade\"}\n",
       "\n",
       "Decida entre:\n",
       "- t√≠tulo atrelado ao CDI;\n",
       "- prefixado curto;\n",
       "- IPCA+ longo.\n",
       "\n",
       "Importante:\n",
       "\n",
       "1. Resposta e racioc√≠nio sempre em portug√™s do brasil.\n",
       "2. Estruture o racioc√≠nio em etapas (riscos, liquidez, duration, sensibilidade √† infla√ß√£o).\n",
       "3. Apresente a recomenda√ß√£o final e uma pol√≠tica de rebalanceamento simples.\n",
       "4. Use n√∫meros aproximados e justificativas claras.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "## üß† Modelo: `llama-3.3-70b-versatile`\n",
       "**‚è± Tempo de execu√ß√£o:** 3.35s\n",
       "\n",
       "\n",
       "\n",
       "### üì• Pergunta\n",
       "\n",
       "Voc√™ √© um analista de investimentos.\n",
       "\n",
       "Dado o cen√°rio:\n",
       "- {\"perfil\": \"conservador\", \"inflacao_projetada_aa\": 5.0, \"cdi_aa\": 14.5, \"vencimentos_anos\": [2026, 2027], \"objetivo\": \"renda previs√≠vel com baixa volatilidade\"}\n",
       "\n",
       "Decida entre:\n",
       "- t√≠tulo atrelado ao CDI;\n",
       "- prefixado curto;\n",
       "- IPCA+ longo.\n",
       "\n",
       "Importante:\n",
       "\n",
       "1. Resposta e racioc√≠nio sempre em portug√™s do brasil.\n",
       "2. Estruture o racioc√≠nio em etapas (riscos, liquidez, duration, sensibilidade √† infla√ß√£o).\n",
       "3. Apresente a recomenda√ß√£o final e uma pol√≠tica de rebalanceamento simples.\n",
       "4. Use n√∫meros aproximados e justificativas claras.\n",
       "\n",
       "### üì§ Resposta\n",
       "\n",
       "### An√°lise de Investimento para Perfil Conservador\n",
       "\n",
       "#### Etapa 1: Riscos\n",
       "O perfil do investidor √© conservador, o que significa que ele busca minimizar riscos e prioriza a estabilidade dos investimentos. Nesse contexto, √© importante considerar os riscos associados a cada op√ß√£o de investimento:\n",
       "- **T√≠tulo atrelado ao CDI**: O risco √© relativamente baixo, pois o retorno √© indexado √† taxa de juros do CDI, que √© uma refer√™ncia para a taxa de juros no mercado financeiro brasileiro. No entanto, existe um risco de cr√©dito associado ao emissor do t√≠tulo.\n",
       "- **Prefixado curto**: O risco tamb√©m √© baixo, pois o investimento tem um vencimento curto, reduzindo o impacto de mudan√ßas nas taxas de juros. Al√©m disso, o risco de cr√©dito √© menor devido ao curto prazo.\n",
       "- **IPCA+ longo**: Este investimento apresenta um risco maior devido ao seu longo prazo, o que o torna mais sens√≠vel a mudan√ßas nas expectativas de infla√ß√£o e nas taxas de juros. Al√©m disso, o risco de cr√©dito pode ser maior se o emissor n√£o for de alta qualidade.\n",
       "\n",
       "#### Etapa 2: Liquidez\n",
       "A liquidez √© importante para investidores que precisam acessar seus recursos rapidamente. Considerando as op√ß√µes:\n",
       "- **T√≠tulo atrelado ao CDI**: A liquidez pode variar dependendo do t√≠tulo espec√≠fico, mas geralmente √© poss√≠vel resgatar o investimento antes do vencimento, embora possa haver penalidades.\n",
       "- **Prefixado curto**: Devido ao seu curto prazo, o prefixado curto oferece uma boa liquidez, pois o investidor pode esperar pelo vencimento, que ocorre em um prazo relativamente curto.\n",
       "- **IPCA+ longo**: A liquidez √© menor devido ao longo prazo do investimento, o que pode dificultar a recupera√ß√£o dos recursos antes do vencimento sem incorrer em penalidades ou perdas.\n",
       "\n",
       "#### Etapa 3: Duration\n",
       "A duration √© uma medida de como o valor de um investimento √© afetado por mudan√ßas nas taxas de juros. Para um investidor conservador:\n",
       "- **T√≠tulo atrelado ao CDI**: A duration √© baixa, pois o retorno √© indexado √† taxa de juros do CDI, o que ajuda a manter o valor do investimento est√°vel em face de mudan√ßas nas taxas de juros.\n",
       "- **Prefixado curto**: A duration tamb√©m √© baixa, pois o investimento tem um vencimento curto, minimizando o impacto de mudan√ßas nas taxas de juros.\n",
       "- **IPCA+ longo**: A duration √© alta, o que significa que o investimento √© mais sens√≠vel a mudan√ßas nas taxas de juros, podendo resultar em perdas se as taxas subirem significativamente.\n",
       "\n",
       "#### Etapa 4: Sensibilidade √† Infla√ß√£o\n",
       "Considerando a infla√ß√£o projetada de 5.0% ao ano:\n",
       "- **T√≠tulo atrelado ao CDI**: N√£o oferece prote√ß√£o direta contra a infla√ß√£o, pois o retorno √© baseado na taxa de juros do CDI, que n√£o √© necessariamente indexada √† infla√ß√£o.\n",
       "- **Prefixado curto**: Tamb√©m n√£o oferece prote√ß√£o direta contra a infla√ß√£o, pois o retorno √© fixo e n√£o acompanha a infla√ß√£o.\n",
       "- **IPCA+ longo**: Oferece prote√ß√£o contra a infla√ß√£o, pois o retorno √© indexado ao IPCA (√çndice de Pre√ßos ao Consumidor Amplo), o que ajuda a manter o poder de compra do investimento ao longo do tempo.\n",
       "\n",
       "### Recomenda√ß√£o Final\n",
       "Considerando o perfil conservador do investidor, a necessidade de renda previs√≠vel com baixa volatilidade e os vencimentos projetados para 2026 e 2027, a recomenda√ß√£o √© investir em **t√≠tulo atrelado ao CDI**. Este investimento oferece um retorno est√°vel, indexado √† taxa de juros do CDI, o que ajuda a manter a renda previs√≠vel. Al√©m disso, o risco de cr√©dito e a sensibilidade a mudan√ßas nas taxas de juros s√£o relativamente baixos, o que se alinha com o perfil de risco do investidor.\n",
       "\n",
       "### Pol√≠tica de Rebalanceamento\n",
       "Para manter a carteira alinhada com o perfil de risco e os objetivos do investidor, √© recomend√°vel revisar e rebalancear a carteira a cada 6 meses. Isso envolve:\n",
       "- Verificar se o perfil de risco do investidor mudou.\n",
       "- Avaliar o desempenho dos investimentos e ajustar a aloca√ß√£o de ativos se necess√°rio.\n",
       "- Considerar a reinvestimento de dividendos ou juros para manter a carteira crescendo de acordo com os objetivos do investidor.\n",
       "\n",
       "Essa abordagem ajudar√° a manter a carteira diversificada, minimizar riscos e maximizar os retornos dentro do perfil de risco aceit√°vel para o investidor.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "## üß† Modelo: `deepseek-r1-distill-llama-70b`\n",
       "**‚è± Tempo de execu√ß√£o:** 6.21s\n",
       "\n",
       "\n",
       "\n",
       "## üßê Racioc√≠nio                                \n",
       "================================================\n",
       "\n",
       "Ok, vamos analisar o cen√°rio apresentado. O perfil do investidor √© conservador, o que geralmente significa que ele prefere menos risco e mais estabilidade. A infla√ß√£o projetada √© de 5% ao ano, e o CDI est√° em 14,5% ao ano. Os vencimentos s√£o em 2026 e 2027, ent√£o o investidor tem um horizonte de investimento de cerca de 3 a 4 anos.\n",
       "\n",
       "Primeiro, vamos considerar os tipos de investimentos dispon√≠veis: t√≠tulo atrelado ao CDI, prefixado curto e IPCA+ longo.\n",
       "\n",
       "1. **T√≠tulo atrelado ao CDI**: Este tipo de investimento acompanha a taxa de juros do CDI, o que pode ser bom em um cen√°rio de taxas elevadas. No entanto, se as taxas ca√≠rem, o valor do t√≠tulo pode diminuir. Al√©m disso, o CDI √© sens√≠vel √†s mudan√ßas nas taxas de juros do mercado, o que pode trazer volatilidade.\n",
       "\n",
       "2. **Prefixado curto**: Investimentos prefixados com vencimento curto s√£o menos sens√≠veis √†s mudan√ßas nas taxas de juros, pois o dinheiro √© devolvido mais rapidamente. Isso reduz o risco de mercado, o que √© bom para um investidor conservador. Al√©m disso, com o vencimento curto, o investidor pode reinvestir em outras oportunidades conforme as condi√ß√µes do mercado mudam.\n",
       "\n",
       "3. **IPCA+ longo**: Este investimento est√° atrelado √† infla√ß√£o mais uma taxa de juros real. Em um cen√°rio de infla√ß√£o controlada, isso pode ser vantajoso, pois o investidor mant√©m o valor da compra. No entanto, se a infla√ß√£o superar as expectativas, o IPCA+ pode oferecer uma prote√ß√£o melhor contra a perda de valor. No entanto, o risco aqui √© que, se a infla√ß√£o for menor do que a projetada, o retorno pode ser menor.\n",
       "\n",
       "Agora, vamos avaliar os riscos associados a cada op√ß√£o:\n",
       "\n",
       "- **Risco de Cr√©dito**: Todos os t√≠tulos p√∫blicos geralmente t√™m baixo risco de cr√©dito, j√° que s√£o emitidos pelo governo. Portanto, este risco √© relativamente baixo em todas as op√ß√µes.\n",
       "\n",
       "- **Risco de Liquidez**: T√≠tulos atrelados ao CDI e prefixados curtos geralmente t√™m boa liquidez, podendo ser vendidos antes do vencimento se necess√°rio. O IPCA+ longo pode ter menor liquidez, especialmente se o mercado n√£o estiver l√≠quido naquele momento.\n",
       "\n",
       "- **Risco de Taxa de Juros (Duration)**: O t√≠tulo atrelado ao CDI tem uma dura√ß√£o mais longa, o que significa que √© mais sens√≠vel √†s mudan√ßas nas taxas de juros. O prefixado curto tem dura√ß√£o mais curta, reduzindo esse risco. O IPCA+ longo, por outro lado, tem uma dura√ß√£o mais longa, tornando-se mais sens√≠vel a mudan√ßas nas taxas de juros reais.\n",
       "\n",
       "- **Sensibilidade √† Infla√ß√£o**: O IPCA+ longo √© menos sens√≠vel √† infla√ß√£o, pois seu retorno acompanha a infla√ß√£o. O t√≠tulo atrelado ao CDI e o prefixado curto podem ser mais afetados se a infla√ß√£o superar as expectativas, reduzindo o valor real do investimento.\n",
       "\n",
       "Considerando o perfil conservador do investidor e o horizonte de investimento de 3 a 4 anos, o prefixado curto parece ser a op√ß√£o mais adequada. Ele oferece menor risco de taxa de juros, boa liquidez e prote√ß√£o contra a infla√ß√£o, j√° que o investidor pode reinvestir os recursos em t√≠tulos com taxas mais atraentes conforme o mercado muda. Al√©m disso, o prefixado curto geralmente tem menor volatilidade, o que se alinha bem com o objetivo de renda previs√≠vel e baixa volatilidade.\n",
       "\n",
       "Para a pol√≠tica de rebalanceamento, recomendo revisar o portf√≥lio anualmente ou sempre que houver mudan√ßas significativas nas taxas de juros ou na infla√ß√£o. Nesse momento, o investidor pode decidir manter os t√≠tulos prefixados curtos ou migrar para outros investimentos com base nas novas condi√ß√µes do mercado.\n",
       "\n",
       "Em resumo, a recomenda√ß√£o √© investir em t√≠tulos prefixados curtos, devido √† sua estabilidade, baixo risco e adequa√ß√£o ao perfil conservador do investidor.\n",
       "\n",
       "### üì• Pergunta\n",
       "\n",
       "Voc√™ √© um analista de investimentos.\n",
       "\n",
       "Dado o cen√°rio:\n",
       "- {\"perfil\": \"conservador\", \"inflacao_projetada_aa\": 5.0, \"cdi_aa\": 14.5, \"vencimentos_anos\": [2026, 2027], \"objetivo\": \"renda previs√≠vel com baixa volatilidade\"}\n",
       "\n",
       "Decida entre:\n",
       "- t√≠tulo atrelado ao CDI;\n",
       "- prefixado curto;\n",
       "- IPCA+ longo.\n",
       "\n",
       "Importante:\n",
       "\n",
       "1. Resposta e racioc√≠nio sempre em portug√™s do brasil.\n",
       "2. Estruture o racioc√≠nio em etapas (riscos, liquidez, duration, sensibilidade √† infla√ß√£o).\n",
       "3. Apresente a recomenda√ß√£o final e uma pol√≠tica de rebalanceamento simples.\n",
       "4. Use n√∫meros aproximados e justificativas claras.\n",
       "\n",
       "### üì§ Resposta\n",
       "\n",
       "# An√°lise de Investimentos para Perfil Conservador\n",
       "\n",
       "## Resumo do Cen√°rio\n",
       "- **Perfil do Investidor:** Conservador\n",
       "- **Infla√ß√£o Projetada (a.a.):** 5,0%\n",
       "- **CDI (a.a.):** 14,5%\n",
       "- **Vencimentos:** 2026 e 2027\n",
       "- **Objetivo:** Renda previs√≠vel com baixa volatilidade\n",
       "\n",
       "## Op√ß√µes de Investimento\n",
       "1. **T√≠tulo Atrelado ao CDI**\n",
       "2. **Prefixado Curto**\n",
       "3. **IPCA+ Longo**\n",
       "\n",
       "## Etapas da An√°lise\n",
       "\n",
       "### 1. Riscos\n",
       "- **Risco de Cr√©dito:** Baixo para todas as op√ß√µes, pois s√£o t√≠tulos p√∫blicos.\n",
       "- **Risco de Liquidez:** \n",
       "  - T√≠tulo CDI e Prefixado Curto: Alta liquidez.\n",
       "  - IPCA+ Longo: Liquidez pode ser menor.\n",
       "- **Risco de Taxa de Juros (Duration):**\n",
       "  - T√≠tulo CDI: Alta sensibilidade.\n",
       "  - Prefixado Curto: Baixa sensibilidade.\n",
       "  - IPCA+ Longo: Alta sensibilidade.\n",
       "- **Sensibilidade √† Infla√ß√£o:**\n",
       "  - T√≠tulo CDI e Prefixado Curto: Maior sensibilidade.\n",
       "  - IPCA+ Longo: Menor sensibilidade.\n",
       "\n",
       "### 2. Liquidez\n",
       "- **T√≠tulo CDI:** Alta liquidez, pode ser negociado diariamente.\n",
       "- **Prefixado Curto:** Alta liquidez, f√°cil de negociar.\n",
       "- **IPCA+ Longo:** Liquidez moderada, pode ser mais dif√≠cil de negociar em momentos de estresse do mercado.\n",
       "\n",
       "### 3. Duration\n",
       "- **T√≠tulo CDI:** Dura√ß√£o mais longa, mais sens√≠vel a mudan√ßas nas taxas de juros.\n",
       "- **Prefixado Curto:** Dura√ß√£o curta, menos sens√≠vel a mudan√ßas nas taxas de juros.\n",
       "- **IPCA+ Longo:** Dura√ß√£o mais longa, mais sens√≠vel a mudan√ßas nas taxas de juros reais.\n",
       "\n",
       "### 4. Sensibilidade √† Infla√ß√£o\n",
       "- **T√≠tulo CDI e Prefixado Curto:** Retornos fixos, mais afetados pela infla√ß√£o n√£o antecipada.\n",
       "- **IPCA+ Longo:** Retorno acompanha a infla√ß√£o, protegendo o valor real.\n",
       "\n",
       "## Recomenda√ß√£o Final\n",
       "**Recomenda√ß√£o:** Investir em **t√≠tulos prefixados curtos**.\n",
       "\n",
       "**Justificativa:**\n",
       "- **Baixo Risco de Taxa de Juros:** Menor exposi√ß√£o a mudan√ßas nas taxas de juros.\n",
       "- **Liquidez:** F√°cil de negociar, permitindo ajustes conforme necess√°rio.\n",
       "- **Prote√ß√£o contra Infla√ß√£o:** Embora n√£o acompanhe a infla√ß√£o, a liquidez permite reinvestir em t√≠tulos com taxas mais atraentes se a infla√ß√£o mudar.\n",
       "- **Adequa√ß√£o ao Perfil Conservador:** Oferece estabilidade e renda previs√≠vel, alinhando-se com o objetivo do investidor.\n",
       "\n",
       "## Pol√≠tica de Rebalanceamento\n",
       "- **Revis√£o Peri√≥dica:** A cada 12 meses ou quando houver mudan√ßas significativas nas taxas de juros ou na infla√ß√£o.\n",
       "- **A√ß√µes de Rebalanceamento:** \n",
       "  - Manter os t√≠tulos prefixados curtos se as condi√ß√µes do mercado forem favor√°veis.\n",
       "  - Considerar migrar para outros investimentos (como IPCA+ ou t√≠tulos CDI) se as taxas de juros ou a infla√ß√£o mudarem substancialmente.\n",
       "\n",
       "## Conclus√£o\n",
       "Os t√≠tulos prefixados curtos s√£o a escolha mais adequada para o investidor conservador, oferecendo um equil√≠brio entre baixo risco, liquidez e prote√ß√£o contra a infla√ß√£o, al√©m de alinharem-se com o objetivo de renda previs√≠vel e baixa volatilidade.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compara√ß√£o do MESMO PROMPT para LLM e LRM\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Importar os m√≥dulos\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from typing import Tuple, Optional\n",
    "from groq import Groq\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Defindo o prompt\n",
    "cenario = {\n",
    "    \"perfil\": \"conservador\",\n",
    "    \"inflacao_projetada_aa\": 5.0,\n",
    "    \"cdi_aa\": 14.5,\n",
    "    \"vencimentos_anos\": [2026, 2027],\n",
    "    \"objetivo\": \"renda previs√≠vel com baixa volatilidade\",\n",
    "}\n",
    "\n",
    "cenario_fmt = json.dumps(cenario, ensure_ascii=False)\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Voc√™ √© um analista de investimentos.\n",
    "\n",
    "Dado o cen√°rio:\n",
    "- {cenario_fmt}\n",
    "\n",
    "Decida entre:\n",
    "- t√≠tulo atrelado ao CDI;\n",
    "- prefixado curto;\n",
    "- IPCA+ longo.\n",
    "\n",
    "Importante:\n",
    "\n",
    "1. Resposta e racioc√≠nio sempre em portug√™s do brasil.\n",
    "2. Estruture o racioc√≠nio em etapas (riscos, liquidez, duration, sensibilidade √† infla√ß√£o).\n",
    "3. Apresente a recomenda√ß√£o final e uma pol√≠tica de rebalanceamento simples.\n",
    "4. Use n√∫meros aproximados e justificativas claras.\n",
    "\"\"\"\n",
    "\n",
    "# T√≠tulo das compara√ß√µes\n",
    "display(Markdown(\"## üî¨ Compara√ß√£o Lado a Lado ‚Äî LLM vs LRM (MESMO prompt)\"))\n",
    "display(Markdown(f\"### üìù Prompt usado nos dois modelos\\n> {prompt.replace('\\\\n', '\\\\n> ')}\"))\n",
    "\n",
    "# M√°ximo de tokens\n",
    "total_tokens_resposta=2000\n",
    "\n",
    "# LLM\n",
    "modelo_llm, saida_llm, tempo_llm = perguntar_llm(\n",
    "    pergunta=prompt,\n",
    "    sistema=\"Responda em Markdown; explicite depend√™ncias, riscos e mitiga√ß√£o.\",\n",
    "    max_tokens_resposta=total_tokens_resposta\n",
    ")\n",
    "\n",
    "exibir_resposta(\n",
    "    modelo=modelo_llm,\n",
    "    pergunta=prompt,\n",
    "    resposta=saida_llm,\n",
    "    tempo=tempo_llm\n",
    ")\n",
    "\n",
    "# LRM\n",
    "modelo_lrm, saida_lrm, cadeia_lrm, tempo_lrm = perguntar_lrm(\n",
    "    pergunta=prompt,\n",
    "    sistema=\"Responda em Markdown; explicite depend√™ncias, riscos e mitiga√ß√£o.\",\n",
    "    max_tokens_resposta=total_tokens_resposta\n",
    ")\n",
    "\n",
    "exibir_resposta(\n",
    "    modelo=modelo_lrm,\n",
    "    pergunta=prompt,\n",
    "    resposta=saida_lrm,\n",
    "    raciocinio=cadeia_lrm,\n",
    "    tempo=tempo_lrm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yG9bx5kR2ZmO"
   },
   "source": [
    "#### CEN√ÅRIO 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HUj2yrlf2BJY",
    "outputId": "627313a2-903d-4fe8-81fc-648851b686f8"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## üî¨ Compara√ß√£o LLM vs LRM ‚Äî **mesmo cen√°rio**, pap√©is diferentes"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üìù Prompt (usu√°rio) enviado *igual* aos dois modelos"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> Crie um plano de 6 semanas para lan√ßar um MVP de assistente de atendimento:\n",
       "> \n",
       ">   - Backend: APIs j√° existentes.\n",
       ">   - Frontend: web app simples.\n",
       ">   - Equipe: 2 devs full-stack, 1 QA, 1 PM; sprint semanal.\n",
       ">   - Restri√ß√µes: integra√ß√£o com WhatsApp Business na semana 3+; testes de carga na semana 5.\n",
       ">   - Entreg√°veis por semana; riscos e mitiga√ß√£o; crit√©rios de aceite."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "## üß† Modelo: `llama-3.3-70b-versatile`\n",
       "**‚è± Tempo de execu√ß√£o:** 2.80s\n",
       "\n",
       "\n",
       "\n",
       "### üì• Pergunta\n",
       "\n",
       "Crie um plano de 6 semanas para lan√ßar um MVP de assistente de atendimento:\n",
       "\n",
       "  - Backend: APIs j√° existentes.\n",
       "  - Frontend: web app simples.\n",
       "  - Equipe: 2 devs full-stack, 1 QA, 1 PM; sprint semanal.\n",
       "  - Restri√ß√µes: integra√ß√£o com WhatsApp Business na semana 3+; testes de carga na semana 5.\n",
       "  - Entreg√°veis por semana; riscos e mitiga√ß√£o; crit√©rios de aceite.\n",
       "\n",
       "### üì§ Resposta\n",
       "\n",
       "### Plano de 6 Semanas para Lan√ßar MVP de Assistente de Atendimento\n",
       "#### Semana 1: Planejamento e Configura√ß√£o Inicial\n",
       "- **Entreg√°veis**:\n",
       "  - Defini√ß√£o de requisitos e funcionalidades do MVP.\n",
       "  - Configura√ß√£o do ambiente de desenvolvimento.\n",
       "  - Planejamento da arquitetura do sistema.\n",
       "- **Riscos e Mitiga√ß√£o**:\n",
       "  - Risco de atraso no planejamento.\n",
       "  - Mitiga√ß√£o: Reuni√µes di√°rias para garantir o progresso.\n",
       "- **Crit√©rios de Aceite**:\n",
       "  - Documento de requisitos aprovado.\n",
       "  - Ambiente de desenvolvimento configurado e testado.\n",
       "\n",
       "#### Semana 2: Desenvolvimento do Frontend\n",
       "- **Entreg√°veis**:\n",
       "  - Desenvolvimento da interface do usu√°rio.\n",
       "  - Integra√ß√£o com APIs existentes para funcionalidades b√°sicas.\n",
       "- **Riscos e Mitiga√ß√£o**:\n",
       "  - Dificuldades na integra√ß√£o com APIs.\n",
       "  - Mitiga√ß√£o: Comunica√ß√£o frequente com a equipe de backend.\n",
       "- **Crit√©rios de Aceite**:\n",
       "  - Interface do usu√°rio funcional.\n",
       "  - Integra√ß√£o b√°sica com APIs testada.\n",
       "\n",
       "#### Semana 3: Integra√ß√£o com WhatsApp Business\n",
       "- **Entreg√°veis**:\n",
       "  - Integra√ß√£o do assistente com o WhatsApp Business.\n",
       "  - Implementa√ß√£o de funcionalidades de envio e recebimento de mensagens.\n",
       "- **Riscos e Mitiga√ß√£o**:\n",
       "  - Complexidades na integra√ß√£o com o WhatsApp.\n",
       "  - Mitiga√ß√£o: Consultoria especializada se necess√°rio.\n",
       "- **Crit√©rios de Aceite**:\n",
       "  - Mensagens enviadas e recebidas com sucesso.\n",
       "  - Funcionalidades b√°sicas de atendimento via WhatsApp implementadas.\n",
       "\n",
       "#### Semana 4: Aperfei√ßoamento e Testes Unit√°rios\n",
       "- **Entreg√°veis**:\n",
       "  - Aperfei√ßoamento da interface do usu√°rio e experi√™ncia do cliente.\n",
       "  - Implementa√ß√£o de testes unit√°rios para garantir a qualidade do c√≥digo.\n",
       "- **Riscos e Mitiga√ß√£o**:\n",
       "  - Atrasos nos testes unit√°rios.\n",
       "  - Mitiga√ß√£o: Prioriza√ß√£o de testes cr√≠ticos.\n",
       "- **Crit√©rios de Aceite**:\n",
       "  - Testes unit√°rios implementados e passando.\n",
       "  - Interface do usu√°rio aperfei√ßoada e testada.\n",
       "\n",
       "#### Semana 5: Testes de Carga e Performance\n",
       "- **Entreg√°veis**:\n",
       "  - Realiza√ß√£o de testes de carga para garantir a escalabilidade do sistema.\n",
       "  - An√°lise de performance e otimiza√ß√µes necess√°rias.\n",
       "- **Riscos e Mitiga√ß√£o**:\n",
       "  - Resultados de testes de carga abaixo do esperado.\n",
       "  - Mitiga√ß√£o: Planejamento de otimiza√ß√µes e ajustes.\n",
       "- **Crit√©rios de Aceite**:\n",
       "  - Testes de carga realizados com resultados satisfat√≥rios.\n",
       "  - Otimiza√ß√µes de performance implementadas.\n",
       "\n",
       "#### Semana 6: Prepara√ß√£o para o Lan√ßamento\n",
       "- **Entreg√°veis**:\n",
       "  - Finaliza√ß√£o de todos os aspectos do MVP.\n",
       "  - Prepara√ß√£o para o lan√ßamento, incluindo documenta√ß√£o e suporte.\n",
       "- **Riscos e Mitiga√ß√£o**:\n",
       "  - Atrasos no lan√ßamento.\n",
       "  - Mitiga√ß√£o: Planejamento rigoroso e conting√™ncias.\n",
       "- **Crit√©rios de Aceite**:\n",
       "  - MVP completamente funcional e testado.\n",
       "  - Lan√ßamento realizado com sucesso.\n",
       "\n",
       "### Decis√µes e Justificativas\n",
       "- **Prioriza√ß√£o**: A prioriza√ß√£o das tarefas foi baseada na depend√™ncia entre elas e na import√¢ncia para o lan√ßamento do MVP. A integra√ß√£o com o WhatsApp Business, por exemplo, foi priorizada para a semana 3, considerando sua complexidade e a necessidade de ter um frontend b√°sico funcionando.\n",
       "- **Riscos e Mitiga√ß√£o**: A identifica√ß√£o de riscos e a proposi√ß√£o de mitiga√ß√£o foram cruciais para antecipar e resolver problemas potenciais, como dificuldades na integra√ß√£o com APIs ou resultados de testes de carga insatisfat√≥rios.\n",
       "- **Crit√©rios de Aceite**: Os crit√©rios de aceite foram definidos para garantir que cada entrega atenda aos padr√µes de qualidade e funcionalidade necess√°rios para o lan√ßamento do MVP.\n",
       "- **Equipe e Recursos**: A aloca√ß√£o de recursos humanos e tecnol√≥gicos foi considerada para cada semana, garantindo que a equipe esteja bem dimensionada para as tarefas propostas e que os recursos necess√°rios estejam dispon√≠veis.\n",
       "- **Flexibilidade**: O plano permite uma certa flexibilidade para ajustes necess√°rios ao longo do caminho, considerando que imprevistos podem surgir e requerer adapta√ß√µes no cronograma ou na abordagem.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "## üß† Modelo: `deepseek-r1-distill-llama-70b`\n",
       "**‚è± Tempo de execu√ß√£o:** 7.33s\n",
       "\n",
       "\n",
       "\n",
       "## üßê Racioc√≠nio                                \n",
       "================================================\n",
       "\n",
       "Okay, I need to create a 6-week plan to launch an MVP for a customer service assistant. The user has provided specific details about the team, backend, frontend, and some constraints. Let me break this down step by step.\n",
       "\n",
       "First, I should start by understanding the project scope. The backend uses existing APIs, which is a plus because it saves time. The frontend is a simple web app, so the focus will be on integrating the backend APIs smoothly. The team consists of 2 full-stack developers, 1 QA, and 1 PM, working in weekly sprints. \n",
       "\n",
       "The constraints mention that integration with WhatsApp Business can only start from week 3 onwards, and load testing is scheduled for week 5. Deliverables are needed each week, along with risk mitigation plans and acceptance criteria.\n",
       "\n",
       "I'll begin by decomposing the project into weekly sprints, considering dependencies. Week 1 should focus on setting up the project and initial backend integration. Since the backend APIs are already in place, the developers can start integrating them into the web app right away. The QA can begin setting up the testing environment.\n",
       "\n",
       "In Week 2, the frontend development starts. The developers will work on the user interface, ensuring it's simple and functional. The QA will start creating test cases based on the MVP features.\n",
       "\n",
       "Week 3 is crucial because that's when the WhatsApp Business integration begins. This is a high-risk area because integrating with external services can have unforeseen issues. The team needs to handle authentication and message handling carefully. The QA will start testing the core features to ensure everything works before moving on to the integration.\n",
       "\n",
       "Week 4 will continue with the WhatsApp integration, focusing on testing and stabilization. The QA will conduct regression testing to make sure nothing broke during integration. This is also a time for bug fixes and optimizing the user experience.\n",
       "\n",
       "Week 5 is all about performance. Load testing is scheduled here, which is essential to ensure the MVP can handle the expected traffic. If the system doesn't perform well, it could lead to a poor user experience. The team will also finalize the MVP and prepare for deployment.\n",
       "\n",
       "Finally, Week 6 is deployment and monitoring. The MVP goes live, and the team monitors its performance. Any critical issues are addressed immediately, and the team starts gathering feedback for future improvements.\n",
       "\n",
       "Now, considering the risks. The main risks are delays in WhatsApp integration, which could cascade into later weeks. To mitigate this, the PM should have a contingency plan, maybe allocating more resources or negotiating with the WhatsApp team if possible. Another risk is the load testing failing, which could delay deployment. The team should run preliminary tests earlier to catch issues before Week 5.\n",
       "\n",
       "For estimations, each developer has about 40 hours a week, so with two developers, that's 80 hours. The QA has 40 hours, and the PM 20. This gives a total of 140 hours per sprint. Margins should be 20% to account for unexpected issues.\n",
       "\n",
       "The critical path here is the WhatsApp integration and load testing. Any delays in these areas will directly impact the launch date. Therefore, these tasks need to be closely monitored.\n",
       "\n",
       "Acceptance criteria should be clear each week. For example, in Week 1, the setup and initial integration must be done. In Week 3, successful WhatsApp integration is a must. By Week 5, the system must pass load tests, and in Week 6, deployment without critical issues.\n",
       "\n",
       "In terms of decisions, starting with backend integration in Week 1 makes sense because it's already available. Prioritizing WhatsApp integration from Week 3 allows time for initial setup without blocking other tasks. Load testing in Week 5 ensures performance is checked before launch. Allocating 20% margins accounts for unexpected issues, which is a safe approach.\n",
       "\n",
       "Overall, the plan is structured to handle dependencies, mitigate risks, and ensure each sprint builds towards a successful MVP launch. The team's structure and the allocation of tasks per sprint should help in delivering the project on time with the required quality.\n",
       "\n",
       "### üì• Pergunta\n",
       "\n",
       "Crie um plano de 6 semanas para lan√ßar um MVP de assistente de atendimento:\n",
       "\n",
       "  - Backend: APIs j√° existentes.\n",
       "  - Frontend: web app simples.\n",
       "  - Equipe: 2 devs full-stack, 1 QA, 1 PM; sprint semanal.\n",
       "  - Restri√ß√µes: integra√ß√£o com WhatsApp Business na semana 3+; testes de carga na semana 5.\n",
       "  - Entreg√°veis por semana; riscos e mitiga√ß√£o; crit√©rios de aceite.\n",
       "\n",
       "### üì§ Resposta\n",
       "\n",
       "### Plano de 6 Semanas para Lan√ßar MVP de Assistente de Atendimento\n",
       "\n",
       "#### 1) Decomposi√ß√£o em Etapas\n",
       "\n",
       "| Semana | Etapa                          | Depend√™ncias                     | Riscos                                      | Trade-offs                                   |\n",
       "|--------|--------------------------------|----------------------------------|---------------------------------------------|---------------------------------------------|\n",
       "| 1      | Setup e Integra√ß√£o Inicial    | APIs existentes                  | Integra√ß√£o inicial pode falhar              | Priorizar backend sobre frontend              |\n",
       "| 2      | Desenvolvimento Frontend       | Backend funcional                | Atraso no frontend                           | Simplificar UI para entrega r√°pida           |\n",
       "| 3      | Integra√ß√£o WhatsApp Business   | Integra√ß√£o a partir da semana 3  | Complexidade na integra√ß√£o                    | Foco em funcionalidade essencial             |\n",
       "| 4      | Testes e Estabiliza√ß√£o        | Integra√ß√£o est√°vel               | Problemas n√£o detectados                     | Aumentar testes unit√°rios                    |\n",
       "| 5      | Testes de Carga                | Sistema est√°vel                  | Falta de desempenho                         | Realizar testes em ambiente real              |\n",
       "| 6      | Deploy e Monitoramento         | Sistema validado                 | Problemas p√≥s-deploy                         | Monitoramento constante                     |\n",
       "\n",
       "#### 2) Estimativas Simples\n",
       "\n",
       "- **Horas por Papel**:\n",
       "  - Desenvolvedores: 40 horas/semana\n",
       "  - QA: 40 horas/semana\n",
       "  - PM: 20 horas/semana\n",
       "\n",
       "- **Capacidade por Sprint**: 140 horas\n",
       "\n",
       "- **Margens**: 20% para imprevistos\n",
       "\n",
       "#### 3) Tabela de Riscos\n",
       "\n",
       "| Risco                     | Probabilidade | Impacto | Mitiga√ß√£o                                      |\n",
       "|----------------------------|---------------|---------|-----------------------------------------------|\n",
       "| Atraso na Integra√ß√£o       | Alta          | Alto    | Conting√™ncia e negocia√ß√£o                     |\n",
       "| Falha nos Testes de Carga   | M√©dia         | Alto    | Testes preliminares                           |\n",
       "| Problemas na Integra√ß√£o     | M√©dia         | M√©dio   | Testes unit√°rios intensivos                    |\n",
       "\n",
       "**Caminho Cr√≠tico**: Integra√ß√£o WhatsApp e Testes de Carga\n",
       "\n",
       "#### 4) Crit√©rios de Aceite por Semana\n",
       "\n",
       "- **Semana 1**: Backend integrado e funcional\n",
       "- **Semana 2**: Frontend b√°sico funcional\n",
       "- **Semana 3**: Integra√ß√£o WhatsApp bem-sucedida\n",
       "- **Semana 4**: Sistema est√°vel e testado\n",
       "- **Semana 5**: Sistema perform√°tico\n",
       "- **Semana 6**: MVP deployado e monitorado\n",
       "\n",
       "#### 5) Formato de Semanas com Checklist\n",
       "\n",
       "1. **Semana 1**\n",
       "   - [ ] Configurar ambiente\n",
       "   - [ ] Integra√ß√£o backend inicial\n",
       "   - [ ] Setup QA\n",
       "\n",
       "2. **Semana 2**\n",
       "   - [ ] Desenvolver frontend\n",
       "   - [ ] Testes unit√°rios\n",
       "\n",
       "3. **Semana 3**\n",
       "   - [ ] Iniciar integra√ß√£o WhatsApp\n",
       "   - [ ] Testes core features\n",
       "\n",
       "4. **Semana 4**\n",
       "   - [ ] Continuar integra√ß√£o\n",
       "   - [ ] Testes de regress√£o\n",
       "\n",
       "5. **Semana 5**\n",
       "   - [ ] Testes de carga\n",
       "   - [ ] Finalizar MVP\n",
       "\n",
       "6. **Semana 6**\n",
       "   - [ ] Deploy\n",
       "   - [ ] Monitoramento\n",
       "\n",
       "#### Decis√µes e Justificativas\n",
       "\n",
       "- **Prioriza√ß√£o Backend**: Utiliza APIs existentes para agilizar o in√≠cio.\n",
       "- **Integra√ß√£o WhatsApp na Semana 3**: Permite tempo para resolver problemas sem atrasar.\n",
       "- **Testes de Carga na Semana 5**: Garante desempenho antes do lan√ßamento.\n",
       "- **Margem de 20%**: Absorve imprevistos e riscos.\n",
       "\n",
       "**Recomenda√ß√£o Final**: Seguir o plano estruturado, monitorando de perto a integra√ß√£o e testes de carga, com revis√µes semanais para ajustes.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compara√ß√£o do MESMO PROMPT para LLM e LRM\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Importar os m√≥dulos\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from typing import Tuple, Optional\n",
    "from groq import Groq\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def _blockquote(txt: str) -> str:\n",
    "    txt = (txt or \"\").strip()\n",
    "    return \"\" if not txt else \"\\n\".join(\"> \" + ln for ln in txt.splitlines())\n",
    "\n",
    "# Mesmo CEN√ÅRIO (user prompt id√™ntico para ambos) ===\n",
    "prompt_comum = \"\"\"\n",
    "Crie um plano de 6 semanas para lan√ßar um MVP de assistente de atendimento:\n",
    "\n",
    "  - Backend: APIs j√° existentes.\n",
    "  - Frontend: web app simples.\n",
    "  - Equipe: 2 devs full-stack, 1 QA, 1 PM; sprint semanal.\n",
    "  - Restri√ß√µes: integra√ß√£o com WhatsApp Business na semana 3+; testes de carga na semana 5.\n",
    "  - Entreg√°veis por semana; riscos e mitiga√ß√£o; crit√©rios de aceite.\n",
    "\"\"\".strip()\n",
    "\n",
    "display(Markdown(\"## üî¨ Compara√ß√£o LLM vs LRM ‚Äî **mesmo cen√°rio**, pap√©is diferentes\"))\n",
    "display(Markdown(\"### üìù Prompt (usu√°rio) enviado *igual* aos dois modelos\"))\n",
    "display(Markdown(_blockquote(prompt_comum)))\n",
    "\n",
    "# M√°ximo de tokens\n",
    "total_tokens_resposta=2000\n",
    "\n",
    "# Regras de SISTEMA para separar os perfis\n",
    "prompt_sistema_comum =f\"\"\"\n",
    "Voc√™ √© um analista de projetos e deve EXPLICAR O RACIOC√çNIO.\n",
    "-\n",
    "Responda em Markdown, com:\n",
    "\n",
    "  1) Decomposi√ß√£o em etapas (depend√™ncias, riscos, trade-offs).\n",
    "  2) Estimativas simples (horas por papel, capacidade por sprint, margens).\n",
    "  3) Tabela de riscos (probabilidade x impacto x mitiga√ß√£o) e caminho cr√≠tico.\n",
    "  4) Crit√©rios de aceite objetivos por semana.\n",
    "  5) Formate como lista de semanas com checklist objetivo.\n",
    "\n",
    "  Inclua uma se√ß√£o final de 'Decis√µes e justificativas' com o porqu√™ de cada escolha.\n",
    "\n",
    "Importante:\n",
    "\n",
    "  1. Texto do racioc√≠nio sempre em portugu√™s do brasil.\n",
    "  2. Estruture o racioc√≠nio em etapas (riscos, liquidez, duration, sensibilidade √† infla√ß√£o).\n",
    "  3. Apresente a recomenda√ß√£o final e uma pol√≠tica de rebalanceamento simples.\n",
    "  4. Use n√∫meros aproximados e justificativas claras.\n",
    "  5. M√°ximo de {total_tokens_resposta} tokens no retorno.\n",
    "\"\"\"\n",
    "\n",
    "# LLM: s√≠ntese direta, sem cadeia expl√≠cita ===\n",
    "modelo_llm, saida_llm, tempo_llm = perguntar_llm(\n",
    "    pergunta=prompt_comum,\n",
    "    sistema=prompt_sistema_comum,\n",
    "    max_tokens_resposta=8192\n",
    ")\n",
    "\n",
    "# Exibe resposta LLM\n",
    "exibir_resposta(\n",
    "    modelo=modelo_llm,\n",
    "    pergunta=prompt_comum,\n",
    "    resposta=saida_llm,\n",
    "    tempo=tempo_llm\n",
    ")\n",
    "\n",
    "# -----\n",
    "\n",
    "# LRM: estrutura com cadeia de racioc√≠nio separada ===\n",
    "modelo_lrm, saida_lrm, cadeia_lrm, tempo_lrm = perguntar_lrm(\n",
    "    pergunta=prompt_comum,\n",
    "    sistema=prompt_sistema_comum,\n",
    "    max_tokens_resposta=2000\n",
    ")\n",
    "\n",
    "# Exibe LRM com racioc√≠nio destacado\n",
    "exibir_resposta(\n",
    "    modelo=modelo_lrm,\n",
    "    pergunta=prompt_comum,\n",
    "    resposta=saida_lrm,\n",
    "    raciocinio=cadeia_lrm,\n",
    "    tempo=tempo_lrm\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPxgx2wHjrQL9AahRW8ZV4B",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
