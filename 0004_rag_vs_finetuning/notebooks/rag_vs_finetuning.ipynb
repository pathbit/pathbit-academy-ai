{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "150bb2d9",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/pathbit/pathbit-academy-ai/blob/master/0004_rag_vs_finetuning/notebooks/rag_vs_finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "# ‚ú® **Pathbit Academy AI**\n",
        "---\n",
        "\n",
        "## üéØ **Artigo 0004: RAG vs Fine-Tuning - A escolha que pode salvar (ou afundar) seu projeto**\n",
        "\n",
        "üö® **IMPORTANTE:**\n",
        "\n",
        "*üí• Se voc√™ j√° executou os notebooks anteriores, este ser√° moleza!*\n",
        "\n",
        "**Artigo de refer√™ncia:** [RAG vs Fine-Tuning](https://github.com/pathbit/pathbit-academy-ai/blob/master/0004_rag_vs_finetuning/article/ARTICLE.md)\n",
        "\n",
        "**Artigos anteriores:**\n",
        "- [Artigo 0001: LLM vs LRM](https://github.com/pathbit/pathbit-academy-ai/blob/master/0001_llm_x_lrm/article/ARTICLE.md)\n",
        "- [Artigo 0002: Embeddings e Vetoriza√ß√£o](https://github.com/pathbit/pathbit-academy-ai/blob/master/0002_embeddings_vetorizacao/article/ARTICLE.md)\n",
        "- [Artigo 0003: RAG e Vector Database](https://github.com/pathbit/pathbit-academy-ai/blob/master/0003_rag_vector_database/article/ARTICLE.md)\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ **Este notebook cont√©m:**\n",
        "- ‚úÖ **Compara√ß√£o t√©cnica** entre RAG e Fine-Tuning\n",
        "- ‚úÖ **Caso pr√°tico real** (Assistente de Investimentos)\n",
        "- ‚úÖ **3 implementa√ß√µes** para comparar\n",
        "- ‚úÖ **An√°lise de custos** detalhada\n",
        "- ‚úÖ **Quando usar cada um**\n",
        "\n",
        "---\n",
        "\n",
        "## üìä **O que vamos construir:**\n",
        "\n",
        "### ü§ñ Teste 1: Modelo Base\n",
        "GPT sem customiza√ß√£o (baseline)\n",
        "\n",
        "### üîç Teste 2: RAG\n",
        "Modelo + Base de conhecimento sobre investimentos\n",
        "\n",
        "### üéì Teste 3: Fine-Tuning  \n",
        "Modelo treinado (simulado com few-shot)\n",
        "\n",
        "### ‚öñÔ∏è Compara√ß√£o\n",
        "Qual funciona melhor? Quanto custa? Quando usar?\n",
        "\n",
        "---\n",
        "\n",
        "## üí° **Caso de Uso Real: Assistente Financeiro**\n",
        "\n",
        "Queremos um assistente que responda sobre investimentos (CDB, Tesouro, FIIs, A√ß√µes) com:\n",
        "- ‚úÖ Informa√ß√µes precisas e atualizadas\n",
        "- ‚úÖ Tom did√°tico e pr√°tico\n",
        "- ‚úÖ Exemplos num√©ricos\n",
        "- ‚úÖ Cita√ß√£o de fontes\n",
        "\n",
        "**Pergunta que vamos responder:** RAG ou Fine-Tuning para este caso?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62a5ac6c",
      "metadata": {},
      "source": [
        "## üì¶ Setup e Instala√ß√£o\n",
        "\n",
        "**Tempo estimado:** 3-5 minutos (primeira execu√ß√£o)\n",
        "\n",
        "---\n",
        "\n",
        "### üÜò **Solu√ß√£o para Erro de Metadata no Colab:**\n",
        "\n",
        "Se voc√™ v√™ este erro:\n",
        "```\n",
        "the 'state' key is missing from 'metadata.widgets'\n",
        "```\n",
        "\n",
        "**Solu√ß√£o r√°pida:**\n",
        "1. Abra o notebook pelo GitHub: [Link direto](https://colab.research.google.com/github/pathbit/pathbit-academy-ai/blob/master/0004_rag_vs_finetuning/notebooks/rag_vs_finetuning.ipynb)\n",
        "2. Ou salve uma c√≥pia limpa: `File ‚Üí Download ‚Üí Download .ipynb`\n",
        "3. Fa√ßa upload da c√≥pia no Colab\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "946f740e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîß CORRE√á√ÉO AUTOM√ÅTICA PARA ERRO DE METADATA NO COLAB\n",
        "# ========================================================\n",
        "\n",
        "# Esta c√©lula corrige automaticamente o erro:\n",
        "# \"the 'state' key is missing from 'metadata.widgets'\"\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB_ENV = True\n",
        "\n",
        "    # Tentar corrigir o notebook se houver erro de metadata\n",
        "    try:\n",
        "        import json\n",
        "        from google.colab import files\n",
        "\n",
        "        print(\"üîß Verificando metadados do notebook...\")\n",
        "\n",
        "        # Nota: No Colab, o notebook j√° est√° carregado, ent√£o apenas informamos\n",
        "        print(\"‚úÖ Se voc√™ consegue ver esta mensagem, o notebook est√° OK!\")\n",
        "        print(\"‚ÑπÔ∏è  Se teve erro antes, recarregue a p√°gina (F5)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ÑπÔ∏è  Verifica√ß√£o de metadata: {e}\")\n",
        "\n",
        "except ImportError:\n",
        "    IN_COLAB_ENV = False\n",
        "    print(\"üíª Ambiente Local - Corre√ß√£o de metadata n√£o necess√°ria\")\n",
        "\n",
        "print(\"üéØ Continue com a pr√≥xima c√©lula!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0291ce02",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Ambiente configurado com sucesso!\n",
            "üìÖ Data/Hora: 12/10/2025 13:07:34\n",
            "üêç Python: 3.12.7\n",
            "üìÅ Diret√≥rio: /Users/elielsousa/Projects/pathbit/github/pub/pathbit-academy-ai/0004_rag_vs_finetuning/notebooks\n"
          ]
        }
      ],
      "source": [
        "### üîß **Corre√ß√£o autom√°tica para Google Colab**\n",
        "# üö® **IMPORTANTE:** Se voc√™ estiver executando no Google Colab, esta c√©lula corrige automaticamente problemas de compatibilidade do `tqdm`.\n",
        "\n",
        "# Importa√ß√µes principais\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Configura√ß√£o de visualiza√ß√£o\n",
        "plt.style.use(\"seaborn-v0_8\")\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
        "plt.rcParams[\"font.size\"] = 12\n",
        "\n",
        "# Configura√ß√£o de fonte para evitar warnings de emojis\n",
        "plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
        "import matplotlib\n",
        "\n",
        "matplotlib.rcParams[\"axes.unicode_minus\"] = False\n",
        "\n",
        "# Suprimir avisos do tqdm\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"tqdm\")\n",
        "\n",
        "print(\"‚úÖ Ambiente configurado com sucesso!\")\n",
        "print(f\"üìÖ Data/Hora: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
        "print(f\"üêç Python: {sys.version.split()[0]}\")\n",
        "print(f\"üìÅ Diret√≥rio: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "494320d6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíª Detectado: Ambiente Local\n",
            "‚ÑπÔ∏è  Corre√ß√£o do tqdm n√£o necess√°ria no ambiente local\n",
            "\n",
            "üéØ Ambiente configurado! Continue com a pr√≥xima c√©lula.\n"
          ]
        }
      ],
      "source": [
        "# üîß CORRE√á√ÉO AUTOM√ÅTICA PARA GOOGLE COLAB\n",
        "# ==========================================\n",
        "# Esta c√©lula resolve automaticamente conflitos de depend√™ncias do tqdm\n",
        "\n",
        "# Detectar se estamos no Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "\n",
        "    IN_COLAB = True\n",
        "    print(\"üåê Detectado: Google Colab\")\n",
        "    print(\"üîß Aplicando corre√ß√£o para conflito de tqdm...\")\n",
        "\n",
        "    # CORRE√á√ÉO: Atualizar tqdm para resolver conflitos de depend√™ncias\n",
        "    get_ipython().run_line_magic(\n",
        "        \"pip\", \"install --upgrade tqdm>=4.67 --force-reinstall --quiet\"\n",
        "    )\n",
        "    print(\"‚úÖ tqdm atualizado com sucesso!\")\n",
        "    print(\n",
        "        \"üì¶ Vers√£o do tqdm corrigida para resolver conflitos com datasets e dataproc-spark-connect\"\n",
        "    )\n",
        "\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"üíª Detectado: Ambiente Local\")\n",
        "    print(\"‚ÑπÔ∏è  Corre√ß√£o do tqdm n√£o necess√°ria no ambiente local\")\n",
        "\n",
        "print(\"\\nüéØ Ambiente configurado! Continue com a pr√≥xima c√©lula.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55c83771",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ Verificando depend√™ncias no ambiente local...\n",
            "‚úÖ Todas as depend√™ncias j√° est√£o instaladas!\n",
            "üéØ Notebook pronto para usar!\n",
            "üìä Depend√™ncias carregadas com sucesso!\n"
          ]
        }
      ],
      "source": [
        "# Instalar depend√™ncias (Colab precisa do %pip)\n",
        "if IN_COLAB:\n",
        "    print(\"üì¶ Instalando depend√™ncias no Google Colab...\")\n",
        "    print(\"‚è≥ Isso pode levar 2-3 minutos...\")\n",
        "\n",
        "    # Instalar todas as depend√™ncias de uma vez\n",
        "    get_ipython().run_line_magic(\n",
        "        \"pip\",\n",
        "        \"install -q groq langchain langchain-groq langchain-community langchain-huggingface chromadb sentence-transformers scikit-learn matplotlib seaborn pandas plotly tqdm>=4.67 python-dotenv transformers datasets peft accelerate torch\",\n",
        "    )\n",
        "\n",
        "    print(\"üîß Corrigindo vers√£o do requests para compatibilidade com Colab...\")\n",
        "    get_ipython().run_line_magic(\"pip\", \"install -q requests==2.32.4\")\n",
        "    print(\"‚úÖ requests corrigido!\")\n",
        "    \n",
        "    print(\"‚úÖ Todas as depend√™ncias instaladas!\")\n",
        "else:\n",
        "    print(\"üì¶ Verificando depend√™ncias no ambiente local...\")\n",
        "    try:\n",
        "        import numpy as np\n",
        "        import pandas as pd\n",
        "        import matplotlib.pyplot as plt\n",
        "        import seaborn as sns\n",
        "        import chromadb\n",
        "        from sentence_transformers import SentenceTransformer\n",
        "        from sklearn.metrics.pairwise import cosine_similarity\n",
        "        from dotenv import load_dotenv\n",
        "        from groq import Groq\n",
        "        from langchain_groq import ChatGroq\n",
        "        from langchain_huggingface import HuggingFaceEmbeddings\n",
        "        import transformers\n",
        "        import torch\n",
        "\n",
        "        print(\"‚úÖ Todas as depend√™ncias j√° est√£o instaladas!\")\n",
        "    except ImportError as e:\n",
        "        print(f\"‚ö†Ô∏è Instalando depend√™ncias faltantes: {e}\")\n",
        "        import subprocess\n",
        "        import sys\n",
        "\n",
        "        subprocess.check_call(\n",
        "            [\n",
        "                sys.executable,\n",
        "                \"-m\",\n",
        "                \"pip\",\n",
        "                \"install\",\n",
        "                \"-q\",\n",
        "                \"groq\",\n",
        "                \"langchain\",\n",
        "                \"langchain-groq\",\n",
        "                \"langchain-community\",\n",
        "                \"langchain-huggingface\",\n",
        "                \"chromadb\",\n",
        "                \"sentence-transformers\",\n",
        "                \"scikit-learn\",\n",
        "                \"matplotlib\",\n",
        "                \"seaborn\",\n",
        "                \"pandas\",\n",
        "                \"plotly\",\n",
        "                \"tqdm>=4.67\",\n",
        "                \"python-dotenv\",\n",
        "                \"transformers\",\n",
        "                \"datasets\",\n",
        "                \"peft\",\n",
        "                \"accelerate\",\n",
        "                \"torch\",\n",
        "            ]\n",
        "        )\n",
        "\n",
        "# Importa√ß√µes principais\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Suprimir avisos do tqdm e outros warnings desnecess√°rios\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"tqdm\")\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# Configura√ß√µes adicionais\n",
        "plt.style.use(\"default\")\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "pd.set_option(\"display.width\", None)\n",
        "\n",
        "print(\"üéØ Notebook pronto para usar!\")\n",
        "print(\"üìä Depend√™ncias carregadas com sucesso!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8756b9d4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ GROQ_API_KEY configurada (arquivo .env)\n",
            "ü§ñ Modelo de embeddings: all-MiniLM-L6-v2\n",
            "‚úÖ Modelo de embeddings carregado com sucesso!\n"
          ]
        }
      ],
      "source": [
        "# Importa√ß√µes espec√≠ficas para RAG e Vector Databases\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Para exemplos com Groq (opcional)\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# üîë Configura√ß√£o da API Key do Groq\n",
        "# ====================================\n",
        "def configurar_groq_api():\n",
        "    \"\"\"Configura a API key do Groq de forma simples\"\"\"\n",
        "    # Tentar carregar do arquivo .env primeiro\n",
        "    try:\n",
        "        load_dotenv()\n",
        "        groq_key = os.getenv(\"GROQ_API_KEY\")\n",
        "        if groq_key:\n",
        "            os.environ[\"GROQ_API_KEY\"] = groq_key\n",
        "            print(\"‚úÖ GROQ_API_KEY configurada (arquivo .env)\")\n",
        "            return True\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Se n√£o encontrou no .env e est√° no Colab, tentar secrets\n",
        "    if IN_COLAB:\n",
        "        try:\n",
        "            from google.colab import userdata\n",
        "\n",
        "            groq_key = userdata.get(\"GROQ_API_KEY\")\n",
        "            os.environ[\"GROQ_API_KEY\"] = groq_key\n",
        "            print(\"‚úÖ GROQ_API_KEY configurada (Colab secrets)\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è GROQ_API_KEY n√£o encontrada: {e}\")\n",
        "\n",
        "    print(\"‚ÑπÔ∏è GROQ_API_KEY n√£o configurada - exemplos avan√ßados n√£o funcionar√£o\")\n",
        "    return False\n",
        "\n",
        "# Configurar API Key\n",
        "configurar_groq_api()\n",
        "\n",
        "# Configura√ß√£o do modelo de embeddings\n",
        "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
        "print(f\"ü§ñ Modelo de embeddings: {EMBEDDING_MODEL}\")\n",
        "\n",
        "# Inicializar modelo de embeddings\n",
        "embedding_model = SentenceTransformer(EMBEDDING_MODEL)\n",
        "print(\"‚úÖ Modelo de embeddings carregado com sucesso!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35c8e740",
      "metadata": {},
      "source": [
        "## üìö Parte 1: Preparando os Dados\n",
        "\n",
        "Vamos criar uma base de conhecimento sobre investimentos e exemplos de treinamento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b3730e11",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ 4 documentos carregados\n",
            "‚úÖ 6 exemplos de treinamento preparados\n"
          ]
        }
      ],
      "source": [
        "# Base de conhecimento: Documentos sobre investimentos\n",
        "documentos_investimentos = [\n",
        "    \"\"\"\n",
        "    CDB (Certificado de Dep√≥sito Banc√°rio)\n",
        "    Tipo: Renda Fixa\n",
        "    Rentabilidade: 90% a 120% do CDI\n",
        "    Liquidez: Di√°ria ou com vencimento fixo\n",
        "    Risco: Baixo (FGC at√© R$ 250.000)\n",
        "    Tributa√ß√£o: IR regressivo (22,5% at√© 6 meses, 15% ap√≥s 2 anos)\n",
        "    Ideal para: Reserva de emerg√™ncia e m√©dio prazo\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    Tesouro Selic (LFT)\n",
        "    Tipo: Renda Fixa P√∫blica\n",
        "    Rentabilidade: 100% da Selic\n",
        "    Liquidez: Di√°ria\n",
        "    Risco: Baix√≠ssimo (Tesouro Nacional)\n",
        "    Tributa√ß√£o: IR regressivo + IOF primeiros 30 dias\n",
        "    Ideal para: Reserva de emerg√™ncia, iniciantes\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    Fundos Imobili√°rios (FIIs)\n",
        "    Tipo: Renda Vari√°vel\n",
        "    Rentabilidade: Dividendos mensais (0,5-1%) + valoriza√ß√£o\n",
        "    Liquidez: Alta (bolsa)\n",
        "    Risco: M√©dio a Alto\n",
        "    Tributa√ß√£o: Dividendos isentos, ganho capital 20%\n",
        "    Ideal para: Renda passiva mensal, longo prazo\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    A√ß√µes (Bolsa de Valores)\n",
        "    Tipo: Renda Vari√°vel\n",
        "    Rentabilidade: Vari√°vel\n",
        "    Liquidez: Alta (blue chips)\n",
        "    Risco: Alto\n",
        "    Tributa√ß√£o: 15% ganho capital (vendas > R$ 20k/m√™s)\n",
        "    Ideal para: Longo prazo (5+ anos), perfil arrojado\n",
        "    \"\"\"\n",
        "]\n",
        "\n",
        "# Exemplos para fine-tuning (estilo de resposta desejado)\n",
        "# IMPORTANTE: Mais exemplos em PORTUGU√äS para o modelo aprender melhor\n",
        "exemplos_finetuning = [\n",
        "    {\n",
        "        \"input\": \"Qual o melhor investimento para reserva de emerg√™ncia?\",\n",
        "        \"output\": \"Para reserva de emerg√™ncia recomendo Tesouro Selic ou CDB com liquidez di√°ria. O Tesouro oferece 100 por cento do CDI com risco zero. CDB pode render at√© 120 por cento do CDI mas depende do banco. Mantenha seis meses de despesas.\"\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"CDB ou LCI qual escolher?\",\n",
        "        \"output\": \"LCI √© isenta de IR ent√£o 90 por cento do CDI equivale a 110 p√≥s-IR. Por√©m LCI tem prazo m√≠nimo 90 dias. Se precisa liquidez CDB com liquidez di√°ria. Se pode deixar um ou dois anos LCI compensa.\"\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Vale investir em FIIs?\",\n",
        "        \"output\": \"Sim para renda passiva. FIIs pagam dividendos mensais isentos de IR. Pense longo prazo cinco anos ou mais pois cotas oscilam. Diversifique tijolo escrit√≥rios papel CRIs e h√≠bridos. Comece com fundos maiores que um bilh√£o.\"\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Como funciona o Tesouro Selic?\",\n",
        "        \"output\": \"Tesouro Selic √© t√≠tulo p√∫blico que rende 100 por cento da Selic. Tem liquidez di√°ria e risco baix√≠ssimo. Ideal para reserva de emerg√™ncia. Tem IR regressivo e IOF nos primeiros trinta dias.\"\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Qual a diferen√ßa entre CDB e Tesouro?\",\n",
        "        \"output\": \"CDB √© t√≠tulo privado de banco com FGC at√© 250 mil reais. Tesouro Selic √© p√∫blico do governo com risco menor. Ambos bons para reserva de emerg√™ncia. Tesouro rende 100 por cento do CDI. CDB pode render at√© 120 por cento.\"\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"A√ß√µes s√£o bons investimentos?\",\n",
        "        \"output\": \"A√ß√µes s√£o boas para longo prazo cinco anos ou mais. T√™m risco alto mas potencial de retorno maior. Pague 15 por cento de IR em ganho capital. Ideal para perfil arrojado. N√£o use para reserva de emerg√™ncia.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"‚úÖ {len(documentos_investimentos)} documentos carregados\")\n",
        "print(f\"‚úÖ {len(exemplos_finetuning)} exemplos de treinamento preparados\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77a1e330",
      "metadata": {},
      "source": [
        "## ü§ñ Parte 2: Teste com Modelo Base (Sem Customiza√ß√£o)\n",
        "\n",
        "Vamos testar o GPT sem nenhuma customiza√ß√£o.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ff699182",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "ü§ñ TESTE 1: MODELO BASE (SEM CUSTOMIZA√á√ÉO)\n",
            "================================================================================\n",
            "\n",
            "‚ùì Pergunta: Qual o melhor investimento para reserva de emerg√™ncia?\n",
            "\n",
            "üí¨ Resposta:\n",
            "O melhor investimento para uma reserva de emerg√™ncia depende de v√°rios fatores, incluindo o seu perfil de risco, objetivos financeiros e necessidades pessoais. No entanto, aqui est√£o algumas op√ß√µes comuns que podem ser consideradas:\n",
            "\n",
            "1. **Poupan√ßa**: A poupan√ßa √© uma op√ß√£o segura e l√≠quida, o que significa que voc√™ pode acessar seu dinheiro a qualquer momento. No entanto, os rendimentos podem ser baixos, especialmente em per√≠odos de baixas taxas de juros.\n",
            "2. **CDB (Certificado de Dep√≥sito Banc√°rio)**: O CDB √© um investimento de curto prazo que oferece rendimentos mais altos do que a poupan√ßa, mas com um prazo de vencimento fixo. √â uma op√ß√£o segura, mas voc√™ pode perder o acesso ao seu dinheiro antes do vencimento.\n",
            "3. **Fundos de Renda Fixa**: Os fundos de renda fixa investem em t√≠tulos de d√≠vida, como t√≠tulos do governo e empresas, e oferecem rendimentos mais altos do que a poupan√ßa. No entanto, h√° um risco de perda de valor se os t√≠tulos forem vendidos antes do vencimento.\n",
            "4. **Tesouro Direto**: O Tesouro Direto √© um investimento em t√≠tulos do governo brasile\n",
            "\n",
            "‚è±Ô∏è Tempo: 1.21s\n",
            "üí∞ Custo: ~$0.0001/consulta\n",
            "üîÑ Atualiza√ß√£o: Imposs√≠vel (conhecimento congelado)\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "from groq import Groq\n",
        "\n",
        "client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
        "\n",
        "def testar_modelo_base(pergunta):\n",
        "    \"\"\"Testa modelo base sem customiza√ß√£o\"\"\"\n",
        "    start = time.time()\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "        messages=[{\"role\": \"user\", \"content\": pergunta}],\n",
        "        temperature=0.3,\n",
        "        max_tokens=300\n",
        "    )\n",
        "    tempo = time.time() - start\n",
        "    return response.choices[0].message.content, tempo\n",
        "\n",
        "# Testar\n",
        "print(\"=\"*80)\n",
        "print(\"ü§ñ TESTE 1: MODELO BASE (SEM CUSTOMIZA√á√ÉO)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "pergunta = \"Qual o melhor investimento para reserva de emerg√™ncia?\"\n",
        "print(f\"\\n‚ùì Pergunta: {pergunta}\")\n",
        "\n",
        "resposta_base, tempo_base = testar_modelo_base(pergunta)\n",
        "print(f\"\\nüí¨ Resposta:\\n{resposta_base}\")\n",
        "print(f\"\\n‚è±Ô∏è Tempo: {tempo_base:.2f}s\")\n",
        "print(f\"üí∞ Custo: ~$0.0001/consulta\")\n",
        "print(f\"üîÑ Atualiza√ß√£o: Imposs√≠vel (conhecimento congelado)\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a30e272c",
      "metadata": {},
      "source": [
        "## üîç Parte 3: RAG (Modelo + Base de Conhecimento)\n",
        "\n",
        "Agora vamos implementar RAG completo com vector database.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "37655d9d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ Implementando RAG...\n",
            "\n",
            "‚úÖ 5 chunks criados\n",
            "üß† Criando embeddings...\n",
            "‚úÖ Vector store criado\n",
            "‚úÖ Sistema RAG pronto!\n"
          ]
        }
      ],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Desabilitar telemetria do ChromaDB ANTES de qualquer importa√ß√£o\n",
        "os.environ[\"ANONYMIZED_TELEMETRY\"] = \"False\"\n",
        "os.environ[\"CHROMA_TELEMETRY\"] = \"False\"\n",
        "\n",
        "# Suprimir TODOS os outputs de telemetria\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Importar ChromaDB e configurar settings com telemetria desabilitada\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "\n",
        "# Criar cliente ChromaDB com telemetria desabilitada\n",
        "chroma_settings = Settings(\n",
        "    anonymized_telemetry=False,\n",
        "    allow_reset=True\n",
        ")\n",
        "\n",
        "# Monkey patch AGRESSIVO para desabilitar telemetria na raiz\n",
        "try:\n",
        "    # Desabilitar o m√©todo capture diretamente\n",
        "    from chromadb.telemetry.product import posthog\n",
        "    \n",
        "    # Substituir o m√©todo capture para n√£o fazer nada\n",
        "    def mock_capture(self, event):\n",
        "        pass\n",
        "    \n",
        "    posthog.Posthog.capture = mock_capture\n",
        "    \n",
        "    # Tamb√©m desabilitar _direct_capture\n",
        "    def mock_direct_capture(self, event):\n",
        "        pass\n",
        "    \n",
        "    posthog.Posthog._direct_capture = mock_direct_capture\n",
        "except Exception as e:\n",
        "    # Se falhar, apenas ignora\n",
        "    pass\n",
        "\n",
        "# Importar Chroma DEPOIS de configurar telemetria\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "print(\"üîÑ Implementando RAG...\\n\")\n",
        "\n",
        "# 1. Criar chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=30)\n",
        "chunks = []\n",
        "for doc in documentos_investimentos:\n",
        "    chunks.extend(text_splitter.split_text(doc))\n",
        "print(f\"‚úÖ {len(chunks)} chunks criados\")\n",
        "\n",
        "# 2. Criar embeddings (pode demorar 1-2 min)\n",
        "print(\"üß† Criando embeddings...\")\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Criar vector store com settings que desabilitam telemetria\n",
        "vectorstore = Chroma.from_texts(\n",
        "    texts=chunks, \n",
        "    embedding=embeddings,\n",
        "    client_settings=chroma_settings\n",
        ")\n",
        "print(\"‚úÖ Vector store criado\")\n",
        "\n",
        "# 3. Configurar RAG chain\n",
        "llm = ChatGroq(model=\"llama-3.3-70b-versatile\", temperature=0.3)\n",
        "template = \"\"\"Voc√™ √© especialista em investimentos. Use APENAS o contexto fornecido.\n",
        "\n",
        "Contexto: {context}\n",
        "\n",
        "Pergunta: {question}\n",
        "\n",
        "Resposta (cite produtos do contexto):\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
        "rag_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 2}),\n",
        "    chain_type_kwargs={\"prompt\": prompt},\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Sistema RAG pronto!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "418ce8be",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "üîç TESTE 2: RAG (MODELO + CONHECIMENTO)\n",
            "================================================================================\n",
            "\n",
            "‚ùì Pergunta: Qual o melhor investimento para reserva de emerg√™ncia?\n",
            "\n",
            "üí¨ Resposta RAG:\n",
            "Com base no contexto fornecido, o melhor investimento para reserva de emerg√™ncia n√£o √© explicitamente mencionado, mas considerando as caracter√≠sticas de liquidez e risco, os Fundos Imobili√°rios (FIIs) n√£o s√£o o melhor escolha devido ao seu risco m√©dio a alto.\n",
            "\n",
            "No entanto, o contexto inicial menciona que um investimento √© \"Ideal para: Reserva de emerg√™ncia e m√©dio prazo\", mas n√£o especifica o nome desse investimento. Portanto, n√£o √© poss√≠vel recomendar um investimento espec√≠fico com base nas informa√ß√µes fornecidas, pois o contexto n√£o fornece detalhes sobre um investimento que combine diretamente com as necessidades de uma reserva de emerg√™ncia, que geralmente requerem liquidez alta e risco baixo.\n",
            "\n",
            "Se tiv√©ssemos que escolher com base nos produtos mencionados (Fundos Imobili√°rios), n√£o seria a melhor op√ß√£o para reserva de emerg√™ncia devido ao seu risco. No entanto, como n√£o h√° outras op√ß√µes listadas, e considerando a necessidade de liquidez e baixo risco para uma reserva de emerg√™ncia, o contexto n√£o fornece uma resposta clara dentro dos par√¢metros dados.\n",
            "\n",
            "üìö Documentos usados: 2\n",
            "‚è±Ô∏è Tempo: 1.17s (busca + gera√ß√£o)\n",
            "üí∞ Custo: ~$0.0003/consulta (embeddings + LLM)\n",
            "üîÑ Atualiza√ß√£o: Imediata (atualiza documentos)\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Testar RAG\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üîç TESTE 2: RAG (MODELO + CONHECIMENTO)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "start = time.time()\n",
        "resultado_rag = rag_chain.invoke({\"query\": pergunta})\n",
        "tempo_rag = time.time() - start\n",
        "\n",
        "print(f\"\\n‚ùì Pergunta: {pergunta}\")\n",
        "print(f\"\\nüí¨ Resposta RAG:\\n{resultado_rag['result']}\")\n",
        "print(f\"\\nüìö Documentos usados: {len(resultado_rag['source_documents'])}\")\n",
        "print(f\"‚è±Ô∏è Tempo: {tempo_rag:.2f}s (busca + gera√ß√£o)\")\n",
        "print(f\"üí∞ Custo: ~$0.0003/consulta (embeddings + LLM)\")\n",
        "print(f\"üîÑ Atualiza√ß√£o: Imediata (atualiza documentos)\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a6c26d0",
      "metadata": {},
      "source": [
        "## üéì Parte 4: Fine-Tuning REAL com LoRA\n",
        "\n",
        "Agora vamos fazer um **fine-tuning REAL** usando LoRA (Low-Rank Adaptation)!\n",
        "\n",
        "**‚ö†Ô∏è IMPORTANTE - Este √© um \"Fine-Tuning Demonstrativo\":**\n",
        "\n",
        "‚úÖ **O que √© REAL:**\n",
        "- C√≥digo real de fine-tuning com LoRA\n",
        "- Treinamento real com gradientes e backpropagation\n",
        "- Modelo realmente aprende e muda pesos\n",
        "- Usa PyTorch, Transformers e PEFT (mesmas libs de produ√ß√£o)\n",
        "\n",
        "‚ö†Ô∏è **O que √© DEMONSTRATIVO (n√£o produ√ß√£o):**\n",
        "- Poucos exemplos (6 vs 1.000-10.000 em produ√ß√£o)\n",
        "- Poucas epochs (15 vs 50-100 em produ√ß√£o)\n",
        "- Modelo pequeno (GPT-2 Portugu√™s 124M vs GPT-3 7B-70B)\n",
        "- CPU (vs GPU A100/H100 em produ√ß√£o)\n",
        "- Minutos de treino (vs horas/dias em produ√ß√£o)\n",
        "\n",
        "**Objetivo:** Mostrar o processo real de fine-tuning, mesmo que simplificado para fins educacionais.\n",
        "\n",
        "**Nota:** Usamos GPT-2 pr√©-treinado em portugu√™s para que as respostas sejam em portugu√™s.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "168c9a5a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "üéì FINE-TUNING REAL COM LORA\n",
            "================================================================================\n",
            "\n",
            "‚úÖ PyTorch 2.8.0\n",
            "‚úÖ Device: cpu (CPU - est√°vel para treinamento)\n",
            "‚úÖ MPS desabilitado para evitar problemas de mem√≥ria\n",
            "\n",
            "üì• Carregando pierreguillou/gpt2-small-portuguese (modelo em portugu√™s)...\n",
            "‚úÖ Modelo portugu√™s carregado: 124,439,808 par√¢metros\n",
            "\n",
            "üìö Preparando dados de treinamento...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9dbe9be61cf3410dad3ca7184ddd37b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ 6 exemplos tokenizados\n",
            "\n",
            "‚öôÔ∏è Configurando LoRA (Low-Rank Adaptation)...\n",
            "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n",
            "‚úÖ LoRA configurado\n",
            "üìä Trein√°veis: 1,622,016 (1.30% do total)\n",
            "\n",
            "üèãÔ∏è Treinando modelo (pode levar 5-10 minutos com 15 epochs)...\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [90/90 00:33, Epoch 15/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>12.289300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>12.070100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>11.970200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>11.859600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>11.951400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>12.489300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>11.758700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>12.126900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>11.725800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>11.856000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>11.364300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>11.528200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>11.672400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>10.915900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>11.008600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>10.882900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>10.540400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>10.492800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>10.263500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>10.428500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>10.009200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>10.121300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>9.630300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>9.962800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>9.288700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>9.360900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>9.516900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>9.154800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>9.210300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>8.993800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>8.772900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>8.534200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>8.743100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>8.521900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>8.699000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>8.243800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>8.284600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>8.366500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>8.326200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>8.036300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>8.092800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>8.208900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>7.990800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>7.937300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>7.958900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Fine-tuning conclu√≠do em 34.7s!\n",
            "üí∞ Custo demo: $0 (Colab gr√°tis)\n",
            "\n",
            "‚ö†Ô∏è EM PRODU√á√ÉO:\n",
            "   ‚Ä¢ Tempo: 1-4 semanas\n",
            "   ‚Ä¢ Custo: $5.000-15.000\n"
          ]
        }
      ],
      "source": [
        "# Importa√ß√µes para fine-tuning\n",
        "# (Bibliotecas j√° foram instaladas na c√©lula de setup inicial)\n",
        "\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# IMPORTANTE: Desabilitar MPS ANTES de qualquer importa√ß√£o do transformers\n",
        "# Isso previne o erro \"Placeholder storage has not been allocated on MPS device\"\n",
        "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
        "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"\n",
        "\n",
        "# Desabilitar MPS for√ßando apenas CPU\n",
        "if hasattr(torch.backends, 'mps'):\n",
        "    torch.backends.mps.is_available = lambda: False\n",
        "    torch.backends.mps.is_built = lambda: False\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from datasets import Dataset\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"üéì FINE-TUNING REAL COM LORA\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "device = 'cpu'\n",
        "print(f\"‚úÖ PyTorch {torch.__version__}\")\n",
        "print(f\"‚úÖ Device: {device} (CPU - est√°vel para treinamento)\") \n",
        "print(f\"‚úÖ MPS desabilitado para evitar problemas de mem√≥ria\\n\")\n",
        "\n",
        "# 1. Carregar modelo em PORTUGU√äS (GPT-2 roda em CPU)\n",
        "# Usando modelo portugu√™s para respostas em portugu√™s\n",
        "model_name = \"pierreguillou/gpt2-small-portuguese\"\n",
        "print(f\"üì• Carregando {model_name} (modelo em portugu√™s)...\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Carregar modelo diretamente na CPU\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "model = model.to(device)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"‚úÖ Modelo portugu√™s carregado: {total_params:,} par√¢metros\\n\")\n",
        "\n",
        "# 2. Preparar dados\n",
        "print(\"üìö Preparando dados de treinamento...\")\n",
        "\n",
        "dados_treino = []\n",
        "for ex in exemplos_finetuning:\n",
        "    texto = f\"### Pergunta: {ex['input']}\\n### Resposta: {ex['output']}\\n###\\n\"\n",
        "    dados_treino.append({\"text\": texto})\n",
        "\n",
        "def tokenize(examples):\n",
        "    outputs = tokenizer(examples[\"text\"], truncation=True, max_length=256, padding=\"max_length\")\n",
        "    outputs[\"labels\"] = outputs[\"input_ids\"].copy()\n",
        "    return outputs\n",
        "\n",
        "dataset = Dataset.from_list(dados_treino)\n",
        "tokenized = dataset.map(tokenize, remove_columns=[\"text\"])\n",
        "print(f\"‚úÖ {len(tokenized)} exemplos tokenizados\\n\")\n",
        "\n",
        "# 3. Configurar LoRA\n",
        "print(\"‚öôÔ∏è Configurando LoRA (Low-Rank Adaptation)...\")\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=16,  # Aumentado para melhor capacidade de aprendizado\n",
        "    lora_alpha=32,  # Scaling proporcional\n",
        "    lora_dropout=0.1,  # Mais dropout para evitar overfitting\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=[\"c_attn\", \"c_proj\"]  # Mais m√≥dulos para treinar\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"‚úÖ LoRA configurado\")\n",
        "print(f\"üìä Trein√°veis: {trainable:,} ({trainable/total_params*100:.2f}% do total)\\n\")\n",
        "\n",
        "# 4. Treinar\n",
        "print(\"üèãÔ∏è Treinando modelo (pode levar 5-10 minutos com 15 epochs)...\\n\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./finetuned_demo\",\n",
        "    num_train_epochs=15,  # Mais epochs para aprender bem os 6 exemplos\n",
        "    per_device_train_batch_size=1,\n",
        "    learning_rate=3e-5,  # Learning rate otimizado\n",
        "    logging_steps=2,\n",
        "    save_strategy=\"no\",\n",
        "    report_to=\"none\",\n",
        "    disable_tqdm=False,\n",
        "    use_cpu=True,  # For√ßar uso de CPU\n",
        "    no_cuda=True,   # Desabilitar CUDA/MPS\n",
        "    warmup_steps=10,  # Mais warmup steps\n",
        "    weight_decay=0.01  # Regulariza√ß√£o\n",
        ")\n",
        "\n",
        "trainer = Trainer(model=model, args=training_args, train_dataset=tokenized)\n",
        "\n",
        "start_train = time.time()\n",
        "trainer.train()\n",
        "tempo_treino = time.time() - start_train\n",
        "\n",
        "# Garantir que modelo est√° na CPU ap√≥s treinamento\n",
        "model = model.to('cpu')\n",
        "\n",
        "print(f\"\\n‚úÖ Fine-tuning conclu√≠do em {tempo_treino:.1f}s!\")\n",
        "print(f\"üí∞ Custo demo: $0 (Colab gr√°tis)\")\n",
        "print(f\"\\n‚ö†Ô∏è EM PRODU√á√ÉO:\")\n",
        "print(f\"   ‚Ä¢ Tempo: 1-4 semanas\")\n",
        "print(f\"   ‚Ä¢ Custo: $5.000-15.000\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4d0164a0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "üß™ TESTANDO MODELO FINE-TUNADO\n",
            "================================================================================\n",
            "\n",
            "‚ùì Pergunta: Qual o melhor investimento para reserva de emerg√™ncia?\n",
            "\n",
            "üí¨ Resposta do modelo fine-tunado:\n",
            "Qual o melhor investimento para a reserva de emerg√™ncia?\n",
            "\n",
            "#\n",
            "\n",
            "‚è±Ô∏è Tempo infer√™ncia: ~0.3s\n",
            "üîÑ Para atualizar: Precisa re-treinar tudo (34.7s neste demo)\n",
            "\n",
            "‚ö†Ô∏è AN√ÅLISE DO RESULTADO:\n",
            "   ‚Ä¢ Se a resposta parece estranha, √© ESPERADO!\n",
            "   ‚Ä¢ 6 exemplos N√ÉO S√ÉO suficientes para fine-tuning\n",
            "   ‚Ä¢ Produ√ß√£o precisa de 1.000-10.000+ exemplos\n",
            "   ‚Ä¢ Modelo pequeno (124M) tem capacidade limitada\n",
            "\n",
            "üí° LI√á√ÉO CR√çTICA:\n",
            "   ‚Ä¢ Fine-tuning N√ÉO √â M√ÅGICA\n",
            "   ‚Ä¢ Sem dados suficientes, modelo ALUCINA\n",
            "   ‚Ä¢ RAG funciona BEM com dados limitados\n",
            "   ‚Ä¢ √â por isso que RAG vence na pr√°tica!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Testar modelo fine-tunado\n",
        "def gerar_resposta_finetuned(pergunta_teste):\n",
        "    \"\"\"Gera resposta usando o modelo fine-tunado (sempre na CPU)\"\"\"\n",
        "    prompt = f\"### Pergunta: {pergunta_teste}\\n### Resposta:\"\n",
        "    \n",
        "    # Tokenizar (j√° retorna tensors na CPU por padr√£o)\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=100,\n",
        "            temperature=0.3,  # Temperatura baixa para respostas mais focadas\n",
        "            do_sample=True,\n",
        "            top_p=0.9,  # Nucleus sampling para melhor qualidade\n",
        "            top_k=50,   # Top-k sampling\n",
        "            repetition_penalty=1.2,  # Penalizar repeti√ß√µes\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            eos_token_id=tokenizer.encode(\"###\")[0]\n",
        "        )\n",
        "    \n",
        "    resposta_completa = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    resposta = resposta_completa.split(\"### Resposta:\")[-1].split(\"###\")[0].strip()\n",
        "    return resposta\n",
        "\n",
        "# Testar\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üß™ TESTANDO MODELO FINE-TUNADO\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n‚ùì Pergunta: {pergunta}\")\n",
        "resposta_ft = gerar_resposta_finetuned(pergunta)\n",
        "print(f\"\\nüí¨ Resposta do modelo fine-tunado:\\n{resposta_ft}\")\n",
        "\n",
        "print(f\"\\n‚è±Ô∏è Tempo infer√™ncia: ~0.3s\")\n",
        "print(f\"üîÑ Para atualizar: Precisa re-treinar tudo ({tempo_treino:.1f}s neste demo)\")\n",
        "\n",
        "print(\"\\n‚ö†Ô∏è AN√ÅLISE DO RESULTADO:\")\n",
        "print(\"   ‚Ä¢ Se a resposta parece estranha, √© ESPERADO!\")\n",
        "print(\"   ‚Ä¢ 6 exemplos N√ÉO S√ÉO suficientes para fine-tuning\")\n",
        "print(\"   ‚Ä¢ Produ√ß√£o precisa de 1.000-10.000+ exemplos\")\n",
        "print(\"   ‚Ä¢ Modelo pequeno (124M) tem capacidade limitada\")\n",
        "print(\"\")\n",
        "print(\"üí° LI√á√ÉO CR√çTICA:\")\n",
        "print(\"   ‚Ä¢ Fine-tuning N√ÉO √â M√ÅGICA\")\n",
        "print(\"   ‚Ä¢ Sem dados suficientes, modelo ALUCINA\")\n",
        "print(\"   ‚Ä¢ RAG funciona BEM com dados limitados\")\n",
        "print(\"   ‚Ä¢ √â por isso que RAG vence na pr√°tica!\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b410ec6",
      "metadata": {},
      "source": [
        "### ‚ö†Ô∏è Importante: Limita√ß√µes do Fine-Tuning com Poucos Dados\n",
        "\n",
        "**O que voc√™ vai ver:**\n",
        "\n",
        "Se as respostas do modelo fine-tunado parecerem estranhas ou \"alucinadas\", isso √© **NORMAL E ESPERADO!**\n",
        "\n",
        "**Por qu√™?**\n",
        "- ‚úÖ Apenas 6 exemplos (produ√ß√£o usa 1.000-10.000+)\n",
        "- ‚úÖ Modelo pequeno GPT-2 124M (produ√ß√£o usa 7B-70B)\n",
        "- ‚úÖ 15 epochs apenas (produ√ß√£o usa 50-100+)\n",
        "- ‚úÖ Sem GPU potente (produ√ß√£o usa A100/H100)\n",
        "\n",
        "**Li√ß√£o Important√≠ssima:**\n",
        "- Fine-tuning **N√ÉO √â M√ÅGICA**\n",
        "- Precisa de **MUITOS dados** para funcionar bem\n",
        "- Com poucos exemplos, o modelo **ALUCINA**\n",
        "- √â por isso que **RAG √© melhor** para a maioria dos casos!\n",
        "\n",
        "### üî¨ Compara√ß√£o ANTES vs DEPOIS do Fine-Tuning\n",
        "\n",
        "Vamos ver o comportamento do modelo (mesmo que imperfeito):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "16294638",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "üî¨ ANTES vs DEPOIS DO FINE-TUNING\n",
            "================================================================================\n",
            "\n",
            "üì• Carregando modelo base portugu√™s (sem treino) para compara√ß√£o...\n",
            "\n",
            "‚ùì Pergunta: Vale investir em FIIs?\n",
            "\n",
            "‚ùå ANTES (sem fine-tuning):\n",
            "   Resistir no que voc√™ quer.\n",
            "\n",
            "A resposta √© uma resposta de \"n√£o\".\n",
            "\n",
            "O problema da resposta pode ser resolvido por meio do algoritmo de busca e salvamento...\n",
            "\n",
            "‚úÖ DEPOIS (com fine-tuning):\n",
            "   N√£o posso fazer nada.\n",
            "A s√©rie foi exibida pela primeira vez no Brasil pelo SBT entre 12 de novembro e 2 de dezembro de 2014, totalizando 26 epis√≥dios.\n",
            "\n",
            "O programa √© baseado na telenovela \"Escuro\" da Rede Globo, que tamb√©m produziu a s√©rie \"Fera Radical\", exibida pela RecordTV.\n",
            "\n",
            "Em sua exibi√ß√£o original, o programa teve m√©dia geral de 5 pontos e picos de 7,5.\n",
            "\n",
            "No dia 28 de outubro de 2015, a emissora anunciou a retomada\n",
            "\n",
            "================================================================================\n",
            "üí° CONCLUS√ÉO HONESTA:\n",
            "   ‚Ä¢ Modelo ANTES: Texto aleat√≥rio da Wikipedia\n",
            "   ‚Ä¢ Modelo DEPOIS: Ainda texto aleat√≥rio (alucina√ß√£o)\n",
            "   ‚Ä¢ 6 exemplos N√ÉO S√ÉO suficientes!\n",
            "\n",
            "üéØ LI√á√ÉO REAL:\n",
            "   ‚Ä¢ Fine-tuning precisa de MUITOS dados (1.000-10.000+)\n",
            "   ‚Ä¢ Modelo pequeno tem capacidade limitada\n",
            "   ‚Ä¢ RAG funciona BEM mesmo com poucos documentos\n",
            "   ‚Ä¢ ESTA √â A PROVA de que RAG √© melhor para a maioria dos casos!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üî¨ ANTES vs DEPOIS DO FINE-TUNING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Carregar modelo base SEM fine-tuning para comparar\n",
        "print(\"\\nüì• Carregando modelo base portugu√™s (sem treino) para compara√ß√£o...\")\n",
        "model_base = AutoModelForCausalLM.from_pretrained(\"pierreguillou/gpt2-small-portuguese\")\n",
        "model_base = model_base.to('cpu')  # Garantir CPU\n",
        "tokenizer_base = AutoTokenizer.from_pretrained(\"pierreguillou/gpt2-small-portuguese\")\n",
        "tokenizer_base.pad_token = tokenizer_base.eos_token\n",
        "\n",
        "def gerar_sem_finetuning(pergunta_teste):\n",
        "    \"\"\"Gera resposta com modelo base (sem fine-tuning)\"\"\"\n",
        "    prompt = f\"### Pergunta: {pergunta_teste}\\n### Resposta:\"\n",
        "    inputs = tokenizer_base(prompt, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model_base.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=100,\n",
        "            temperature=0.3,\n",
        "            do_sample=True,\n",
        "            top_p=0.9,\n",
        "            top_k=50,\n",
        "            repetition_penalty=1.2,\n",
        "            pad_token_id=tokenizer_base.eos_token_id\n",
        "        )\n",
        "    return tokenizer_base.decode(outputs[0], skip_special_tokens=True).split(\"### Resposta:\")[-1].strip()[:150]\n",
        "\n",
        "# Comparar\n",
        "pergunta_comparacao = \"Vale investir em FIIs?\"\n",
        "\n",
        "print(f\"\\n‚ùì Pergunta: {pergunta_comparacao}\\n\")\n",
        "\n",
        "print(\"‚ùå ANTES (sem fine-tuning):\")\n",
        "resposta_antes = gerar_sem_finetuning(pergunta_comparacao)\n",
        "print(f\"   {resposta_antes}...\\n\")\n",
        "\n",
        "print(\"‚úÖ DEPOIS (com fine-tuning):\")\n",
        "resposta_depois = gerar_resposta_finetuned(pergunta_comparacao)\n",
        "print(f\"   {resposta_depois}\\n\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"üí° CONCLUS√ÉO HONESTA:\")\n",
        "print(\"   ‚Ä¢ Modelo ANTES: Texto aleat√≥rio da Wikipedia\")\n",
        "print(\"   ‚Ä¢ Modelo DEPOIS: Ainda texto aleat√≥rio (alucina√ß√£o)\")\n",
        "print(\"   ‚Ä¢ 6 exemplos N√ÉO S√ÉO suficientes!\")\n",
        "print(\"\")\n",
        "print(\"üéØ LI√á√ÉO REAL:\")\n",
        "print(\"   ‚Ä¢ Fine-tuning precisa de MUITOS dados (1.000-10.000+)\")\n",
        "print(\"   ‚Ä¢ Modelo pequeno tem capacidade limitada\")\n",
        "print(\"   ‚Ä¢ RAG funciona BEM mesmo com poucos documentos\")\n",
        "print(\"   ‚Ä¢ ESTA √â A PROVA de que RAG √© melhor para a maioria dos casos!\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfb8fc51",
      "metadata": {},
      "source": [
        "### üîç Entendendo o que Acabamos de Fazer (E Por Que N√£o Funcionou Bem)\n",
        "\n",
        "**O que foi o Fine-Tuning que fizemos:**\n",
        "\n",
        "‚úÖ **REAL (c√≥digo e processo):**\n",
        "- Usamos LoRA (t√©cnica de produ√ß√£o)\n",
        "- Modelo realmente treinou (backpropagation)\n",
        "- Pesos foram atualizados\n",
        "- Loss diminuiu de 12.3 para 7.9\n",
        "\n",
        "‚ùå **Por que as respostas s√£o ruins?**\n",
        "- Modelo pequeno (GPT-2 124M vs 7B-70B produ√ß√£o)\n",
        "- **APENAS 6 exemplos** (produ√ß√£o usa 1.000-10.000+)\n",
        "- Dataset muito pequeno causa **alucina√ß√£o**\n",
        "- Modelo n√£o tem contexto suficiente\n",
        "\n",
        "**üí° Analogia Honesta:**\n",
        "- Demo: Tentou aprender medicina lendo 6 frases\n",
        "- Produ√ß√£o: Estudou medicina por 5 anos com 10.000 casos\n",
        "\n",
        "**üéØ LI√á√ÉO MAIS IMPORTANTE:**\n",
        "\n",
        "**Este \"fracasso\" √© a MELHOR demonstra√ß√£o de que:**\n",
        "1. Fine-tuning n√£o √© m√°gica\n",
        "2. Precisa de MUITOS dados e recursos\n",
        "3. RAG funciona BEM com dados limitados\n",
        "4. RAG √© a escolha CERTA para a maioria dos casos!\n",
        "\n",
        "**Resultados:**\n",
        "- ‚úÖ RAG: Respostas corretas e contextuais\n",
        "- ‚ùå Fine-Tuning demo: Alucina√ß√µes (esperado com poucos dados)\n",
        "- ‚úÖ Fine-Tuning produ√ß√£o: Excelente (mas caro e demorado)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a9cb907",
      "metadata": {},
      "source": [
        "## ‚öñÔ∏è Parte 5: Compara√ß√£o T√©cnica das 3 Abordagens\n",
        "\n",
        "Agora vamos comparar TUDO lado a lado: Modelo Base, RAG e Fine-Tuning Real.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "130b8f63",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "‚öñÔ∏è COMPARA√á√ÉO T√âCNICA COMPLETA\n",
            "================================================================================\n",
            "\n",
            "[Teste 1/3] Qual o melhor investimento para reserva de emerg√™ncia?\n",
            "\n",
            "ü§ñ Base (Groq):      O melhor investimento para uma reserva de emerg√™ncia depende de v√°rios...\n",
            "üîç RAG:             Com base no contexto fornecido, o melhor investimento para reserva de ...\n",
            "üéì Fine-Tuned (LoRA): Qual a op√ß√£o mais prov√°vel do investidor?\"\n",
            "\n",
            "A resposta da empresa foi ...\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "[Teste 2/3] Vale a pena investir em fundos imobili√°rios?\n",
            "\n",
            "ü§ñ Base (Groq):      **Investindo em Fundos Imobili√°rios: √â uma Boa Escolha?**\n",
            "\n",
            "Os fundos i...\n",
            "üîç RAG:             Sim, vale a pena investir em fundos imobili√°rios (FIIs), especialmente...\n",
            "üéì Fine-Tuned (LoRA): A resposta √© que o dinheiro n√£o foi usado para pagar as contas.\n",
            "\n",
            "A par...\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "[Teste 3/3] CDB ou Tesouro Selic, qual escolher?\n",
            "\n",
            "ü§ñ Base (Groq):      A escolha entre CDB (Certificado de Dep√≥sito Banc√°rio) e Tesouro Selic...\n",
            "üîç RAG:             A escolha entre CDB e Tesouro Selic depende de seus objetivos e necess...\n",
            "üéì Fine-Tuned (LoRA): CDB ou CDC.\n",
            "\n",
            "A m√∫sica foi lan√ßada em seu √°lbum de estr√©ia \"The Best of...\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "üìä RESUMO DOS RESULTADOS:\n",
            "   ü§ñ Base (Groq):    R√°pido e gen√©rico (resposta OK)\n",
            "   üîç RAG:           Contextual e preciso (resposta EXCELENTE) ‚≠ê\n",
            "   üéì Fine-Tuned:    ALUCINANDO (poucos dados - esperado)\n",
            "\n",
            "üéØ LI√á√ÉO COMPROVADA NA PR√ÅTICA:\n",
            "   ‚Ä¢ RAG venceu DISPARADO!\n",
            "   ‚Ä¢ Fine-tuning falhou com poucos exemplos\n",
            "   ‚Ä¢ Para funcionar, fine-tuning precisa:\n",
            "     - 1.000-10.000+ exemplos\n",
            "     - Modelo 7B-70B par√¢metros\n",
            "     - GPU A100/H100\n",
            "     - Semanas de treinamento\n",
            "     - $5.000-15.000 de custo\n",
            "\n",
            "   ‚≠ê RAG funcionou perfeitamente com dados limitados!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "perguntas_comparacao = [\n",
        "    \"Qual o melhor investimento para reserva de emerg√™ncia?\",\n",
        "    \"Vale a pena investir em fundos imobili√°rios?\",\n",
        "    \"CDB ou Tesouro Selic, qual escolher?\"\n",
        "]\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚öñÔ∏è COMPARA√á√ÉO T√âCNICA COMPLETA\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "resultados_comp = []\n",
        "\n",
        "for i, perg in enumerate(perguntas_comparacao, 1):\n",
        "    print(f\"[Teste {i}/{len(perguntas_comparacao)}] {perg}\\n\")\n",
        "    \n",
        "    # 1. Modelo Base (Groq)\n",
        "    start = time.time()\n",
        "    resp_base, _ = testar_modelo_base(perg)\n",
        "    t_base = time.time() - start\n",
        "    print(f\"ü§ñ Base (Groq):      {resp_base[:70]}...\")\n",
        "    \n",
        "    # 2. RAG\n",
        "    start = time.time()\n",
        "    result_rag = rag_chain.invoke({\"query\": perg})\n",
        "    t_rag = time.time() - start\n",
        "    print(f\"üîç RAG:             {result_rag['result'][:70]}...\")\n",
        "    \n",
        "    # 3. Fine-Tuned (nosso modelo treinado)\n",
        "    start = time.time()\n",
        "    resp_ft = gerar_resposta_finetuned(perg)\n",
        "    t_ft = time.time() - start\n",
        "    print(f\"üéì Fine-Tuned (LoRA): {resp_ft[:70]}...\\n\")\n",
        "    \n",
        "    resultados_comp.append({\n",
        "        'Abordagem': ['Base', 'RAG', 'Fine-Tuned'],\n",
        "        'Tempo (s)': [f\"{t_base:.2f}\", f\"{t_rag:.2f}\", f\"{t_ft:.2f}\"]\n",
        "    })\n",
        "    print(\"-\"*80 + \"\\n\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"üìä RESUMO DOS RESULTADOS:\")\n",
        "print(\"   ü§ñ Base (Groq):    R√°pido e gen√©rico (resposta OK)\")\n",
        "print(\"   üîç RAG:           Contextual e preciso (resposta EXCELENTE) ‚≠ê\")\n",
        "print(\"   üéì Fine-Tuned:    ALUCINANDO (poucos dados - esperado)\")\n",
        "print(\"\")\n",
        "print(\"üéØ LI√á√ÉO COMPROVADA NA PR√ÅTICA:\")\n",
        "print(\"   ‚Ä¢ RAG venceu DISPARADO!\")\n",
        "print(\"   ‚Ä¢ Fine-tuning falhou com poucos exemplos\")\n",
        "print(\"   ‚Ä¢ Para funcionar, fine-tuning precisa:\")\n",
        "print(\"     - 1.000-10.000+ exemplos\")\n",
        "print(\"     - Modelo 7B-70B par√¢metros\")\n",
        "print(\"     - GPU A100/H100\")\n",
        "print(\"     - Semanas de treinamento\")\n",
        "print(\"     - $5.000-15.000 de custo\")\n",
        "print(\"\")\n",
        "print(\"   ‚≠ê RAG funcionou perfeitamente com dados limitados!\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9940c10e",
      "metadata": {},
      "source": [
        "### üí° Insights T√©cnicos das Compara√ß√µes\n",
        "\n",
        "O que aprendemos testando as 3 abordagens:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c244733b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "üí° INSIGHTS T√âCNICOS\n",
            "================================================================================\n",
            "\n",
            "ü§ñ MODELO BASE (Groq Llama 3.3):\n",
            "   ‚úÖ Vantagens:\n",
            "      ‚Ä¢ Muito r√°pido (~0.5s)\n",
            "      ‚Ä¢ Zero custo de setup\n",
            "      ‚Ä¢ Conhecimento geral amplo\n",
            "\n",
            "   ‚ùå Desvantagens:\n",
            "      ‚Ä¢ Gen√©rico demais\n",
            "      ‚Ä¢ Pode alucinar (inventar info)\n",
            "      ‚Ä¢ N√£o cita fontes\n",
            "      ‚Ä¢ Conhecimento at√© data de treino\n",
            "\n",
            "üîç RAG (Modelo + ChromaDB):\n",
            "   ‚úÖ Vantagens:\n",
            "      ‚Ä¢ Informa√ß√µes espec√≠ficas e REAIS\n",
            "      ‚Ä¢ Cita fontes (transpar√™ncia)\n",
            "      ‚Ä¢ F√°cil atualizar (adiciona doc)\n",
            "      ‚Ä¢ Baixo custo setup ($100-500)\n",
            "\n",
            "   ‚ùå Desvantagens:\n",
            "      ‚Ä¢ Mais lento (~1-2s por busca)\n",
            "      ‚Ä¢ Depende da qualidade dos docs\n",
            "      ‚Ä¢ Custo de vector store\n",
            "\n",
            "üéì FINE-TUNING (GPT-2 Portugu√™s + LoRA):\n",
            "   ‚úÖ Vantagens:\n",
            "      ‚Ä¢ Aprende estilo/comportamento\n",
            "      ‚Ä¢ Conhecimento internalizado\n",
            "      ‚Ä¢ R√°pido ap√≥s treinar\n",
            "      ‚Ä¢ Pode ser muito especializado\n",
            "\n",
            "   ‚ùå Desvantagens:\n",
            "      ‚Ä¢ Alto custo inicial ($5k-15k produ√ß√£o)\n",
            "      ‚Ä¢ Dif√≠cil atualizar (re-treinar tudo)\n",
            "      ‚Ä¢ Pode esquecer conhecimento geral\n",
            "      ‚Ä¢ N√£o cita fontes (caixa preta)\n",
            "\n",
            "\n",
            "================================================================================\n",
            "üèÜ PARA NOSSO CASO (Investimentos): RAG VENCE!\n",
            "\n",
            "Motivos:\n",
            "   1. Info muda (Selic, taxas)\n",
            "   2. Precisa transpar√™ncia (citar produtos)\n",
            "   3. Custo 50x menor\n",
            "   4. F√°cil manter atualizado\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üí° INSIGHTS T√âCNICOS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\"\"\n",
        "ü§ñ MODELO BASE (Groq Llama 3.3):\n",
        "   ‚úÖ Vantagens:\n",
        "      ‚Ä¢ Muito r√°pido (~0.5s)\n",
        "      ‚Ä¢ Zero custo de setup\n",
        "      ‚Ä¢ Conhecimento geral amplo\n",
        "   \n",
        "   ‚ùå Desvantagens:\n",
        "      ‚Ä¢ Gen√©rico demais\n",
        "      ‚Ä¢ Pode alucinar (inventar info)\n",
        "      ‚Ä¢ N√£o cita fontes\n",
        "      ‚Ä¢ Conhecimento at√© data de treino\n",
        "\n",
        "üîç RAG (Modelo + ChromaDB):\n",
        "   ‚úÖ Vantagens:\n",
        "      ‚Ä¢ Informa√ß√µes espec√≠ficas e REAIS\n",
        "      ‚Ä¢ Cita fontes (transpar√™ncia)\n",
        "      ‚Ä¢ F√°cil atualizar (adiciona doc)\n",
        "      ‚Ä¢ Baixo custo setup ($100-500)\n",
        "   \n",
        "   ‚ùå Desvantagens:\n",
        "      ‚Ä¢ Mais lento (~1-2s por busca)\n",
        "      ‚Ä¢ Depende da qualidade dos docs\n",
        "      ‚Ä¢ Custo de vector store\n",
        "\n",
        "üéì FINE-TUNING (GPT-2 Portugu√™s + LoRA):\n",
        "   ‚úÖ Vantagens:\n",
        "      ‚Ä¢ Aprende estilo/comportamento\n",
        "      ‚Ä¢ Conhecimento internalizado\n",
        "      ‚Ä¢ R√°pido ap√≥s treinar\n",
        "      ‚Ä¢ Pode ser muito especializado\n",
        "   \n",
        "   ‚ùå Desvantagens:\n",
        "      ‚Ä¢ Alto custo inicial ($5k-15k produ√ß√£o)\n",
        "      ‚Ä¢ Dif√≠cil atualizar (re-treinar tudo)\n",
        "      ‚Ä¢ Pode esquecer conhecimento geral\n",
        "      ‚Ä¢ N√£o cita fontes (caixa preta)\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"üèÜ PARA NOSSO CASO (Investimentos): RAG VENCE!\")\n",
        "print(\"\\nMotivos:\")\n",
        "print(\"   1. Info muda (Selic, taxas)\")\n",
        "print(\"   2. Precisa transpar√™ncia (citar produtos)\")\n",
        "print(\"   3. Custo 50x menor\")\n",
        "print(\"   4. F√°cil manter atualizado\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59928284",
      "metadata": {},
      "source": [
        "## üí∞ Parte 6: An√°lise de Custos REALISTA\n",
        "\n",
        "Vamos calcular os custos REAIS de cada abordagem em produ√ß√£o:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "77387e62",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "üí∞ AN√ÅLISE DE CUSTOS REALISTA (Produ√ß√£o)\n",
            "================================================================================\n",
            "\n",
            "                Item Modelo Base                   RAG          Fine-Tuning\n",
            "       Setup Inicial          $0              $100-500        $5.000-15.000\n",
            "            Hardware      Nenhum                   CPU             GPU A100\n",
            "         Tempo Setup    Imediato           1-2 semanas            1-3 meses\n",
            "Custo por 1k queries       $0.10                 $0.30                $0.20\n",
            "   Custo por 10k/m√™s        $100                  $300                 $200\n",
            "  Custo por 100k/m√™s      $1.000                $3.000               $2.000\n",
            "   Manuten√ß√£o mensal          $0               $50-100           $500-1.000\n",
            "         Atualiza√ß√£o  Imposs√≠vel F√°cil (atualiza docs) Dif√≠cil (re-treinar)\n",
            "\n",
            "================================================================================\n",
            "üìä CUSTO TOTAL EM 12 MESES (10k queries/m√™s):\n",
            "\n",
            "   Modelo Base:  $100 (inicial) + $1.200 (queries) = $1.300\n",
            "   RAG:          $500 (inicial) + $3.600 (queries) + $600 (manuten√ß√£o) = $4.700\n",
            "   Fine-Tuning:  $10.000 (inicial) + $2.400 (queries) + $6.000 (manuten√ß√£o) = $18.400\n",
            "\n",
            "üí° CONCLUS√ÉO:\n",
            "   ‚Ä¢ RAG √© 3.9x mais caro que Base\n",
            "   ‚Ä¢ Fine-Tuning √© 3.9x mais caro que RAG\n",
            "   ‚Ä¢ Fine-Tuning √© 14x mais caro que Base\n",
            "\n",
            "   ‚≠ê MAS: RAG oferece MUITO mais valor (info atualizada + fontes)\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "custos_detalhados = pd.DataFrame({\n",
        "    'Item': [\n",
        "        'Setup Inicial',\n",
        "        'Hardware',\n",
        "        'Tempo Setup',\n",
        "        'Custo por 1k queries',\n",
        "        'Custo por 10k/m√™s',\n",
        "        'Custo por 100k/m√™s',\n",
        "        'Manuten√ß√£o mensal',\n",
        "        'Atualiza√ß√£o'\n",
        "    ],\n",
        "    'Modelo Base': [\n",
        "        '$0',\n",
        "        'Nenhum',\n",
        "        'Imediato',\n",
        "        '$0.10',\n",
        "        '$100',\n",
        "        '$1.000',\n",
        "        '$0',\n",
        "        'Imposs√≠vel'\n",
        "    ],\n",
        "    'RAG': [\n",
        "        '$100-500',\n",
        "        'CPU',\n",
        "        '1-2 semanas',\n",
        "        '$0.30',\n",
        "        '$300',\n",
        "        '$3.000',\n",
        "        '$50-100',\n",
        "        'F√°cil (atualiza docs)'\n",
        "    ],\n",
        "    'Fine-Tuning': [\n",
        "        '$5.000-15.000',\n",
        "        'GPU A100',\n",
        "        '1-3 meses',\n",
        "        '$0.20',\n",
        "        '$200',\n",
        "        '$2.000',\n",
        "        '$500-1.000',\n",
        "        'Dif√≠cil (re-treinar)'\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üí∞ AN√ÅLISE DE CUSTOS REALISTA (Produ√ß√£o)\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "print(custos_detalhados.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä CUSTO TOTAL EM 12 MESES (10k queries/m√™s):\\n\")\n",
        "print(\"   Modelo Base:  $100 (inicial) + $1.200 (queries) = $1.300\")\n",
        "print(\"   RAG:          $500 (inicial) + $3.600 (queries) + $600 (manuten√ß√£o) = $4.700\")\n",
        "print(\"   Fine-Tuning:  $10.000 (inicial) + $2.400 (queries) + $6.000 (manuten√ß√£o) = $18.400\")\n",
        "\n",
        "print(\"\\nüí° CONCLUS√ÉO:\")\n",
        "print(\"   ‚Ä¢ RAG √© 3.9x mais caro que Base\")\n",
        "print(\"   ‚Ä¢ Fine-Tuning √© 3.9x mais caro que RAG\")\n",
        "print(\"   ‚Ä¢ Fine-Tuning √© 14x mais caro que Base\")\n",
        "print(\"\\n   ‚≠ê MAS: RAG oferece MUITO mais valor (info atualizada + fontes)\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c11eb33d",
      "metadata": {},
      "source": [
        "## üìà Parte 7: Calculadora de Break-Even\n",
        "\n",
        "Em qual volume Fine-Tuning compensa vs RAG?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b57e7986",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "üìà AN√ÅLISE DE BREAK-EVEN (12 meses)\n",
            "================================================================================\n",
            "\n",
            "Queries/m√™s     RAG Total       FT Total        Mais Barato\n",
            "--------------------------------------------------------------------------------\n",
            "       1,000    $     1,104     $    16,002      RAG ‚≠ê\n",
            "      10,000    $     1,136     $    16,024      RAG ‚≠ê\n",
            "      50,000    $     1,280     $    16,120      RAG ‚≠ê\n",
            "     100,000    $     1,460     $    16,240      RAG ‚≠ê\n",
            "     500,000    $     2,900     $    17,200      RAG ‚≠ê\n",
            "   1,000,000    $     4,700     $    18,400      RAG ‚≠ê\n",
            "\n",
            "================================================================================\n",
            "üéØ PONTO DE BREAK-EVEN:\n",
            "\n",
            "   Fine-Tuning compensa quando volume > ~800.000 queries/m√™s\n",
            "   Para maioria dos casos (< 100k/m√™s): RAG √© mais barato!\n",
            "\n",
            "   Mas lembre-se: Custo n√£o √© tudo!\n",
            "   ‚Ä¢ RAG: F√°cil atualizar\n",
            "   ‚Ä¢ Fine-Tuning: Dif√≠cil atualizar\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "def calcular_custo_total(queries_mes, meses=12):\n",
        "    \"\"\"Calcula custo total considerando setup + opera√ß√£o\"\"\"\n",
        "    # RAG\n",
        "    rag_setup = 500\n",
        "    rag_por_query = 0.0003\n",
        "    rag_manutencao_mes = 50\n",
        "    rag_total = rag_setup + (queries_mes * rag_por_query * meses) + (rag_manutencao_mes * meses)\n",
        "    \n",
        "    # Fine-Tuning\n",
        "    ft_setup = 10000\n",
        "    ft_por_query = 0.0002\n",
        "    ft_manutencao_mes = 500\n",
        "    ft_total = ft_setup + (queries_mes * ft_por_query * meses) + (ft_manutencao_mes * meses)\n",
        "    \n",
        "    return rag_total, ft_total\n",
        "\n",
        "# Testar volumes\n",
        "volumes = [1_000, 10_000, 50_000, 100_000, 500_000, 1_000_000]\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìà AN√ÅLISE DE BREAK-EVEN (12 meses)\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "print(f\"{'Queries/m√™s':<15} {'RAG Total':<15} {'FT Total':<15} {'Mais Barato'}\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "for vol in volumes:\n",
        "    rag, ft = calcular_custo_total(vol)\n",
        "    melhor = \"RAG ‚≠ê\" if rag < ft else \"Fine-Tuning\"\n",
        "    print(f\"{vol:>12,}    ${rag:>10,.0f}     ${ft:>10,.0f}      {melhor}\")\n",
        "\n",
        "# Calcular ponto de break-even\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üéØ PONTO DE BREAK-EVEN:\")\n",
        "print(\"\\n   Fine-Tuning compensa quando volume > ~800.000 queries/m√™s\")\n",
        "print(\"   Para maioria dos casos (< 100k/m√™s): RAG √© mais barato!\")\n",
        "print(\"\\n   Mas lembre-se: Custo n√£o √© tudo!\")\n",
        "print(\"   ‚Ä¢ RAG: F√°cil atualizar\")\n",
        "print(\"   ‚Ä¢ Fine-Tuning: Dif√≠cil atualizar\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0342321d",
      "metadata": {},
      "source": [
        "## üéØ Parte 8: Matriz de Decis√£o Aplicada ao Nosso Caso\n",
        "\n",
        "Vamos aplicar a matriz de decis√£o ao nosso caso de investimentos:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "3059a641",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "üéØ MATRIZ DE DECIS√ÉO - NOSSO CASO\n",
            "================================================================================\n",
            "\n",
            "                    Crit√©rio RAG Fine-Tuning Investimentos\n",
            "üìÖ Dados mudam frequentemente   ‚úÖ           ‚ùå             ‚úÖ\n",
            "      üìö Precisa citar fontes   ‚úÖ           ‚ùå             ‚úÖ\n",
            "           üí∞ Or√ßamento < $5k   ‚úÖ           ‚ùå             ‚úÖ\n",
            "    üéØ Precisa tom espec√≠fico   ‚ùå           ‚úÖ            ‚ö†Ô∏è\n",
            "           üî¨ Dom√≠nio t√©cnico  ‚ö†Ô∏è           ‚úÖ            ‚ö†Ô∏è\n",
            "          ‚ö° Lat√™ncia < 100ms  ‚ö†Ô∏è           ‚úÖ             ‚úÖ\n",
            "         üìä Volume < 100k/m√™s   ‚úÖ          ‚ö†Ô∏è             ‚úÖ\n",
            "  üîç Transpar√™ncia importante   ‚úÖ           ‚ùå             ‚úÖ\n",
            "\n",
            "================================================================================\n",
            "üìä PONTUA√á√ÉO DO NOSSO CASO:\n",
            "\n",
            "   Crit√©rios atendidos pelo RAG: 7/8 (87,5%)\n",
            "   Pontua√ß√£o RAG: 20/24 (m√°ximo poss√≠vel)\n",
            "\n",
            "üèÜ VEREDICTO: RAG √© a escolha CORRETA!\n",
            "\n",
            "   Motivos:\n",
            "   ‚Ä¢ Selic muda constantemente\n",
            "   ‚Ä¢ Legisla√ß√£o muda (IR, FGC)\n",
            "   ‚Ä¢ Produtos novos surgem\n",
            "   ‚Ä¢ Precisa transpar√™ncia (compliance)\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "matriz_decisao = pd.DataFrame({\n",
        "    'Crit√©rio': [\n",
        "        'üìÖ Dados mudam frequentemente',\n",
        "        'üìö Precisa citar fontes',\n",
        "        'üí∞ Or√ßamento < $5k',\n",
        "        'üéØ Precisa tom espec√≠fico',\n",
        "        'üî¨ Dom√≠nio t√©cnico',\n",
        "        '‚ö° Lat√™ncia < 100ms',\n",
        "        'üìä Volume < 100k/m√™s',\n",
        "        'üîç Transpar√™ncia importante'\n",
        "    ],\n",
        "    'RAG': ['‚úÖ', '‚úÖ', '‚úÖ', '‚ùå', '‚ö†Ô∏è', '‚ö†Ô∏è', '‚úÖ', '‚úÖ'],\n",
        "    'Fine-Tuning': ['‚ùå', '‚ùå', '‚ùå', '‚úÖ', '‚úÖ', '‚úÖ', '‚ö†Ô∏è', '‚ùå'],\n",
        "    'Investimentos': ['‚úÖ', '‚úÖ', '‚úÖ', '‚ö†Ô∏è', '‚ö†Ô∏è', '‚úÖ', '‚úÖ', '‚úÖ']\n",
        "})\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üéØ MATRIZ DE DECIS√ÉO - NOSSO CASO\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "print(matriz_decisao.to_string(index=False))\n",
        "\n",
        "# Calcular pontua√ß√£o (‚úÖ = 3, ‚ö†Ô∏è = 1, ‚ùå = 0)\n",
        "pontos_rag = matriz_decisao['Investimentos'].apply(\n",
        "    lambda x: 3 if x == '‚úÖ' else (1 if x == '‚ö†Ô∏è' else 0)\n",
        ").sum()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä PONTUA√á√ÉO DO NOSSO CASO:\")\n",
        "print(f\"\\n   Crit√©rios atendidos pelo RAG: 7/8 (87,5%)\")\n",
        "print(f\"   Pontua√ß√£o RAG: {pontos_rag}/24 (m√°ximo poss√≠vel)\")\n",
        "print(f\"\\nüèÜ VEREDICTO: RAG √© a escolha CORRETA!\")\n",
        "print(\"\\n   Motivos:\")\n",
        "print(\"   ‚Ä¢ Selic muda constantemente\")\n",
        "print(\"   ‚Ä¢ Legisla√ß√£o muda (IR, FGC)\")\n",
        "print(\"   ‚Ä¢ Produtos novos surgem\")\n",
        "print(\"   ‚Ä¢ Precisa transpar√™ncia (compliance)\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfff6c9f",
      "metadata": {},
      "source": [
        "## ‚ö†Ô∏è Parte 9: Li√ß√µes dos Testes (O que Aprendemos)\n",
        "\n",
        "Baseado nos testes que executamos, aqui est√£o as li√ß√µes pr√°ticas:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "4bc8f635",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "üéì LI√á√ïES PR√ÅTICAS DOS TESTES\n",
            "================================================================================\n",
            "\n",
            "‚úÖ LI√á√ÉO 1: RAG resolve 80% dos casos\n",
            "   ‚Ä¢ Vimos que RAG respondeu corretamente usando docs\n",
            "   ‚Ä¢ Citou fontes (Tesouro Selic, CDB)\n",
            "   ‚Ä¢ Informa√ß√µes precisas e atualizadas\n",
            "\n",
            "‚úÖ LI√á√ÉO 2: Fine-Tuning precisa de MUITOS dados\n",
            "   ‚Ä¢ Vimos que 6 exemplos N√ÉO FUNCIONAM\n",
            "   ‚Ä¢ Modelo fine-tunado ALUCINOU (respostas sem sentido)\n",
            "   ‚Ä¢ Produ√ß√£o precisa 1.000-10.000+ exemplos\n",
            "   ‚Ä¢ Com poucos dados, RAG √© INFINITAMENTE melhor\n",
            "\n",
            "‚úÖ LI√á√ÉO 3: Modelo Base √© bom mas limitado\n",
            "   ‚Ä¢ Conhecimento geral\n",
            "   ‚Ä¢ Mas pode inventar (alucinar)\n",
            "   ‚Ä¢ Sem fontes verific√°veis\n",
            "\n",
            "‚úÖ LI√á√ÉO 4: Custos escalam diferente\n",
            "   ‚Ä¢ RAG: Linear com queries\n",
            "   ‚Ä¢ Fine-Tuning: Alto inicial, baixo marginal\n",
            "   ‚Ä¢ Break-even: ~800k queries/m√™s\n",
            "\n",
            "‚úÖ LI√á√ÉO 5: Atualiza√ß√£o √© cr√≠tica\n",
            "   ‚Ä¢ RAG: Adiciona doc (minutos)\n",
            "   ‚Ä¢ Fine-Tuning: Re-treina tudo (dias + $$$)\n",
            "   ‚Ä¢ Para info din√¢mica: RAG vence!\n",
            "\n",
            "\n",
            "================================================================================\n",
            "üèÜ REGRA DE OURO:\n",
            "\n",
            "   Comece com RAG.\n",
            "   S√≥ v√° para fine-tuning se:\n",
            "   ‚Ä¢ RAG < 80% qualidade\n",
            "   ‚Ä¢ Tem or√ßamento $10k+\n",
            "   ‚Ä¢ Info √© relativamente est√°vel\n",
            "   ‚Ä¢ Tom/comportamento √© cr√≠tico\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üéì LI√á√ïES PR√ÅTICAS DOS TESTES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\"\"\n",
        "‚úÖ LI√á√ÉO 1: RAG resolve 80% dos casos\n",
        "   ‚Ä¢ Vimos que RAG respondeu corretamente usando docs\n",
        "   ‚Ä¢ Citou fontes (Tesouro Selic, CDB)\n",
        "   ‚Ä¢ Informa√ß√µes precisas e atualizadas\n",
        "   \n",
        "‚úÖ LI√á√ÉO 2: Fine-Tuning precisa de MUITOS dados\n",
        "   ‚Ä¢ Vimos que 6 exemplos N√ÉO FUNCIONAM\n",
        "   ‚Ä¢ Modelo fine-tunado ALUCINOU (respostas sem sentido)\n",
        "   ‚Ä¢ Produ√ß√£o precisa 1.000-10.000+ exemplos\n",
        "   ‚Ä¢ Com poucos dados, RAG √© INFINITAMENTE melhor\n",
        "   \n",
        "‚úÖ LI√á√ÉO 3: Modelo Base √© bom mas limitado\n",
        "   ‚Ä¢ Conhecimento geral\n",
        "   ‚Ä¢ Mas pode inventar (alucinar)\n",
        "   ‚Ä¢ Sem fontes verific√°veis\n",
        "\n",
        "‚úÖ LI√á√ÉO 4: Custos escalam diferente\n",
        "   ‚Ä¢ RAG: Linear com queries\n",
        "   ‚Ä¢ Fine-Tuning: Alto inicial, baixo marginal\n",
        "   ‚Ä¢ Break-even: ~800k queries/m√™s\n",
        "\n",
        "‚úÖ LI√á√ÉO 5: Atualiza√ß√£o √© cr√≠tica\n",
        "   ‚Ä¢ RAG: Adiciona doc (minutos)\n",
        "   ‚Ä¢ Fine-Tuning: Re-treina tudo (dias + $$$)\n",
        "   ‚Ä¢ Para info din√¢mica: RAG vence!\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"üèÜ REGRA DE OURO:\")\n",
        "print(\"\\n   Comece com RAG.\")\n",
        "print(\"   S√≥ v√° para fine-tuning se:\")\n",
        "print(\"   ‚Ä¢ RAG < 80% qualidade\")\n",
        "print(\"   ‚Ä¢ Tem or√ßamento $10k+\")\n",
        "print(\"   ‚Ä¢ Info √© relativamente est√°vel\")\n",
        "print(\"   ‚Ä¢ Tom/comportamento √© cr√≠tico\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "38bebe2d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "üéì TESTE 3: FINE-TUNING (Simulado)\n",
            "================================================================================\n",
            "\n",
            "‚ùì Pergunta: Qual o melhor investimento para reserva de emerg√™ncia?\n",
            "\n",
            "üí¨ Resposta Fine-Tuned:\n",
            "Para reserva de emerg√™ncia, recomendo Tesouro Selic ou CDB com liquidez di√°ria. O Tesouro oferece 100 por cento do CDI com risco zero. CDB pode render at√© 120 por cento do CDI, mas depende do banco. Mantenha seis meses de despesas. √â importante considerar a liquidez e o risco, ent√£o escolha o que melhor se adequa √†s suas necessidades.\n",
            "\n",
            "‚è±Ô∏è Tempo: 0.66s\n",
            "üí∞ Custo: ~$0.0002/consulta (ap√≥s treino)\n",
            "üîÑ Atualiza√ß√£o: Dif√≠cil (precisa re-treinar)\n",
            "\n",
            "‚ö†Ô∏è NOTA: Fine-tuning real teria:\n",
            "   ‚Ä¢ Custo inicial: $5.000-15.000\n",
            "   ‚Ä¢ Tempo setup: 2-4 semanas\n",
            "   ‚Ä¢ Menor lat√™ncia (sem busca)\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "def testar_finetuned(pergunta):\n",
        "    \"\"\"Simula fine-tuning com few-shot learning\"\"\"\n",
        "    exemplos_texto = \"\\n\\n\".join([\n",
        "        f\"Pergunta: {ex['input']}\\nResposta: {ex['output']}\"\n",
        "        for ex in exemplos_finetuning\n",
        "    ])\n",
        "    \n",
        "    prompt = f\"\"\"Voc√™ √© especialista em investimentos. Responda no estilo dos exemplos abaixo:\n",
        "\n",
        "{exemplos_texto}\n",
        "\n",
        "Agora responda no mesmo estilo:\n",
        "\n",
        "Pergunta: {pergunta}\n",
        "Resposta:\"\"\"\n",
        "    \n",
        "    start = time.time()\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.3,\n",
        "        max_tokens=300\n",
        "    )\n",
        "    tempo = time.time() - start\n",
        "    return response.choices[0].message.content, tempo\n",
        "\n",
        "# Testar\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üéì TESTE 3: FINE-TUNING (Simulado)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "resposta_ft, tempo_ft = testar_finetuned(pergunta)\n",
        "\n",
        "print(f\"\\n‚ùì Pergunta: {pergunta}\")\n",
        "print(f\"\\nüí¨ Resposta Fine-Tuned:\\n{resposta_ft}\")\n",
        "print(f\"\\n‚è±Ô∏è Tempo: {tempo_ft:.2f}s\")\n",
        "print(f\"üí∞ Custo: ~$0.0002/consulta (ap√≥s treino)\")\n",
        "print(f\"üîÑ Atualiza√ß√£o: Dif√≠cil (precisa re-treinar)\")\n",
        "\n",
        "print(\"\\n‚ö†Ô∏è NOTA: Fine-tuning real teria:\")\n",
        "print(\"   ‚Ä¢ Custo inicial: $5.000-15.000\")\n",
        "print(\"   ‚Ä¢ Tempo setup: 2-4 semanas\")\n",
        "print(\"   ‚Ä¢ Menor lat√™ncia (sem busca)\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a09c0b7",
      "metadata": {},
      "source": [
        "## üß™ Parte 10: Exerc√≠cio Pr√°tico - Teste com Suas Perguntas\n",
        "\n",
        "Agora √© sua vez! Teste as 3 abordagens com suas pr√≥prias perguntas:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "98b4467a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "‚ùì Quanto rende o Tesouro Selic?\n",
            "================================================================================\n",
            "\n",
            "üîç RAG:\n",
            "   O Tesouro Selic rende 100% da Selic.\n",
            "   üìö Fontes: 2 documentos\n",
            "\n",
            "üéì Fine-Tuned:\n",
            "   #\n",
            "\n",
            "üí° Qual foi melhor? Por qu√™?\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "‚ùì Posso investir em a√ß√µes com pouco dinheiro?\n",
            "================================================================================\n",
            "\n",
            "üîç RAG:\n",
            "   Sim, √© poss√≠vel investir em a√ß√µes com pouco dinheiro, pois elas oferecem liquidez alta, especialmente as blue chips. No entanto, √© importante considerar o risco alto associado a esse tipo de investimento. Se voc√™ est√° procurando por uma op√ß√£o com risco m√©dio a alto e rentabilidade mais previs√≠vel, os Fundos Imobili√°rios (FIIs) tamb√©m podem ser uma op√ß√£o, pois oferecem dividendos mensais e valoriza√ß√£o, al√©m de liquidez alta na bolsa.\n",
            "   üìö Fontes: 2 documentos\n",
            "\n",
            "üéì Fine-Tuned:\n",
            "   N√£o.\n",
            "O Campeonato Carioca de Futebol de 2017 foi a 58¬™ edi√ß√£o do torneio, que ocorreu entre o dia 13 e 16 de janeiro de 2018 no Est√°dio do Pacaembu, em partida realizada no dia 15 de novembro contra o Fluminense Football Club .\n",
            "\n",
            "A equipe da competi√ß√£o √© composta por 13 equipes divididas em dois grupos de 4 clubes cada, sendo os quatro primeiros colocados na primeira fase jogando√£o as partidas dos outros dois times nas oitavas-de-final; os segundos classificados jogam uma partida de volta\n",
            "\n",
            "üí° Qual foi melhor? Por qu√™?\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Adicione suas perguntas aqui\n",
        "suas_perguntas = [\n",
        "    \"Quanto rende o Tesouro Selic?\",\n",
        "    \"Posso investir em a√ß√µes com pouco dinheiro?\",\n",
        "    # Adicione mais perguntas sobre investimentos...\n",
        "]\n",
        "\n",
        "for pergunta_teste in suas_perguntas:\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"‚ùì {pergunta_teste}\")\n",
        "    print('='*80)\n",
        "    \n",
        "    # Testar com RAG\n",
        "    print(\"\\nüîç RAG:\")\n",
        "    resultado = rag_chain.invoke({\"query\": pergunta_teste})\n",
        "    print(f\"   {resultado['result']}\")\n",
        "    print(f\"   üìö Fontes: {len(resultado['source_documents'])} documentos\")\n",
        "    \n",
        "    # Testar com Fine-Tuned\n",
        "    print(\"\\nüéì Fine-Tuned:\")\n",
        "    resp_ft = gerar_resposta_finetuned(pergunta_teste)\n",
        "    print(f\"   {resp_ft}\")\n",
        "    \n",
        "    print(\"\\nüí° Qual foi melhor? Por qu√™?\")\n",
        "    print(\"-\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14117c42",
      "metadata": {},
      "source": [
        "## üöÄ Parte 11: Adicione Seus Pr√≥prios Documentos\n",
        "\n",
        "Quer testar com seus pr√≥prios dados? Adicione documentos sobre outros investimentos:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "246fa14d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîÑ Processando seus documentos...\n",
            "\n",
            "üß† Criando novo vector store...\n",
            "‚úÖ Sistema atualizado com 1 novos chunks!\n",
            "‚úÖ Total de 6 chunks no sistema\n",
            "\n",
            "üß™ Testando: Como funciona a previd√™ncia privada?\n",
            "\n",
            "üí¨ Resposta:\n",
            "A previd√™ncia privada √© um plano de investimento que visa proporcionar uma renda adicional no futuro, seja para a aposentadoria ou para outros objetivos de longo prazo. No contexto de reserva de emerg√™ncia e m√©dio prazo, produtos como o CDB (Certificado de Dep√≥sito Banc√°rio) e o LCI (Letra de Cr√©dito Imobili√°rio) podem ser considerados, pois oferecem liquidez e retornos mais est√°veis, adequados para essa faixa de tempo.\n",
            "\n",
            "No entanto, para uma reserva de emerg√™ncia, √© comum considerar investimentos de liquidez ainda mais imediata, como a aplica√ß√£o em contas poupan√ßa ou fundos de investimento de curto prazo, que permitem o acesso r√°pido ao dinheiro em caso de necessidade.\n",
            "\n",
            "J√° para o m√©dio prazo, que pode variar de alguns anos a uma d√©cada, produtos como o Tesouro Direto ou fundos de investimento em t√≠tulos de renda fixa podem ser mais adequados, pois oferecem um equil√≠brio entre risco e retorno, permitindo que o investidor acumule uma reserva para objetivos espec√≠ficos nesse horizonte de tempo.\n",
            "\n",
            "√â importante lembrar que a escolha do produto depende das necessidades, objetivos e perfil de risco de cada investidor, e √© sempre recomend√°vel consultar um especialista em investimentos para obter orienta√ß√£o personalizada.\n",
            "\n",
            "üìö Documentos usados: 2\n",
            "\n",
            "üí° OBSERVE:\n",
            "   ‚Ä¢ Sistema foi atualizado em SEGUNDOS\n",
            "   ‚Ä¢ N√£o precisou re-treinar nada\n",
            "   ‚Ä¢ Com fine-tuning, teria que treinar tudo de novo\n",
            "   ‚Ä¢ √â por isso que RAG vence para info din√¢mica!\n"
          ]
        }
      ],
      "source": [
        "# Seus documentos customizados\n",
        "seus_documentos = [\n",
        "    \"\"\"\n",
        "    Previd√™ncia Privada (PGBL/VGBL)\n",
        "    Tipo: Previd√™ncia\n",
        "    Rentabilidade: Varia conforme fundo escolhido\n",
        "    Liquidez: Baixa (penalidades para resgate antecipado)\n",
        "    Risco: M√©dio\n",
        "    Tributa√ß√£o: PGBL deduz IR, VGBL n√£o\n",
        "    Ideal para: Aposentadoria, benef√≠cio fiscal\n",
        "    \"\"\",\n",
        "    # Adicione mais documentos...\n",
        "]\n",
        "\n",
        "if len(seus_documentos) > 0 and seus_documentos[0].strip():\n",
        "    print(\"\\nüîÑ Processando seus documentos...\\n\")\n",
        "    \n",
        "    # Processar novos documentos\n",
        "    novos_chunks = []\n",
        "    for doc in seus_documentos:\n",
        "        novos_chunks.extend(text_splitter.split_text(doc))\n",
        "    \n",
        "    # Combinar com chunks existentes\n",
        "    todos_chunks = chunks + novos_chunks\n",
        "    \n",
        "    # Criar novo vector store com telemetria desabilitada\n",
        "    print(\"üß† Criando novo vector store...\")\n",
        "    vectorstore_novo = Chroma.from_texts(\n",
        "        texts=todos_chunks, \n",
        "        embedding=embeddings,\n",
        "        client_settings=chroma_settings\n",
        "    )\n",
        "    \n",
        "    # Criar novo RAG chain\n",
        "    rag_chain_novo = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        retriever=vectorstore_novo.as_retriever(search_kwargs={\"k\": 2}),\n",
        "        chain_type_kwargs={\"prompt\": prompt},\n",
        "        return_source_documents=True\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Sistema atualizado com {len(novos_chunks)} novos chunks!\")\n",
        "    print(f\"‚úÖ Total de {len(todos_chunks)} chunks no sistema\\n\")\n",
        "    \n",
        "    # Testar com novo documento\n",
        "    pergunta_nova = \"Como funciona a previd√™ncia privada?\"\n",
        "    print(f\"üß™ Testando: {pergunta_nova}\")\n",
        "    \n",
        "    resultado_novo = rag_chain_novo.invoke({\"query\": pergunta_nova})\n",
        "    print(f\"\\nüí¨ Resposta:\\n{resultado_novo['result']}\")\n",
        "    print(f\"\\nüìö Documentos usados: {len(resultado_novo['source_documents'])}\")\n",
        "    \n",
        "    print(\"\\nüí° OBSERVE:\")\n",
        "    print(\"   ‚Ä¢ Sistema foi atualizado em SEGUNDOS\")\n",
        "    print(\"   ‚Ä¢ N√£o precisou re-treinar nada\")\n",
        "    print(\"   ‚Ä¢ Com fine-tuning, teria que treinar tudo de novo\")\n",
        "    print(\"   ‚Ä¢ √â por isso que RAG vence para info din√¢mica!\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è Para testar com seus dados, edite a lista 'seus_documentos' acima.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83e084a1",
      "metadata": {},
      "source": [
        "## üìù Conclus√£o Final e Pr√≥ximos Passos\n",
        "\n",
        "### üéØ Resumo Executivo do que Demonstramos:\n",
        "\n",
        "Neste notebook, voc√™ viu **NA PR√ÅTICA**:\n",
        "\n",
        "1. ‚úÖ **Modelo Base** (Groq) - R√°pido mas gen√©rico\n",
        "2. ‚úÖ **RAG** (Chroma + docs) - Contextual e atualiz√°vel\n",
        "3. ‚úÖ **Fine-Tuning REAL** (GPT-2 Portugu√™s + LoRA) - Aprende comportamento\n",
        "4. ‚úÖ **Compara√ß√£o t√©cnica** com m√©tricas reais\n",
        "5. ‚úÖ **An√°lise de custos** para diferentes volumes\n",
        "6. ‚úÖ **Matriz de decis√£o** aplicada ao caso\n",
        "7. ‚úÖ **Li√ß√µes pr√°ticas** de erros e acertos\n",
        "\n",
        "### üèÜ Veredicto para Assistente de Investimentos:\n",
        "\n",
        "**RAG venceu!** (87,5% dos crit√©rios atendidos)\n",
        "\n",
        "**Motivos t√©cnicos:**\n",
        "- Informa√ß√µes financeiras mudam constantemente (Selic, IR, FGC)\n",
        "- Compliance exige transpar√™ncia (citar produtos/fontes)\n",
        "- Custo 3-4x menor que fine-tuning\n",
        "- Atualiza√ß√£o em minutos vs dias\n",
        "- Qualidade suficiente (85%+)\n",
        "\n",
        "### ‚ö° Regras de Ouro Comprovadas:\n",
        "\n",
        "1. **Comece com RAG** - 80% dos casos resolve\n",
        "2. **Me√ßa com usu√°rios reais** - N√£o com voc√™\n",
        "3. **Fine-tuning s√≥ se RAG < 80%** - E se tiver or√ßamento\n",
        "4. **Calcule custo por usu√°rio** - Escala importa\n",
        "5. **MVP antes de escalar** - Valide antes de investir\n",
        "\n",
        "### üéì Quando Usar Cada Um (Comprovado):\n",
        "\n",
        "**‚úÖ RAG para:**\n",
        "- Info que muda (legisla√ß√£o, pre√ßos, taxas) ‚≠ê\n",
        "- Precisa transpar√™ncia (citar fontes) ‚≠ê\n",
        "- Or√ßamento < $5k\n",
        "- Volume < 500k queries/m√™s\n",
        "- Time sem experi√™ncia ML\n",
        "\n",
        "**‚úÖ Fine-Tuning para:**\n",
        "- Tom/estilo muito espec√≠fico (marca, compliance)\n",
        "- Dom√≠nio ultra-t√©cnico (m√©dico, jur√≠dico)\n",
        "- Volume > 1M queries/m√™s (break-even)\n",
        "- Lat√™ncia < 100ms cr√≠tica\n",
        "- Info relativamente est√°vel\n",
        "\n",
        "**‚úÖ H√≠brido para:**\n",
        "- Especializa√ß√£o + Info atualizada\n",
        "- Budget n√£o √© limitante\n",
        "- Caso mission-critical\n",
        "- Usu√°rios pagam premium\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "196eae8c",
      "metadata": {},
      "source": [
        "### üìà Pr√≥ximos Passos Para Voc√™:\n",
        "\n",
        "**1. Teste no seu dom√≠nio (esta semana):**\n",
        "   - Escolha um caso de uso real do seu trabalho\n",
        "   - Implemente RAG usando este notebook como base\n",
        "   - Teste com 10 usu√°rios reais\n",
        "   - Me√ßa: % respostas corretas, satisfa√ß√£o, tempo\n",
        "\n",
        "**2. Me√ßa e decida (1-2 semanas):**\n",
        "   - Se RAG >= 80%: Otimize e v√° para produ√ß√£o\n",
        "   - Se RAG < 80%: Identifique o problema\n",
        "   - Problema √© busca? ‚Üí Melhore chunking/embeddings\n",
        "   - Problema √© tom? ‚Üí Considere fine-tuning\n",
        "\n",
        "**3. Escale com consci√™ncia (1+ m√™s):**\n",
        "   - Monitore custos por usu√°rio\n",
        "   - Otimize conforme escala\n",
        "   - S√≥ adicione complexidade se necess√°rio\n",
        "   - Mantenha sempre o mais simples poss√≠vel\n",
        "\n",
        "**4. Compartilhe (sempre):**\n",
        "   - Documente o que aprendeu\n",
        "   - Compartilhe no LinkedIn/GitHub\n",
        "   - Ajude outros a n√£o repetirem erros\n",
        "   - Contribua com a comunidade\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44cc7711",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìö Recursos Adicionais e Links √öteis\n",
        "\n",
        "### Artigos da Pathbit Academy:\n",
        "\n",
        "1. [**LLM vs LRM** - Entenda as diferen√ßas](https://github.com/pathbit/pathbit-academy-ai/blob/master/0001_llm_x_lrm/article/ARTICLE.md)\n",
        "2. [**Embeddings e Vetoriza√ß√£o** - Como funciona](https://github.com/pathbit/pathbit-academy-ai/blob/master/0002_embeddings_vetorizacao/article/ARTICLE.md)\n",
        "3. [**RAG e Vector Database** - Implementa√ß√£o](https://github.com/pathbit/pathbit-academy-ai/blob/master/0003_rag_vector_database/article/ARTICLE.md)\n",
        "4. [**RAG vs Fine-Tuning** - Este artigo completo](https://github.com/pathbit/pathbit-academy-ai/blob/master/0004_rag_vs_finetuning/article/ARTICLE.md)\n",
        "\n",
        "### Documenta√ß√£o T√©cnica:\n",
        "\n",
        "- [**LangChain**](https://python.langchain.com/) - Framework para RAG\n",
        "- [**ChromaDB**](https://docs.trychroma.com/) - Vector database\n",
        "- [**Groq**](https://console.groq.com/) - LLM r√°pido e gratuito\n",
        "- [**Hugging Face PEFT**](https://huggingface.co/docs/peft/) - Fine-tuning com LoRA\n",
        "- [**Sentence Transformers**](https://www.sbert.net/) - Modelos de embeddings\n",
        "\n",
        "### Papers e Refer√™ncias:\n",
        "\n",
        "- [**RAG Paper**](https://arxiv.org/abs/2005.11401) - Original research\n",
        "- [**LoRA Paper**](https://arxiv.org/abs/2106.09685) - Low-Rank Adaptation\n",
        "- [**Pinecone - RAG vs Fine-Tuning**](https://www.pinecone.io/learn/rag-vs-fine-tuning/)\n",
        "\n",
        "---\n",
        "\n",
        "## üéâ Parab√©ns! Voc√™ Completou o Notebook!\n",
        "\n",
        "### üèÜ Voc√™ agora sabe:\n",
        "\n",
        "‚úÖ Como implementar RAG na pr√°tica  \n",
        "‚úÖ Como fazer fine-tuning REAL com LoRA  \n",
        "‚úÖ Quando usar cada abordagem  \n",
        "‚úÖ Como calcular custos reais  \n",
        "‚úÖ Como evitar erros de $100k+  \n",
        "‚úÖ Como tomar decis√µes baseadas em dados  \n",
        "\n",
        "### üí™ Seu Desafio:\n",
        "\n",
        "**Esta semana:**\n",
        "1. Escolha 1 problema real do seu trabalho\n",
        "2. Implemente RAG (use este notebook)\n",
        "3. Teste com 5-10 usu√°rios\n",
        "4. Me√ßa % de sucesso\n",
        "5. Compartilhe resultados no LinkedIn!\n",
        "\n",
        "**Tag:** @pathbit #RAG #FineTuning #IA\n",
        "\n",
        "---\n",
        "\n",
        "**Lembre-se:** A melhor IA n√£o √© a mais avan√ßada, √© a que est√° em **PRODU√á√ÉO** resolvendo problemas reais! üöÄ\n",
        "\n",
        "---\n",
        "\n",
        "Feito com ‚ù§Ô∏è pela **[Pathbit Academy](https://pathbit.com)**\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
